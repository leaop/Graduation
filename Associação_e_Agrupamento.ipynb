{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leaop/Graduation/blob/main/Associa%C3%A7%C3%A3o_e_Agrupamento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUvDmcUKxiVK"
      },
      "source": [
        "# Unidade 2 - Associação e Agrupamento em Tarefas de Mineração de Dados\n",
        "\n",
        "As técnicas de associação e agrupamento são fundamentais na análise de grandes conjuntos de dados, especialmente em áreas como ``mineração de dados`` e aprendizado de máquina.\n",
        "\n",
        "A técnica de associação é usada para descobrir relações frequentes entre itens em um conjunto de dados. Isso é especialmente útil em análises de transações, como compras de clientes em uma loja online. Por exemplo, a técnica de associação pode ser usada para identificar padrões de compra, como produtos que geralmente são comprados juntos, ou produtos que são frequentemente comprados após um determinado evento, como um feriado ou promoção.\n",
        "\n",
        "Já as técnicas de agrupamento são usadas para segmentar um conjunto de dados em grupos, com base em alguma medida de similaridade. Essa técnica é usada em diversos campos, como marketing, pesquisa de mercado, análise de imagem, entre outros. Por exemplo, é possível usar a técnica de agrupamento para segmentar clientes com base em seus comportamentos de compra ou para agrupar imagens com base em suas características visuais.\n",
        "\n",
        "Ambas as técnicas permitem a identificação de padrões e insights em grandes conjuntos de dados que seriam difíceis ou impossíveis de serem descobertos por meio de análises manuais. Além disso, elas podem ser usadas para prever comportamentos futuros com base em padrões passados e para auxiliar na tomada de decisões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd20Z3FkxiVM"
      },
      "source": [
        "## ``Associação``\n",
        "A Associação é uma tarefa de Mineração de Dados que busca descobrir associações frequentes entre um conjunto de itens em um grande conjunto de dados transacionais. Em outras palavras, a associação identifica relações entre diferentes itens que costumam ocorrer juntos em uma transação.\n",
        "\n",
        "A Associação é frequentemente usada em marketing, análise de vendas, análise de padrões de consumo, entre outros. Alguns dos algoritmos mais comuns usados para realizar a tarefa de Associação incluem o algoritmo Apriori e o algoritmo FP-Growth.\n",
        "\n",
        "#### Exemplo de Associação em Tarefas de Mineração de Dados\n",
        "\n",
        "Um exemplo de Associação em Tarefas de Mineração de Dados é a identificação de padrões de consumo de clientes em uma loja de varejo. O objetivo seria encontrar associações entre diferentes produtos comprados por um cliente e identificar quais produtos tendem a ser comprados juntos.\n",
        "\n",
        "O conjunto de dados seria composto por transações de vendas realizadas em diferentes momentos. Cada transação seria composta por uma lista de itens comprados por um cliente. O modelo seria treinado usando algoritmos de mineração de dados de associação, como o algoritmo Apriori, que identifica associações frequentes entre itens.\n",
        "\n",
        "Após o treinamento, o modelo seria capaz de identificar quais produtos tendem a ser comprados juntos com alta frequência e quais produtos têm menos associações entre si. Essas informações podem ser úteis para a loja de varejo para decidir como organizar os produtos nas prateleiras e planejar promoções e ofertas especiais para incentivar a compra de produtos relacionados. Além disso, a loja pode usar essas informações para criar pacotes de produtos que incentivem os clientes a comprar mais itens juntos.\n",
        "\n",
        "#### Outro exemplo de Associação em Tarefas de Mineração de Dados\n",
        "Já reparou que em algumas lojas on-line, quando visita algum produto, em alguma parte da página, geralmente no final, temos uma aba semelhante a \"Pessoas que compraram este produto também compraram estes...\"\n",
        "\n",
        "## ``Regras de Associação``\n",
        "Um dos métodos de avaliar se as associações são boas ou não, é a identificação de regras fortes nas bases de dados. Para isto, precisamos conhecer os seguintes termos:\n",
        "\n",
        "\n",
        "- **Suporte**: o suporte é a frequência absoluta de uma regra em um conjunto de transações. Em outras palavras, o suporte mede a proporção de transações no conjunto que contêm todos os itens da regra. Quanto maior o suporte, mais frequente é a regra no conjunto de dados. (Ex Regra: Cliente que compra cebola compra batata)\n",
        "\n",
        "- **Confiança**: a confiança mede a proporção de transações que contêm todos os itens da regra entre as transações que contêm o antecedente da regra. Em outras palavras, a confiança mede a probabilidade de o consequente aparecer em uma transação que já contém o antecedente. Quanto maior a confiança, mais forte é a associação entre o antecedente e o consequente.(Qual a confiança de que o cliente que comprou cebola (antecedente é comprar cebola) também irá comprar batata (Comprar batata é o consequente))\n",
        "\n",
        "- **Lift**: o lift é uma medida de quão fortemente os itens do antecedente e do consequente estão associados, em relação à sua frequência esperada se fossem independentes. O lift mede a proporção entre a confiança da regra e a frequência do consequente. Se o lift for maior que 1, indica que os itens do antecedente e do consequente estão associados de forma positiva, enquanto um lift menor que 1 indica que eles estão associados de forma negativa. Um lift igual a 1 indica independência entre os itens.\n",
        "\n",
        "**Ex**:\n",
        "\n",
        "Suponha que estamos analisando um conjunto de transações que contém compras em um supermercado. Aqui está um exemplo de como calcular o suporte, a confiança e o lift para uma regra de associação simples:\n",
        "\n",
        "Regra: {cerveja} -> {amendoim} \n",
        "\n",
        "quem compra cerveja (antecedente) também compra amendoim (consequente)\n",
        "\n",
        "Nesta base de dados fictícia temos:\n",
        "100 transações\n",
        "40 transações possuem compra de cerveja\n",
        "30 transações possuem compra de amendoim\n",
        "20 transações possuem compra de cerveja e amendoim\n",
        "\n",
        "**Suporte**: o suporte da regra é a proporção de transações que contêm cerveja e amendoim. Em um total de 100 transações, 20 delas possuem cerveja e amendoim. O suporte seria, portanto, de 20/100 ou 0,2 (20%).\n",
        "\n",
        "**Confiança**: a confiança da regra mede a proporção de transações que contêm cerveja e amendoim entre as transações que contêm cerveja. Com o total de 40 transações que contêm cerveja, 20 delas também contêm amendoim. A confiança seria, portanto, de 20/40 ou 0,5 (50%).\n",
        "\n",
        "**Lift**: o lift da regra mede a força da associação entre cerveja e amendoim, comparado com o que seria esperado se eles fossem independentes. O lift é calculado dividindo a confiança da regra pelo suporte do consequente (quantidade de transações com amendoim dividido pela quantidade de transações totais - 30/100 = 0,3 ou 30%). No nosso exemplo, o lift seria (0,5 / (0.3)) = 1,66.\n",
        "\n",
        "Uma interpretação possível dos resultados seria: a regra {cerveja} -> {amendoim} é relativamente comum, aparecendo em 20% das transações. A confiança de 0,5 indica que quando um cliente compra cerveja, há uma probabilidade de 50% de que ele também compre amendoim. O lift de 1,66 indica que a associação entre as duas variáveis é positiva e que há um efeito sinérgico entre elas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFYYcxMgxiVN"
      },
      "outputs": [],
      "source": [
        "!pip install mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzEKhHrNxiVO"
      },
      "outputs": [],
      "source": [
        "# Importar bibliotecas\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2hcaFQPxiVO"
      },
      "outputs": [],
      "source": [
        "# Leitura da base de dados\n",
        "df = pd.read_csv('compras.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF3Yi-3YxiVO"
      },
      "source": [
        "#### Breve análise exploratória da base de dados\n",
        "Inclui:\n",
        "- Ver as primiras linhas para ter noção do que a base representa;\n",
        "- Informações da base de dados\n",
        "- Quantidade de valores nulos\n",
        "- Informações descritivas da base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFwVn7GAxiVP"
      },
      "outputs": [],
      "source": [
        "# Exibir as 3 primeiras linhas da base de dados\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTV-NN43xiVP"
      },
      "outputs": [],
      "source": [
        "# Informação da base de dados\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLg_agYUxiVP"
      },
      "outputs": [],
      "source": [
        "# Quantidade de valores núlos por coluna\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwz1UAcyxiVP"
      },
      "outputs": [],
      "source": [
        "# Informações descritivas dos valores numéricos\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3YxS-zvxiVP"
      },
      "outputs": [],
      "source": [
        "# Informações descritivas dos valores textuais\n",
        "df.describe(include='O')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jv75ebyxiVQ"
      },
      "source": [
        "#### Aplicação do algorítmo "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RBSGv-kxiVQ"
      },
      "outputs": [],
      "source": [
        "# Transformar o dataframe em uma lista de transações\n",
        "# Agrupa os itens das mesmas compras\n",
        "transactions = df.groupby(['id_compra'])['nome_item'].apply(list).values.tolist()\n",
        "\n",
        "# Forma uma lista de listas\n",
        "transactions[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBWc_qC3xiVQ"
      },
      "outputs": [],
      "source": [
        "transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3qezIUQxiVQ"
      },
      "outputs": [],
      "source": [
        "# Criar uma instância do objeto TransactionEncoder\n",
        "te = TransactionEncoder()\n",
        "\n",
        "# Codificar as transações em um formato de matriz binária\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "\n",
        "# Criar um dataframe com a matriz binária codificada\n",
        "transactions_df = pd.DataFrame(te_ary, columns=te.columns_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0ULvl_DxiVQ"
      },
      "outputs": [],
      "source": [
        "transactions_df.tail(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8DCLqbBxiVQ"
      },
      "outputs": [],
      "source": [
        "df.tail(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cLIJAfIxiVQ"
      },
      "outputs": [],
      "source": [
        "# Aplicar o algoritmo Apriori\n",
        "frequent_itemsets_apriori = apriori(transactions_df, min_support=0.3, use_colnames=True)\n",
        "\n",
        "# Aplicar as regras de associação\n",
        "rules = association_rules(frequent_itemsets_apriori, metric=\"lift\", min_threshold=1)\n",
        "\n",
        "# Mostrar as regras de associação e suas métricas\n",
        "print(\"Regras de associação:\\n\", rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-w0lkvNxiVR"
      },
      "source": [
        "Vamos fazer os cálculos da regra feijão e óleo então arroz\n",
        "\n",
        "#### Suporte\n",
        "Suporte registros que possuem açúcaro e arroz / pela quantidade de compras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6PFA9jFxiVR"
      },
      "outputs": [],
      "source": [
        "# Identificadores das compras que possuem feijão\n",
        "id_acucar = list(df.loc[df['nome_item'] == 'açúcar'].id_compra)\n",
        "# Identificadores das compras que possuem óleo\n",
        "id_arroz = list(df.loc[df['nome_item'] == 'arroz'].id_compra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9OVLOTSxiVR"
      },
      "outputs": [],
      "source": [
        "# Retorna as compras com arroz\n",
        "df.loc[df['nome_item'] == 'arroz']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzTl4qXfxiVR"
      },
      "outputs": [],
      "source": [
        "# Retorna o id_compra das compras com arroz\n",
        "df.loc[df['nome_item'] == 'arroz'].id_compra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO4dMqPFxiVR"
      },
      "outputs": [],
      "source": [
        "# Retorna uma lista com o id_compra das compras com arroz\n",
        "list(df.loc[df['nome_item'] == 'arroz'].id_compra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iZ-PbatxiVR"
      },
      "outputs": [],
      "source": [
        "#Filtro para deixar somente os registros com os identificadores de compras nas listas a cima\n",
        "df_calcula_suporte = df.loc[(df.id_compra.isin(id_acucar))&(df.id_compra.isin(id_arroz))]\n",
        "\n",
        "df_calcula_suporte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuHPR1J2xiVR"
      },
      "outputs": [],
      "source": [
        "# quantidade de compras com açúcar e arroz\n",
        "qtd_suporte = df_calcula_suporte.id_compra.nunique()\n",
        "qtd_suporte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7m_Vct3xiVR"
      },
      "outputs": [],
      "source": [
        "print('Quantidade de compras com açúcar e arroz:',qtd_suporte)\n",
        "print('Quantidade total de compras:',df.id_compra.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW6tyisIxiVR"
      },
      "outputs": [],
      "source": [
        "# Quantidade total de compras\n",
        "df.id_compra.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcnR1vnLxiVR"
      },
      "outputs": [],
      "source": [
        "# Quantidade de compras com açúcar e arroz dividido pela quantidade total de compras\n",
        "suporte = qtd_suporte/df.id_compra.nunique()\n",
        "\n",
        "print('Suporte:',qtd_suporte,'/',df.id_compra.nunique(),' = ',suporte)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gmu1UN-xiVS"
      },
      "source": [
        "#### Confiança\n",
        "\n",
        "Calculada pela quantidade de compras com açúcar e arroz dividido pela quantidade de compras com açucar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4R5scpAxiVS"
      },
      "outputs": [],
      "source": [
        "#Filtro para deixar somente os registros com os identificadores de compras com açúcar\n",
        "df_calcula_confianca = df.loc[(df.id_compra.isin(id_acucar))]\n",
        "\n",
        "# quantidade de compras com açúcar\n",
        "qtd_confianca = df_calcula_confianca.id_compra.nunique()\n",
        "\n",
        "print('Quantidade de compras com açúcacr e arroz:',qtd_suporte)\n",
        "print('Quantidade de compras com açúcacr:',qtd_confianca)\n",
        "\n",
        "confianca = qtd_suporte / qtd_confianca\n",
        "print('Confiança:',qtd_suporte,'/',qtd_confianca,' = ',confianca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJeVeJ8wxiVS"
      },
      "source": [
        "#### lift\n",
        "Calculado pela confiança dividida pelo suporte do consequente(quantidade de vezes que arroz aparece divido pela quantidade de compras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsfBd75IxiVS"
      },
      "outputs": [],
      "source": [
        "#Filtro para deixar somente os registros com os identificadores de compras que possuem arroz\n",
        "df_calcula_lift = df.loc[(df.id_compra.isin(id_arroz))]\n",
        "\n",
        "# quantidade de compras com arroz\n",
        "qtd_lift = df_calcula_lift.id_compra.nunique()\n",
        "\n",
        "print('Quantidade de compras com arroz:',qtd_lift)\n",
        "suporte_consequente = qtd_lift / df.id_compra.nunique()\n",
        "print('Suporte do consequente:',suporte_consequente)\n",
        "\n",
        "lift = confianca / suporte_consequente\n",
        "print('Lift:',confianca,'/',suporte_consequente,' = ',lift)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdbfMVfexiVS"
      },
      "source": [
        "Em resumo, este algoritmo gera regras de associação e não é aplicado depois como um algorítmo treinado. Nós utilizamos as regras identificadas para agregar valor ao negócio.\n",
        "\n",
        "No caso desta regra de quem leva feijão e óleo também irá levar arroz, em um mercado, poderia influenciar na dispersão dos produtos nas prateleiras, deixando estes produtos próximos. Nocaso de mercado online, sugerir arroz para as pessoas que adicionaram feijão e óleo ao carrinho de compra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXeQWZD3xiVS"
      },
      "source": [
        "## ``Agrupamento``\n",
        "O Agrupamento é uma tarefa de Mineração de Dados que busca dividir um conjunto de dados em grupos (ou clusters) que possuem características semelhantes entre si e distintas dos outros grupos. O objetivo do agrupamento é encontrar estruturas ocultas ou padrões nos dados que não são evidentes à primeira vista.\n",
        "\n",
        "Em outras palavras, a tarefa de agrupamento é uma forma de explorar e visualizar dados, permitindo que padrões e relações entre os dados sejam identificados e analisados. O agrupamento é frequentemente usado em segmentação de mercado, análise de redes sociais, análise de imagens e muitas outras áreas.\n",
        "\n",
        "Existem vários algoritmos de agrupamento, incluindo K-Means, Hierarchical Clustering, DBSCAN, Gaussian Mixture Models, entre outros. Cada algoritmo tem suas próprias vantagens e desvantagens e são mais adequado para diferentes tipos de problemas de agrupamento.\n",
        "\n",
        "#### Exemplo de Agrupamento em Tarefas de Mineração de Dados\n",
        "Um exemplo de Agrupamento em Tarefas de Mineração de Dados é a segmentação de clientes com base em suas preferências e comportamentos de compra. O objetivo é agrupar os clientes em diferentes grupos com base em padrões semelhantes de compra, a fim de criar ofertas de produtos personalizadas e otimizar a experiência do cliente.\n",
        "\n",
        "O conjunto de dados seria composto por informações de transações de vendas, incluindo a lista de produtos comprados por cada cliente, o valor gasto em cada compra, a frequência de compra e outras informações relevantes. O modelo seria treinado usando algoritmos de agrupamento, como o algoritmo K-Means, para agrupar os clientes em diferentes clusters com base em suas preferências de compra.\n",
        "\n",
        "Após o treinamento, o modelo seria capaz de identificar os diferentes clusters de clientes com base em suas preferências de compra, como clientes que compram produtos de beleza e cuidados pessoais com frequência, clientes que compram produtos de limpeza doméstica e suprimentos para animais de estimação, clientes que compram principalmente alimentos orgânicos, entre outros. Essas informações podem ser úteis para a empresa de varejo para criar ofertas personalizadas para cada cluster de clientes e melhorar a experiência de compra do cliente. Além disso, essa segmentação pode ajudar a empresa a tomar decisões estratégicas sobre a seleção de produtos, gerenciamento de estoque e planejamento de marketing.\n",
        "\n",
        "#### Outro exemplo de Agrupamento em Tarefas de Mineração de Dados\n",
        "\n",
        "A análise de dados de sensores em uma fábrica para identificar grupos de máquinas com desempenho semelhante. O objetivo seria agrupar as máquinas em diferentes clusters com base em seus padrões de operação e desempenho, a fim de identificar problemas e melhorar a eficiência da fábrica.\n",
        "\n",
        "O conjunto de dados seria composto por informações de sensores em cada máquina, incluindo a temperatura, a pressão, a vibração, a energia consumida e outras informações relevantes. O modelo seria treinado usando algoritmos de agrupamento para agrupar as máquinas em diferentes clusters com base em seus padrões de operação.\n",
        "\n",
        "Após o treinamento, o modelo seria capaz de identificar os diferentes clusters de máquinas com base em seus padrões de operação e desempenho, como máquinas que operam a altas temperaturas e vibrações, máquinas que consomem altas quantidades de energia, entre outros. Essas informações podem ser úteis para a fábrica identificar problemas e fazer ajustes em tempo hábil para evitar avarias ou falhas nas máquinas. Além disso, essa segmentação pode ajudar a fábrica a tomar decisões estratégicas sobre o gerenciamento de recursos, manutenção e planejamento de produção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KgMBzjCxiVS"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEoXpkxDxiVS"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C83J0vG3xiVS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tng6xWH0xiVS"
      },
      "outputs": [],
      "source": [
        "# Leitura da base de dados\n",
        "df = pd.read_csv('compras.csv')\n",
        "df['data'] = pd.to_datetime(df['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4W-aPF8xiVT"
      },
      "outputs": [],
      "source": [
        "# Define quais as colunas o modelo irá usar para treinar\n",
        "X = df[['quantidade','valor']]\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMSSwRWXxiVT"
      },
      "outputs": [],
      "source": [
        "X.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB9u0i03xiVT"
      },
      "outputs": [],
      "source": [
        "X.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5gazE9exiVT"
      },
      "source": [
        "Nem sempre precisamos utilizar bibliotecas para normalizar os dados\n",
        "\n",
        "Desta forma que foi normalizado, o maior valor de cada coluna se tornará igual a 1 e o menor igual a 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqvfzqZgxiVT"
      },
      "outputs": [],
      "source": [
        "# Normaliza as colunas que serão aplicadas ao modelo\n",
        "X = (X - X.min()) / (X.max() - X.min())\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTl74nbTxiVT"
      },
      "outputs": [],
      "source": [
        "X.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vTGJCwjxiVT"
      },
      "outputs": [],
      "source": [
        "X.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fdR16ugxiVT"
      },
      "source": [
        "## Como definir o número de clusters?\n",
        "\n",
        "O próprio sklearn fornece algumas bibliotecas que nos ajudam a determinar qual a quantidade ideal de clusters.\n",
        "\n",
        "Um método múito utilizado é o `Método do cotovelo` (Elbow method). Esta é uma técnica gráfica para determinar o número ideal de clusters em um conjunto de dados. Ele envolve a execução do algoritmo de clustering para um intervalo de valores k e plotar a soma dos erros quadráticos (SSE) em relação ao número de clusters. O número ideal de clusters é geralmente escolhido no ponto em que a curva começa a nivelar, formando um \"cotovelo\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Anfn_P0FxiVT"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Defina o intervalo de valores k\n",
        "k_range = range(1, 10)\n",
        "\n",
        "# Execute o algoritmo de clustering para cada valor k e armazene a soma dos erros quadráticos em uma lista\n",
        "sse = []\n",
        "for k in k_range:\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km.fit(X)\n",
        "    sse.append(km.inertia_)\n",
        "\n",
        "# Trace a curva de cotovelo\n",
        "plt.plot(k_range, sse)\n",
        "plt.xlabel('Número de Clusters (k)')\n",
        "plt.ylabel('soma dos erros quadráticos ')\n",
        "plt.title('Método do Cotovelo')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6geyFqvzxiVT"
      },
      "source": [
        "Analisando o gráfico a cima, podemos identificar que a quantidade ideal de clusters é cerca de 3, 4 ou 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB84NA7rxiVT"
      },
      "outputs": [],
      "source": [
        "# Define quantos clusters queremos identificar (no caso 6)\n",
        "# O random_state permite executar os cálculos da forma mais semelhante possível\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "\n",
        "# Treina o modelo\n",
        "kmeans.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jx1oBlGxiVT"
      },
      "outputs": [],
      "source": [
        "kmeans.labels_.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIQfq4pYxiVU"
      },
      "outputs": [],
      "source": [
        "kmeans.labels_.min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xODQvmW8xiVU"
      },
      "source": [
        "Desnormalizar os dados, apenas aplica a operação inversa da normalização\n",
        "\n",
        "- **normalização:** (valor - valor_minimo) / (valor_maximo - valor_minimo) = valor_normalizado\n",
        "\n",
        "- **desnormalização:** ((valor_maximo - valor_minimo) * valor_normalizado) + valor_minimo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx79qXtvxiVU"
      },
      "outputs": [],
      "source": [
        "X = ((df[['quantidade','valor']].max() - df[['quantidade','valor']].min()) * X) + df[['quantidade','valor']].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKau7ZPZxiVU"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=kmeans.labels_)\n",
        "plt.xlabel('Quantidade de produtos iguais')\n",
        "plt.ylabel('Valor de cada produto')\n",
        "plt.title('Grupos de clientes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPObwwO_xiVU"
      },
      "source": [
        "O que podemos inferir deste gráfico?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXgl7QGyxiVU"
      },
      "source": [
        "# Diferenças entre associação e agrupamento\n",
        "Associação e agrupamento são dois conceitos importantes em mineração de dados, e embora estejam relacionados à descoberta de padrões em conjuntos de dados, eles são diferentes em suas abordagens e objetivos.\n",
        "\n",
        "``Agrupamento`` refere-se ao processo de dividir um conjunto de dados em grupos ou clusters, com base em suas características e semelhanças. O objetivo do agrupamento é encontrar grupos de objetos que sejam semelhantes uns aos outros e diferentes dos outros grupos. O agrupamento é uma técnica de aprendizado não supervisionado, o que significa que o algoritmo não recebe nenhum tipo de rótulo ou classe para orientar a formação dos grupos.\n",
        "\n",
        "Por outro lado, a ``associação`` refere-se ao processo de descobrir relações entre os itens de um conjunto de dados. A associação é usada para encontrar padrões frequentes, que são combinações de itens que ocorrem juntos com uma frequência acima de um limite mínimo estabelecido. A associação é uma técnica de aprendizado não supervisionado, o que significa que o algoritmo não recebe nenhuma informação sobre as classes dos itens, mas apenas os identifica com base em suas características.\n",
        "\n",
        "### Quando usar cada técnica: \n",
        "A escolha da técnica de mineração de dados a ser usada depende dos objetivos do projeto e das características do conjunto de dados. A seguir, apresento alguns casos de uso típicos para cada técnica:\n",
        "\n",
        "``Agrupamento``:\n",
        "\n",
        "- Segmentação de clientes em grupos com base em seus comportamentos de compra, para direcionar campanhas de marketing específicas para cada grupo;\n",
        "\n",
        "- Identificação de grupos de produtos com base em suas características, para melhorar o gerenciamento de estoque;\n",
        "\n",
        "- Agrupamento de notícias ou artigos em categorias para criar uma navegação mais intuitiva em sites de notícias.\n",
        "\n",
        "\n",
        "``Associação``:\n",
        "\n",
        "- Análise de cestas de compras para identificar produtos que são frequentemente comprados juntos, para aprimorar a estratégia de precificação e promoções;\n",
        "\n",
        "- Análise de dados de cliques em sites para identificar páginas que são frequentemente visitadas juntas, para melhorar a usabilidade do site;\n",
        "\n",
        "- Análise de transações financeiras para identificar padrões de gastos fraudulentos.\n",
        "\n",
        "Em resumo, enquanto o agrupamento é usado para encontrar grupos semelhantes de objetos em um conjunto de dados, a associação é usada para descobrir relações frequentes entre os itens de um conjunto de dados. Ambos são importantes na mineração de dados e têm várias aplicações em áreas como marketing, finanças e ciência da computação.\n",
        "\n",
        "`Sugestões de leitura:`\n",
        "Aqui estão algumas referências bibliográficas e sugestões de leitura sobre mineração de dados e as técnicas de agrupamento e associação:\n",
        "\n",
        "- Han, J., Kamber, M., & Pei, J. (2011). Data mining: concepts and techniques (3rd ed.). Morgan Kaufmann Publishers.\n",
        "\n",
        "- Tan, P. N., Steinbach, M., & Kumar, V. (2006). Introduction to data mining. Addison-Wesley.\n",
        "\n",
        "- Jain, A. K. (2010). Data clustering: 50 years beyond K-means. Pattern Recognition Letters, 31(8), 651-666.\n",
        "\n",
        "- Joly, A., Tamine, L., & Vodislav, D. (2017). Association rule mining: A recent overview. Knowledge Engineering Review, 32(3), e5.\n",
        "\n",
        "- Wang, J., & Han, J. (2013). Mining high utility itemsets. Data Mining and Knowledge Discovery, 27(2), 264-299.\n",
        "\n",
        "- Agrawal, R., Imieliński, T., & Swami, A. (1993). Mining association rules between sets of items in large databases. ACM SIGMOD Record, 22(2), 207-216.\n",
        "\n",
        "Esses livros e artigos oferecem uma visão geral dos conceitos de mineração de dados, bem como técnicas específicas de agrupamento e associação. Eles também podem fornecer uma base teórica sólida para quem deseja aprofundar seus conhecimentos na área."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG66nFb7xiVU"
      },
      "source": [
        "# Revisão básica de python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5iZrHIAxiVU"
      },
      "outputs": [],
      "source": [
        "# Importar as bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0CZEvMixiVU"
      },
      "outputs": [],
      "source": [
        "# Leitura da base de dados\n",
        "\n",
        "# Repare que chamamos o pandas por meio do pd\n",
        "# em seguida utilizamos a função read_csv para \n",
        "# especificar qual o arquivo desejamos que seja lido pelo pandas\n",
        "df = pd.read_csv('banco.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJcwqdfhxiVU"
      },
      "outputs": [],
      "source": [
        "# Exibir as 5 primeiras e 5 últimas linhas\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpv0Jy0oxiVU"
      },
      "outputs": [],
      "source": [
        "# Exibir as primeiras 5 linhas\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWdThJAxxiVV"
      },
      "outputs": [],
      "source": [
        "# Exibir as primeiras 2 linhas\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0NxVH8PxiVV"
      },
      "outputs": [],
      "source": [
        "# Exibir as 2 últimas Linhas\n",
        "df.tail(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4cjEzyyxiVV"
      },
      "outputs": [],
      "source": [
        "# Exibe informações das colunas numéricas\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqSZfXo9xiVV"
      },
      "outputs": [],
      "source": [
        "# Exibe uma descrição das colunas do tipo object\n",
        "df.describe(include = \"O\")\n",
        "# A primeira descrição 'count' é a quantidade de valores não nulos\n",
        "# A segunda descrição 'unique' informa quantos valores únicos existem nas colunas\n",
        "# A terceira descrição 'top' informa qual o valor que mais aparece na coluna\n",
        "# A quarta descrição 'freq' é em relação à frequência (quantidade de vezes) que o valor top aparece na coluna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAFji8q9xiVV"
      },
      "outputs": [],
      "source": [
        "df.info()\n",
        "# Repare que existem algumas linhas com valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPgeVNTNxiVV"
      },
      "outputs": [],
      "source": [
        "# Quantidade de valores nulos por coluna\n",
        "df.isnull().sum() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soCs-Z3VxiVV"
      },
      "source": [
        "Verificar quantos valores nulos cada coluna possui é interessante, mas talvez verificar a porcentagem de valores nulos por coluna seja melhor para entender os valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unVCQ_uhxiVV"
      },
      "outputs": [],
      "source": [
        "# Porcentagem de valores nulos por coluna\n",
        "# Abaixo é realizada uma regra de 3 onde \n",
        "# a quantidade de valores nulos é dividida pela\n",
        "# quantidade de linhas do dataframe e multiplicado por 100\n",
        "# Resultando na porcentagem de valores nulos por coluna\n",
        "# Após a regra de 3, é utilizado a função round para exibir\n",
        "# 4 casas decimais\n",
        "round(df.isnull().sum() / len(df) * 100, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ASGSKbNxiVV"
      },
      "outputs": [],
      "source": [
        "# Para verificar a quantidade de valores únicos na coluna emprego\n",
        "df.emprego.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyuu9dy7xiVV"
      },
      "outputs": [],
      "source": [
        "# Para verificar a os valores únicos na coluna emprego\n",
        "df.estado_civil.unique()\n",
        "# No python, quando um valor é nulo é representado por \n",
        "# NaN (Abreviação de Not a Number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eodRMWkCxiVV"
      },
      "outputs": [],
      "source": [
        "# Para verificar a os valores únicos na coluna emprego e a quantidade de aparições de cada valor\n",
        "df.emprego.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNk7eIdGxiVW"
      },
      "outputs": [],
      "source": [
        "# Verificar o tamanho do dataframe (Tabela)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHFhJiY_xiVW"
      },
      "outputs": [],
      "source": [
        "# quantidade de linhas\n",
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY2Qp6LzxiVY"
      },
      "outputs": [],
      "source": [
        "# Existe outro método de verificar a quantidade de linhas do dataframe\n",
        "# é o mesmo método para verificar o tamanho de uma lista\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAO80tnWxiVY"
      },
      "outputs": [],
      "source": [
        "# quantidade de colunas\n",
        "df.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNWMIX4RxiVY"
      },
      "outputs": [],
      "source": [
        "# Listar as colunas do dataframe\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDITceabxiVY"
      },
      "source": [
        "## Selecionar linhas com o loc\n",
        "\n",
        "Assim como o iloc, nós podemos selecionar linhas com o loc, mas seu funcionamento não se da pelo index. No Loc, nós definimos para selecionar todos os registros que estejam de acordo com um determinado valor, em uma determinada coluna, ou seja, por exemplo, podemos selecionar todos os registros que possuemque possuem idade igual a 37\n",
        "\n",
        "Para usar o loc, utilizamos a seguinte sintaxe:\n",
        "* `df.loc[df['nome_da_coluna'] == valor_desejado]` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ6XU010xiVY"
      },
      "outputs": [],
      "source": [
        "# Selecionar todos os registros com iade igual a 37\n",
        "df.loc[df['idade'] == 37]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkOy1PO5xiVY"
      },
      "source": [
        "Assim como vimos anteriormente, podemos usar a função .shape[0] para receber quantos registros existem para o determinado filtro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eluyNXohxiVY"
      },
      "outputs": [],
      "source": [
        "# Selecionar a quantidade de registros com iade igual a 37\n",
        "df.loc[df['idade'] == 37].shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6v8_zBcxiVY"
      },
      "source": [
        "Também podemos usar a função loc com os valores textuais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf0l1liyxiVY"
      },
      "outputs": [],
      "source": [
        "# Selecionar todos os registros com o estado civil divorciado\n",
        "df.loc[df['estado_civil'] == 'divorced']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD7V1UkDxiVZ"
      },
      "source": [
        "Podemos usar mais filtros com o loc com a seguinte sintaxe:\n",
        "* `df.loc[(df['nome_da_coluna'] == valor_desejado) & (df['nome_da_coluna_2'] == valor_desejado_2)]` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YU6pj7wxiVZ"
      },
      "outputs": [],
      "source": [
        "# Exibe as pessoas divorciadas com 25 anos\n",
        "df.loc[(df['idade'] == 25) & (df['estado_civil'] == 'divorced')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_zzVgg9xiVZ"
      },
      "outputs": [],
      "source": [
        "# Exibe as pessoas divorciadas com 35 anos e que são gerentes\n",
        "df.loc[(df['idade'] == 35) & (df['emprego'] == 'management') & (df['estado_civil'] == 'divorced')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3gtfW6OxiVZ"
      },
      "source": [
        "# Outra funcionalidade da função loc\n",
        "\n",
        "Com o loc, podemos passar mais alguns parâmetros, permitindo mudar valores nas linhas em que o filtro selecionou. Veja o exemplo para ficar mais claro para `Alterar os valores da coluna estado_civil`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCvtZbaIxiVZ"
      },
      "outputs": [],
      "source": [
        "# Primeiro, vamos verificar quais são os valores únicos da coluna emprego\n",
        "df.emprego.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORWDddWaxiVZ"
      },
      "outputs": [],
      "source": [
        "# Seleciona todos os registros com o valor retired em emprego\n",
        "df.loc[df['emprego'] == 'retired']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rcal5NbFxiVZ"
      },
      "outputs": [],
      "source": [
        "# após realizar o filtro selecionando os registros que possuem o valor 'married'\n",
        "# Colocamos uma vírgula e selecionamos qual coluna desejamos realizar a alteração\n",
        "# Neste caso selecionamos a própria coluna estado_civil, mas poderia ser qualquer \n",
        "# outra coluna.\n",
        "# Após definir a coluna, fechamos o colchetes e, com o sinal de igual, definimos\n",
        "# Qual será o novo valor para a coluna estado_civil onde os registros eram 'married'\n",
        "df.loc[df['emprego'] == 'retired','emprego'] = 'Aposentado'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hENT_PnvxiVZ"
      },
      "outputs": [],
      "source": [
        "# Verificando novamente os valores presentes na coluna estado_civil\n",
        "# Repare que não existe mais o valor married, pois todos os registros \n",
        "# Que possuiam este valor foram alterados para 'Casado'\n",
        "df.emprego.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3Y-tshQxiVZ"
      },
      "source": [
        "## Valores nulos\n",
        "Voltando a falar de valores nulos, nas colunas em que existem valores nulos, existem algumas observações a serem feitas:\n",
        "* Qual o tipo de dados da coluna\n",
        "* O que a coluna representa\n",
        "* Qual a porcentagem de dados nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv3SaApZxiVZ"
      },
      "outputs": [],
      "source": [
        "# Porcentagem de valores nulos por coluna\n",
        "round(df.isnull().sum() / len(df) * 100, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dusbeCgnxiVZ"
      },
      "source": [
        "Na base de dados, existem 4 colunas com alguns valores nulos.\n",
        "Destas, as colunas com valores numéricos são:\n",
        "* idade;\n",
        "* duracão;\n",
        "* qtd_contato.\n",
        "\n",
        "E a coluna estado_civil é do tipo textual\n",
        "\n",
        "Nas colunas com tipo de dados numéricos, podemos utilizar 3 abordagens:\n",
        "* 1 - Se forem poucos dados nulos, apagar os registros com estes dados;\n",
        "* 2 - Se for uma quantidade considerável de dados podemos:\n",
        "    * 2.1 - Substituir os valores nulos pela média da coluna;\n",
        "    * 2.1 - Substituir os valores nulos pela mediana da coluna;\n",
        "    * 2.1 - Substituir os valores nulos pela moda da coluna.\n",
        "* 3 - Se forem muitos dados nulos, apagar a coluna.\n",
        "\n",
        "Nas colunas com tipo de dados textual, podemos utilizar 3 abordagens:\n",
        "* 1 - Se forem poucos dados nulos, apagar os registros com estes dados;\n",
        "* 2 - Se for uma quantidade considerável de dados podemos substituir os valores nulos pela moda da coluna;\n",
        "* 3 - Se forem muitos dados nulos, apagar a coluna.\n",
        "\n",
        "O que é média, mediana e moda:\n",
        "* Média - é a soma de todos os valores, dividido pela quantidade de valores somados\n",
        "* Mediana - considerando a lista de valores em ordem crescente, é o valor central da lista\n",
        "* Moda - é o valor que mais aparece na coluna\n",
        "\n",
        "Para fazer as alterações nos valores nulos podemos usar a função loc, se for alterar os valores, ou drop se for apagar a coluna.\n",
        "No caso da função loc, não utilizamos um sinal de igualdade para verificar os valores nulos e sim, usamos o .isnull()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJvrjw4YxiVa"
      },
      "source": [
        "### Coluna numérica abordagem 1 - Apagar as linhas.\n",
        "Como na coluna idade não temos nem 0,2% de registros nulos, é aceitável que se exclua tais registros (Poderíamos utilizar os outros métodos também)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lACGg9wxiVa"
      },
      "outputs": [],
      "source": [
        "# Exibe todos os registros com valores nulos na coluna idade\n",
        "df.loc[df['idade'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6AAjDFJxiVa"
      },
      "outputs": [],
      "source": [
        "# Retornamos uma lista com o index de todos os\n",
        "# registros onde a idade é nula \n",
        "df.loc[df['idade'].isnull()].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMVlh2dAxiVa"
      },
      "outputs": [],
      "source": [
        "# Ao executar o código abaixo foram removidos todos os registros \n",
        "# Que possuíam a idade nula\n",
        "df.drop(df.loc[df['idade'].isnull()].index, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWETzn9-xiVa"
      },
      "outputs": [],
      "source": [
        "# Exibe todos os registros com valores nulos na coluna idade\n",
        "df.loc[df['idade'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSMTSNPUxiVa"
      },
      "outputs": [],
      "source": [
        "# Porcentagem de valores nulos por coluna\n",
        "round(df.isnull().sum() / len(df) * 100, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI55frjPxiVa"
      },
      "source": [
        "### Coluna numérica abordagem 2 - substituir valores nulos por média, mediana ou moda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trbNfTcdxiVa"
      },
      "outputs": [],
      "source": [
        "media = df.duracao.mean()\n",
        "mediana = df.duracao.median()\n",
        "print(f'Média da coluna duração {media}')\n",
        "print(f'Mediana da coluna duração {mediana}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86He91oexiVa"
      },
      "source": [
        "Importante notar que, a média, geralmente será um valor com casas decimais e, a depender da coluna, devemos remover as casas decimais com a função round.\n",
        "\n",
        "Por exemplo, a coluna duracao representa quantos dias o cliente tem conta no banco, então não podemos ter que o cliente possui conta há 400.64843 dias..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMLzHswAxiVa"
      },
      "outputs": [],
      "source": [
        "# Retorna a média arredondada sem casas decimais da coluna\n",
        "round(df['duracao'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_fqpyYQxiVa"
      },
      "outputs": [],
      "source": [
        "# Exibe todos os registros com valores nulos na coluna duracao\n",
        "df.loc[df['duracao'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESpbkQDExiVa"
      },
      "outputs": [],
      "source": [
        "# Altera todos os registros com valores núlos da coluna duração para a média arredondada da coluna\n",
        "df.loc[df['duracao'].isnull(), 'duracao'] = round(df['duracao'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH-RTAGKxiVb"
      },
      "outputs": [],
      "source": [
        "# Exibe todos os registros com valores nulos na coluna duracao\n",
        "df.loc[df['duracao'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgJzA5KSxiVb"
      },
      "outputs": [],
      "source": [
        "# Porcentagem de valores nulos por coluna\n",
        "round(df.isnull().sum() / len(df) * 100, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wggi8ZvvxiVb"
      },
      "source": [
        "### Coluna de valores textuais \n",
        "Na coluna estado_civil temos quase 90% de dados nulos, o melhor que podemos fazer é apagar a coluna, mas, se fossem poucos dados núlos, poderíamos excluir somente as linhas com valores nulos nesta coluna e, ou usar a moda para atribuir o valor que mais aparece na coluna aos valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S2uYKTsxiVb"
      },
      "outputs": [],
      "source": [
        "# Apenas para exibir a moda da coluna textual, \n",
        "# mas não iremos utilizá-la\n",
        "df.estado_civil.mode()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrY6G6JvxiVb"
      },
      "outputs": [],
      "source": [
        "# Desta forma apenas exibimos a tabela sem a coluna estado_civil\n",
        "# Devido ao parâmetro inplace ser False\n",
        "df.drop('estado_civil', inplace=False, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8g8DuRYxiVb"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0BmVCfPxiVb"
      },
      "outputs": [],
      "source": [
        "# Desta forma apagamos definitivamente a coluna estado_civil\n",
        "df.drop('estado_civil', inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFXkBeFrxiVb"
      },
      "outputs": [],
      "source": [
        "# Porcentagem de valores nulos por coluna\n",
        "# Repare que não temos mais a coluna estado_civil\n",
        "# E também temos todas as colunas sem valores nulos\n",
        "round(df.isnull().sum() / len(df) * 100, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT2h8XuAxiVb"
      },
      "source": [
        "# Salvar alterações\n",
        "\n",
        "Diferente de uma planilha excel que nós abrimos o arquivo, editamos e salvamos o mesmo arquivo, no python toda alteração realizada na tabela não será salva até que utilize o comando para salvar as alterações.\n",
        "\n",
        "Para o comando que salva as alterações, é necessário definir um nome para o arquivo. Podemos definir o nome igual ao do arquivo original, o que acarretaria em substituir o arquivo original pelo arquivo alterado, então, por padrão, definimos um nome diferente do original e intuitivo.\n",
        "\n",
        "Outro ponto importante, por padrão, ao salvar a DataFrame alterado, será criada uma coluna com o index dos registros. Para evitar que isto aconteça, é necessário que chame o parâmetro `index e selecione False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3JD6knQxiVb"
      },
      "outputs": [],
      "source": [
        "df.to_csv('banco_alterado_sem_dados_nulos.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vsmk3gkxiVb"
      },
      "source": [
        "# Exercício\n",
        "\n",
        "1 - importe a biblioteca pandas com apelido pd\n",
        "\n",
        "2 - Crie uma variável para receber o banco de dados 'banco_exercicio.csv'\n",
        "\n",
        "3 - Faça uma análise inicial a respeito da base de dados\n",
        "\n",
        "4 - Analise o tipo de dados das colunas que possuem valores nulos\n",
        "\n",
        "5 - Realize o tratamento da base de dados para que nenhuma coluna possua valores nulos\n",
        "\n",
        "6 - Salve a base de dados com o nome 'banco_exercicios_tratado.csv' e sem o index\n",
        "\n",
        "\n",
        "Obs: utilize os blocos de código abaixo para realizar isto. Caso necessário, pode criar mais blocos de código"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX2wcLY-xiVb"
      },
      "source": [
        "# 1 - importar a biblioteca para leitura e manipulação de tabelas com o apelido pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7qY4x61xiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moF4P8tMxiVc"
      },
      "source": [
        "# 2 - leitura da base de dados\n",
        "Criamos a variável df e utilizamos o pandas por meio do apelido pd para ler o nosso arquivo banco_exercicio.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLxWsgGuxiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seR4OEP7xiVc"
      },
      "source": [
        "# 3 - Faça uma análise exploratória da base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YROIVlUxiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O-zvHrnxiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA7ntDTixiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHbD1vn9xiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QafzCa19xiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmDO_JxqxiVc"
      },
      "source": [
        "# 4 - Analise o tipo de dados das colunas que possuem valores nulos\n",
        "apenas a última coluna não possui valores nulos, então iremos analisar o tipo de dados de todas as outras colunas\n",
        "\n",
        "lembrando que o tipo de dados da coluna estará presente em Dtype e:\n",
        "* float64 - Representa os dados numéricos com casas decimais\n",
        "* int -  Representa os dados numéricos com casas inteiros\n",
        "* Object - representa os dados textuais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTAkIpI1xiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg4ZUFHpxiVc"
      },
      "source": [
        "# 5 - Realize o tratamento da base de dados para que nenhuma coluna possua valores nulos\n",
        "Analisando a quantidade de valores nulos, nunhuma coluna possui dados nulos suficientes para justificar a exclusão da coluna\n",
        "\n",
        "As colunas abaixo de 1% de valores nulos podemos excluir ass linhas com os valores nulos (Também poderiamos substituir pela moda, mediana...)\n",
        "\n",
        "Valores textuais (object) com mais de 1% de dados nulos vamos substituir os dados nulos pela moda\n",
        "\n",
        "Valores numéricos (float ou int) com mais de 1% de dados nulos vamos substituir os dados nulos pela moda, mediana ou média"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWjzmgmkxiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHv8uQZVxiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqo48dTBxiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_3EL0OOxiVc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qS4IygOxiVc"
      },
      "source": [
        "# 6 - Salve a base de dados com o nome 'banco_exercicios_tratado.csv' e sem o index\n",
        "\n",
        "Antes de salvar a base de dados tratada, apenas para verificar se a base de dados está sem valores nulos, vamos verificar a porcentagem de valores nulos por coluna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ExBVC6rxiVd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAnzWSBYxiVd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}