{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Analisar os Dados\n",
    "Nesta etapa são realizadas análises para entender os dados que estamos trabalhando. \n",
    "\n",
    "Geralmente existe algum documento ou texto informando a origem e a finalidade dos dados, mas ainda é necessário análisar coisas como:\n",
    "* Quais valores são mais frequentes;\n",
    "* Faixa etária;\n",
    "* Quantidade/porcentagem de valores nulos;\n",
    "* \n",
    "\n",
    "A primeira coisa, mais importante a se fazer, é importar a biblioteca que nos permite analisar e manipular tabelas, o `pandas`.\n",
    "\n",
    "Para importar o pandas, usamos o comando `import pandas as pd`, que em tradução, seria algo como \"importar o pandas como pd\", ou seja, para utilizarmos a biblioteca pandas, iremos utilizar a sigla `pd`.\n",
    "\n",
    "Se por algum motivo der erro ao executar o comando `import pandas as pd`, provavelmente o pandas não estará instalado no computador em questão. Para instalar o pandas, basta executar, em uma célula de código, o comando `!pip install pandas`\n",
    "\n",
    "Detalhe importante: Ao abrir um jupyter notebook (arquivo com extensão `.ipynb`), verificar se a versão do python que esta sendo executada é a versão do anaconda e se o arquivo está marcado como confiável (em inglês, `trust`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar a biblioteca pandas com o apelido pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após importat a biblioteca pandas, devemos realizar a leitura da base de dados. Para isto, o arquivo jupyter notebook (arquivo com extensão `.ipynb`) e a base de dados necessitam estar na mesma pasta.\n",
    "\n",
    "Para ler o arquivo de dados (arquivo com extensão `.csv`), criamos uma variável, geralmente chamada de df (abreviação de Data Frame, em portugês seria \"Quadro de Dados\"), e atribuímos à variável, com o sinal `=`, a leitura da base de dados com pd.read_csv('nome_do_arquivo.csv').\n",
    "\n",
    "Vale ressaltar que os dados geralmente vem no formato `.csv` (`C`omma `S`eparated `V`alues, em portugês, Valores separadps por vírgula), mas em alguns raros casos, os dados podem vir no formato do excel `.xlsx` e, nestes casos, o comando para ler estes arquivos é bem intuitivo, sendo, ao invés de `pd.read_csv('nome_do_arquivo.csv')` fica `pd.read_excel('nome_do_arquivo.xlsx)`\n",
    "\n",
    "\n",
    "A fonte dos dados da aula de hoje está disponível em:\n",
    "https://www.kaggle.com/datasets/jackdaoud/marketing-data?select=ifood_df.csv\n",
    "\n",
    "A base de dados que iremos utilizar hoje foi fornecida pelo ifood, gerada ao realizar uma pesquisa averiguando o perfil dos clientes durante 2 anos e se eles iriam ou não aceitar a campanha de aderir ao clube ifood. \n",
    "\n",
    "Na pasta do google drive em que esta aula se encontra existe uma imagem chamada `metadados.png` com informações do que cada coluna representa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a leitura da base de dados\n",
    "df = pd.read_csv('ifood.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe as 3 linhas iniciais da tabela\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repare que a quantidade de colunas muito grande acaba não exibindo todas as colunas. Para resolver isto, podemos solicitar para mostrar as colunas que desejamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe todas as colunas\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe as duas linhas iniciais da metade das colunas\n",
    "df[['ultima_compra', 'visitas', 'online', 'loja', 'catalogo', 'descontos',\n",
    "       'vinho', 'doces', 'fruta', 'carne']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe as duas linhas iniciais da outra metade das colunas\n",
    "df[['peixe', 'renda', 'total_gasto', 'adolescentes', 'criancas', 'estado_civil', \n",
    "'educacao', 'tempo_cliente', 'reclamacao', 'idade', 'aceitou_campanha']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "  ['ultima_compra', 'visitas', 'online', 'loja', 'catalogo', 'descontos',\n",
    "       'vinho', 'doces', 'fruta', 'carne', 'peixe', 'renda', 'total_gasto',\n",
    "       'adolescentes', 'criancas', 'estado_civil', 'educacao', 'tempo_cliente',\n",
    "       'reclamacao', 'idade',\n",
    "       'aceitou_campanha']  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe quantidade de valores nulos por coluna\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa base de dados não possui valores nulos, não sendo necessário realizar o tratamento de valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe o tipo de dados das colunas\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe informações descritivas a respeito das colunas numéricas\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe informações descritivas a respeito das colunas não numéricas\n",
    "df.describe(include='O').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com a informação da coluna (`aceitou_campanha`) que é a classe alvo, existem apenas valores 1 e 0.\n",
    "\n",
    "Desta forma, também é interessante analizarmos quantas vezes cada valor aparece nesta coluna. Para isto, usamos o comando value_counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.aceitou_campanha.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um insight interessante que já podemos ter é que a minoria dos clientes aceitou contratar o clube ifood e talvez seja interessante mudar a estratégia de marketing que esta sendo utilizada..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Tratamento de Dados\n",
    "\n",
    "Nesta etapa se enquadram 3 etapas:\n",
    "* Tratamento de valores nulos;\n",
    "* Converter dados textuais para numéricos;\n",
    "* Normalizar os dados.\n",
    "\n",
    "Como vimos durante nossa análise dos dados, não temos dados nulos e temos apenas duas colunas com valores textuais (as colunas `estado_civil` e `educacao`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Converter dados textuais para numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica quais valores aparecem na coluna educacao e quantas vezes aparecem\n",
    "df.educacao.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por se tratar de uma quantidade relativamente pequena de valores únicos, iremos usar o loc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['educacao'] == 'primeiro_grau', 'educacao'] = 1\n",
    "df.loc[df['educacao'] == 'segundo_grau', 'educacao'] = 2\n",
    "df.loc[df['educacao'] == 'graduado', 'educacao'] = 3         \n",
    "df.loc[df['educacao'] == 'mestrado', 'educacao'] = 4         \n",
    "df.loc[df['educacao'] == 'doutorado', 'educacao'] = 5     \n",
    "# Converte a coluna educacao para o tipo de dados numérico  \n",
    "df['educacao'] = pd.to_numeric(df['educacao'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica quais valores aparecem na coluna estado_civil e quantas vezes aparecem\n",
    "df.estado_civil.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['estado_civil'] == 'solteiro', 'estado_civil'] = 1\n",
    "df.loc[df['estado_civil'] == 'uniao_estavel', 'estado_civil'] = 2\n",
    "df.loc[df['estado_civil'] == 'casado', 'estado_civil'] = 3         \n",
    "df.loc[df['estado_civil'] == 'divorciado', 'estado_civil'] = 4         \n",
    "df.loc[df['estado_civil'] == 'viuvo', 'estado_civil'] = 5   \n",
    "# Converte a coluna estado_civil para o tipo de dados numérico  \n",
    "df['estado_civil'] = pd.to_numeric(df['estado_civil'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica o tipo de dados das colunas\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Normalizar os dados\n",
    "\n",
    "A normalização é necessária para que todas as colunas possuam o mesmo peso de importância para os algoritmos de machine learning. Entretanto, após treinar um modelo, só é possível utilizar o modelo treinado em dados normalizados pelos mesmos parâmetros utilizados para normalizar os dados que treinaram o modelo.\n",
    "\n",
    "#### O que são estes parâmetros?\n",
    "Para normalizar os dados, são necessários dois valores de cada coluna, sendo o valor máximo e o valor mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista para receber o nome das colunas\n",
    "lista_coluna = []\n",
    "# Cria uma lista para receber o valor máximo de cada coluna\n",
    "lista_max = []\n",
    "# Cria uma lista para receber o valor mínimo de cada coluna\n",
    "lista_min = []\n",
    "\n",
    "# Cria um loop para percorrer as colunas\n",
    "# e preencher as listas criadas acima\n",
    "# Sem pegar os dados da última coluna\n",
    "for col in df.columns[0:-1]:\n",
    "    lista_coluna.append(col)\n",
    "    lista_max.append(df[col].max())\n",
    "    lista_min.append(df[col].min())\n",
    "\n",
    "# Cria um dicionário com as listas criadas\n",
    "dic_norm = {\n",
    "    'coluna' : lista_coluna,\n",
    "    'maximo': lista_max,\n",
    "    'minimo': lista_min}\n",
    "\n",
    "# Cria um dataframe com o dicionário criado\n",
    "df_normalizar = pd.DataFrame(dic_norm)\n",
    "\n",
    "# Exibe os dados utilizados para normalizar a base de dados\n",
    "df_normalizar\n",
    "\n",
    "# Se desejar salvar estes dados para\n",
    "# utilizar em outros dias, basta salvar\n",
    "# esta base de dados conforme aprendemos\n",
    "# basta descomentar a linha de baixo para salvar\n",
    "# df_normalizar.to_csv('parametros_para_normalizar.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não podemos equecer de não normalizar a coluna da nossa classe alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a normalização de toda a base de dados e atribui à variável df_norm\n",
    "df_norm = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "# Retornamos os valores da classe alvo para os valores numéricos originais\n",
    "df_norm[['aceitou_campanha']] = df[['aceitou_campanha']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe a base de dados normalizada\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Vamos treinar um modelo!!\n",
    "Para treinar o modelo nós separamos a base de dados em duas partes, `treinamento` e `teste`.\n",
    "\n",
    "# `Treinamento`\n",
    "Será utilizado para treinar o modelo\n",
    "\n",
    "# `Teste`\n",
    "Será utilizado para Testar se o modelo performa bem em dados que não foram utilizados para treinar\n",
    "\n",
    "# Como fazemos isto?\n",
    "Iremos utilizar a biblioteca train_test_split do sklearn, que irá realizar isto automaticamente.\n",
    "\n",
    "Para isto, precisamos separar os dados em 2 (x e y), sendo X as `variáveis independentes` e y a `variável dependente` (Classe Alvo).\n",
    "\n",
    "Na varável x nós queremos colocar todas as colunas menos a última, então vamos usar o código `list(df_norm.columns[0:-1])` para selecionar todas as colunas menos a última"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribui todas as colunas menos a última à variável X\n",
    "x = df_norm[list(df_norm.columns[0:-1])]\n",
    "\n",
    "# Atribuimos à variável y a nossa classe alvo (que é aceitou_campanha ou não)\n",
    "y = df_norm['aceitou_campanha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quantidade de dados utilizados para o teste geralmente  fica entre 40% e 20%. Esta porcentagem de dados para testes é definida no parâmetro test_size.\n",
    "\n",
    "Geralmente é bom ter muitos dados para treinar o modelo (o termo \"muitos\" pode ser subjetivo, mas diria que uma boa quantidade é de 10.000 para cima.), mas como temos uma quantidade pequena de dados (um pouco mais de 2000 registros), irei separar apenas 15% para teste e 85% para treinar o modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos a biblioteca necessária para dividir a base de dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos X e y em treino e teste\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(x, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Cria uma instância do modelo\n",
    "clf = ExtraTreesClassifier()\n",
    "# Treina o modelo com a base de treinamento\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "# Realiza a predição dos valores de teste\n",
    "pred_Y = clf.predict(test_X)\n",
    "\n",
    "# Retorna a acurácia de acerto na base de teste\n",
    "accuracy_score(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bons resultados de acurácia são acurácias acima de 95%. O que não significa que nosso resultado obtido tenha sido horroroso, podemos deduzir dois pontos:\n",
    "* Tivemos poucos dados para treinar o modelo e é necessário que sejam coletados mais dados, ou;\n",
    "* Os dados não posuem uma correlação muito boa para prever nossa classe alvo.\n",
    "\n",
    "Outra forma de analisarmos o resultado é com a matriz de confusão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a biblioteca para realizar a matriz de confusão\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Cria a matriz de confusão com os dados reais de teste e os preditos\n",
    "confusion_matrix(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para interpretar a matriz de confusão, vamos interpretar o 0 como negativo (de não aceitou a proposta) e o 1 como positivo (aceitou a proposta):\n",
    "\n",
    "* VN (Verdadeiro Negativo) - São os valores 0 classificados como 0\n",
    "* VP (Verdadeiro Positivo) - São os valores 1 classificados como 1\n",
    "* FP (Falso Positivo) - São os valores 0 classificados como 1\n",
    "* FN (Falso Negativo) - São os valores 1 classificados como 0\n",
    "\n",
    "Então, analisando a matriz de confusão retornada, temos:\n",
    "* VN = 279\n",
    "* VP = 16\n",
    "* FP = 5\n",
    "* FN = 31\n",
    "\n",
    "O calculo da acurácia é dado por:\n",
    "\n",
    "`(VN + VP) / (VN + FP + FN + VP)`\n",
    "\n",
    "E na prática, fica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(279 + 16) / (279 + 5 + 31 + 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - E se quisermos testar o nosso algoritmo treinado em novos dados??\n",
    "\n",
    "Podemos preencher manualmente uma planilha no excel, usar o formulário do google ou ja receber uma planilha pronta (em csv ou xlsx).\n",
    "\n",
    "Importante notar que geralmente, os dados novos geralmente não possuem a classe alvo, sendo papel do nosso modelo treinado prever para a classe alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repare que estamos lendo um arquivo de excel, não um csv\n",
    "df = pd.read_excel('dados_novos.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como realizamos o tratamento dos dados anteriormente, agora também temos que converter dados textuais para numéricos e em seguida normalizar com os valores de df_normalizar\n",
    "\n",
    "Para converter os dados textuais para numéricos é muito simples, basta usar os mesmos códigos de antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['educacao'] == 'primeiro_grau', 'educacao'] = 1\n",
    "df.loc[df['educacao'] == 'segundo_grau', 'educacao'] = 2\n",
    "df.loc[df['educacao'] == 'graduado', 'educacao'] = 3         \n",
    "df.loc[df['educacao'] == 'mestrado', 'educacao'] = 4         \n",
    "df.loc[df['educacao'] == 'doutorado', 'educacao'] = 5     \n",
    "# Converte a coluna educacao para o tipo de dados numérico  \n",
    "df['educacao'] = pd.to_numeric(df['educacao'])    \n",
    "\n",
    "df.loc[df['estado_civil'] == 'solteiro', 'estado_civil'] = 1\n",
    "df.loc[df['estado_civil'] == 'uniao_estavel', 'estado_civil'] = 2\n",
    "df.loc[df['estado_civil'] == 'casado', 'estado_civil'] = 3         \n",
    "df.loc[df['estado_civil'] == 'divorciado', 'estado_civil'] = 4         \n",
    "df.loc[df['estado_civil'] == 'viuvo', 'estado_civil'] = 5   \n",
    "# Converte a coluna estado_civil para o tipo de dados numérico  \n",
    "df['estado_civil'] = pd.to_numeric(df['estado_civil'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos uma lista com o index \n",
    "# (valor único de cada linha)\n",
    "list(df_normalizar.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencionado anteriormente, os novos dados necessitam ser normalizados com os valores utilizados nos dados de treinamento do modelo.\n",
    "\n",
    "Com o df_normalizar e o código abaixo (ambos são códigos universais então podem ser utilizados em outros códigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = df.copy()\n",
    "for var in list(df_normalizar.index):\n",
    "    coluna = df_normalizar.iloc[var]['coluna']\n",
    "    maximo = df_normalizar.iloc[var]['maximo']\n",
    "    minimo = df_normalizar.iloc[var]['minimo']\n",
    "\n",
    "    df_norm[coluna] = (df_norm[coluna] - minimo) / (maximo - minimo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, é importante notar, que os novos dados que desejamos prever, não possuem a classe alvo, logo não é possível calcular a acurácia nem a matriz de confusão.\n",
    "\n",
    "Também não é necessário realizar a separação da base em treinamento e teste (pois temos já treinamos e testamos o modelo), basta usar o df_norm para o modelo prever os valores da classe alvo\n",
    "\n",
    "Após realizar a previsão de cada registro, será criada uma lista de valores preditos que poderemos alocar na classe alvo do Data Frame df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a predição dos valores de teste\n",
    "pred_Y = clf.predict(df_norm)\n",
    "\n",
    "# Criamos a coluna aceitou_campanha\n",
    "# e alocamos os valores preditos para\n",
    "# a coluna \n",
    "df['aceitou_campanha'] = pred_Y\n",
    "\n",
    "# Exibe os dados novos e os respectivos valores preditos\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios\n",
    "\n",
    "A base de dados `preco_carros.csv` possui informaçõs sobre valores de carros no reino unido.\n",
    "\n",
    "\n",
    "## Contexto\n",
    "Os dados foram extraídos de vários sites na República Tcheca e na Alemanha durante um período de mais de um ano. Originalmente, eu queria construir um modelo para estimar se um carro é uma boa ou má compra com base na postagem. \n",
    "Mas não consegui criar um modelo com o qual pudesse ficar satisfeito e agora não tenho utilidade para esses dados. Eu acredito muito em dados abertos, então aqui vai.\n",
    "\n",
    "## OBS\n",
    "Os dados foram ajustados lentamente ao longo do ano e algumas das fontes foram completamente desestruturadas, portanto, como resultado, os dados estão sujos, há valores ausentes e alguns valores obviamente errados (por exemplo, números de telefone raspados como quilometragem, etc.)\n",
    "\n",
    "Existem aproximadamente 3,5 milhões de linhas e as seguintes colunas:\n",
    "\n",
    "maker - normalizou todas as letras minúsculas\n",
    "\n",
    "modelo - tudo normalizado em minúsculas\n",
    "\n",
    "quilometragem - em KM\n",
    "\n",
    "ano_fabricação\n",
    "\n",
    "engine_displacement - em ccm\n",
    "\n",
    "engine_power - em kW\n",
    "\n",
    "body_type - quase nunca presente, mas raspei apenas carros pessoais, sem motocicletas ou veículos utilitários\n",
    "\n",
    "color_slug - também quase nunca presente\n",
    "\n",
    "stk_year - ano do último controle de emissão\n",
    "\n",
    "transmissão - automática ou manual\n",
    "\n",
    "porta_contagem\n",
    "\n",
    "assento_contagem\n",
    "\n",
    "fuel_type - gasolina, diesel, cng, gpl, elétrico\n",
    "\n",
    "date_created - quando o anúncio foi copiado\n",
    "\n",
    "data da última visualização - quando o anúncio foi visto pela última vez. Nossa política era remover todos os anúncios com mais de 60 dias\n",
    "\n",
    "price_eur - preço de tabela convertido em EUR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Um modelo treinado em todos os carros pode ser usado para prever com precisão os preços dos modelos com apenas algumas amostras?\n",
    "\n",
    "\n",
    "1 - Realize a leitura da base de dados;\n",
    "\n",
    "2 - Realize uma análise da base de dados (Tipo de dados das colunas, quantidade e porcentagem de valores nulos por coluna, descrição de valores...);\n",
    "\n",
    "3 - Realize o tratamento de valores nulos;\n",
    "\n",
    "4 - Realize a conversão dos valores textuais para numéricos;\n",
    "\n",
    "5 - Realize a normalização da base de dados (Sem normalizar a classe alvo, que é a última coluna `aceitou_proposta`);\n",
    "\n",
    "6 - Crie a variável X (Para receber os dados de todas as colunas menos a última);\n",
    "\n",
    "7 - Crie a variável y para receber os dados da coluna `aceitou_proposta`;\n",
    "\n",
    "8 - Use o train_test_split para separar a base de dados em treinamento e teste (separe 30% dos dados para teste);\n",
    "\n",
    "9 - Aplique a base de treinamento em no mínimo 4 modelos;\n",
    "\n",
    "10 - Verifique qual modelo resultou na melhor acurácia;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f43ba6cefd8f24580ff42e8af3aabb69fa421e7aad4e479f4a62a25e10b01fe1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
