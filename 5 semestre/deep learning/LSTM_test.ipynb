{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_excel('dados.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 37) (3874043292.py, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 37\u001b[1;36m\u001b[0m\n\u001b[1;33m    [net, Modelo] = predictAndUpdateState(net, X_treino');\u001b[0m\n\u001b[1;37m                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 37)\n"
     ]
    }
   ],
   "source": [
    "% Verifique se as seguintes toolboxes estão instaladas antes de executar este script\n",
    "% Deep Learning Toolbox\n",
    "% Statistics and Machine Learning Toolbox (opcional para pré-processamento)\n",
    "\n",
    "num_dados_treino = floor(0.9*numel(dados));\n",
    "num_dados_teste = numel(dados) - num_dados_treino;\n",
    "\n",
    "% Normalizando dados\n",
    "mu = mean(dados(1:num_dados_treino));\n",
    "sig = std(dados(1:num_dados_treino));\n",
    "\n",
    "dados_treino_normalizado = (dados(1:num_dados_treino) - mu) / sig;\n",
    "\n",
    "% Prepara as previsões\n",
    "X_treino = dados_treino_normalizado(1:end-1);\n",
    "Y_treino = dados_treino_normalizado(2:end);\n",
    "\n",
    "% LSTM\n",
    "\n",
    "numFeatures = 1;\n",
    "numResponses = 1;\n",
    "numHiddenUnits = 200;\n",
    "\n",
    "layers = [...\n",
    "        sequenceInputLayer(numFeatures)\n",
    "        lstmLayer(numHiddenUnits,'OutputMode','sequence')\n",
    "        fullyConnectedLayer(numResponses)\n",
    "        regressionLayer];\n",
    "\n",
    "options = trainingOptions('rmsprop', ...\n",
    "    'MaxEpochs', 1000, ...\n",
    "    'GradientThreshold', 1, ...\n",
    "    'InitialLearnRate', 0.01, ...\n",
    "    'LearnRateSchedule', 'piecewise', ...\n",
    "    'LearnRateDropPeriod', 125, ...\n",
    "    'LearnRateDropFactor', 0.2, ...\n",
    "    'Plots', 'training-progress', ...\n",
    "    'Verbose', 0);\n",
    "\n",
    "net = trainNetwork(X_treino', Y_treino', layers, options);\n",
    "[net, Modelo] = predictAndUpdateState(net, X_treino');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 200)         161600    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 200)               320800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 482,601\n",
      "Trainable params: 482,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "11/11 [==============================] - 1s 930us/step\n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Supondo que 'dados' é um array numpy com seus dados de treino\n",
    "num_dados_treino = int(0.9 * len(dados))\n",
    "num_dados_teste = len(dados) - num_dados_treino\n",
    "\n",
    "# Normalizando os dados\n",
    "mu = dados[:num_dados_treino].mean()\n",
    "sig = dados[:num_dados_treino].std()\n",
    "\n",
    "dados_treino_normalizado = (dados[:num_dados_treino] - mu) / sig\n",
    "\n",
    "# Preparando as previsões\n",
    "X_treino = dados_treino_normalizado[:-1]\n",
    "Y_treino = dados_treino_normalizado[1:]\n",
    "\n",
    "# Definindo o modelo LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(None, 1), return_sequences=True))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()\n",
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(X_treino, Y_treino, epochs=1000, batch_size=32, verbose=0)\n",
    "\n",
    "# Fazendo previsões\n",
    "previsoes = model.predict(X_treino)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
