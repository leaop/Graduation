{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 16 - Autoencoders\n",
    "\n",
    "## Fundamentos e Aplicações de Autoencoders\n",
    "\n",
    "### O que são Autoencoders?\n",
    "- **Definição:** \n",
    "  - Redes neurais usadas para aprender representações de dados, geralmente para redução de dimensionalidade. Elas tentam capturar as características mais importantes dos dados de entrada, de modo a poder reconstruí-los com boa precisão.\n",
    "- **Arquitetura:** \n",
    "  - Composta por duas partes principais: codificador (encoder) e decodificador (decoder). O codificador transforma os dados de entrada em uma representação de menor dimensão (codificação latente), e o decodificador reconstrói os dados de entrada a partir dessa codificação.\n",
    "\n",
    "### Componentes de um Autoencoder\n",
    "- **Codificador (Encoder):**\n",
    "  - Reduz a dimensão dos dados de entrada.\n",
    "  - **Função de ativação comum:** ReLU (Rectified Linear Unit), que introduz não-linearidade ao modelo, permitindo que ele aprenda representações mais complexas.\n",
    "  - **Estrutura típica:** Composta por camadas densas (fully connected layers), onde cada camada subsequente possui menos neurônios do que a anterior, forçando a rede a aprender uma representação comprimida dos dados.\n",
    "\n",
    "- **Codificação Latente:**\n",
    "  - Representação compacta e comprimida dos dados de entrada.\n",
    "  - **Tamanho da camada latente:** Determinado pela necessidade específica da aplicação e pela quantidade de informação que deve ser retida. Deve ser um compromisso entre a capacidade de compressão e a precisão de reconstrução.\n",
    "\n",
    "- **Decodificador (Decoder):**\n",
    "  - Reconstrói os dados originais a partir da codificação latente.\n",
    "  - **Função de ativação comum:** Sigmoid ou Tanh, que são frequentemente utilizadas nas camadas finais para garantir que os valores de saída estejam no mesmo intervalo que os dados de entrada.\n",
    "  - **Estrutura típica:** Semelhante ao codificador, mas em ordem inversa. As camadas possuem um número crescente de neurônios, expandindo a codificação latente de volta ao formato original dos dados de entrada.\n",
    "\n",
    "### Processo de Treinamento\n",
    "- **Função de Custo:** \n",
    "  - O objetivo do treinamento é minimizar o erro de reconstrução, que é a diferença entre os dados de entrada e os dados reconstruídos pelo autoencoder. Uma função de custo comum é o erro quadrático médio (MSE - Mean Squared Error).\n",
    "  - **Erro de reconstrução:** Mede o quanto os dados de saída se desviam dos dados de entrada.\n",
    "\n",
    "- **Algoritmo de Otimização:**\n",
    "  - Uso do algoritmo de descida do gradiente (Gradient Descent) para ajustar os pesos da rede neural de forma a minimizar a função de custo.\n",
    "  - **Learning rate:** Taxa de aprendizado que controla o tamanho dos passos dados na direção do gradiente negativo. Um learning rate adequado é crucial para garantir a convergência eficiente e estável do modelo.\n",
    "\n",
    "### Aplicações de Autoencoders\n",
    "- **Redução de Dimensionalidade:** \n",
    "  - Extração de características principais dos dados de entrada, facilitando a visualização, compressão e análise dos dados.\n",
    "  - Compressão de dados, permitindo armazenar grandes volumes de dados em um formato mais compacto.\n",
    "\n",
    "- **Detecção de Anomalias:**\n",
    "  - Identificação de dados que não se ajustam ao padrão normal, com base no erro de reconstrução. Dados que resultam em alto erro de reconstrução podem ser considerados anômalos.\n",
    "\n",
    "- **Pré-treinamento para Redes Neurais Profundas:**\n",
    "  - Inicialização de pesos para outras redes neurais, melhorando a eficiência e a eficácia do treinamento em tarefas subsequentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de Dimensionalidade de uma Tabela com Autoencoders\n",
    "\n",
    "### Passos para Reduzir a Dimensionalidade de uma Tabela com Autoencoders\n",
    "\n",
    "#### 1. Pré-processamento dos Dados\n",
    "- **Normalização:** Escale seus dados para que todas as características estejam na mesma faixa de valores (por exemplo, entre 0 e 1).\n",
    "  - Isso ajuda o modelo a convergir mais rapidamente e a melhorar a precisão da reconstrução.\n",
    "\n",
    "#### 2. Definição do Modelo Autoencoder\n",
    "- **Codificador (Encoder):** \n",
    "  - Reduz a dimensão dos dados de entrada.\n",
    "  - **Exemplo:** Se sua tabela original tem 100 características, você pode querer reduzir para 10 características principais.\n",
    "- **Camada Latente:**\n",
    "  - A camada de codificação compacta os dados para um espaço de dimensão menor.\n",
    "  - **Exemplo:** Um vetor de 10 valores.\n",
    "- **Decodificador (Decoder):**\n",
    "  - Reconstrói os dados originais a partir da codificação latente.\n",
    "  - A estrutura do decodificador deve ser simétrica ao codificador.\n",
    "\n",
    "#### 3. Treinamento do Autoencoder\n",
    "- **Função de Custo:** \n",
    "  - Utilize uma função de custo como o erro quadrático médio (MSE) para medir a diferença entre os dados de entrada e os dados reconstruídos.\n",
    "- **Algoritmo de Otimização:**\n",
    "  - Utilize o algoritmo de descida do gradiente com uma taxa de aprendizado adequada.\n",
    "- **Treinamento:**\n",
    "  - Treine o autoencoder com seus dados até que a função de custo seja minimizada e a reconstrução seja suficientemente precisa.\n",
    "\n",
    "#### 4. Extração das Características Latentes\n",
    "- **Utilize apenas o Codificador:**\n",
    "  - Após o treinamento, utilize apenas a parte do codificador do autoencoder para transformar seus dados de entrada na representação de baixa dimensionalidade.\n",
    "- **Novo Conjunto de Dados:**\n",
    "  - O resultado será uma nova tabela com o número de características reduzido, mas preservando a maior parte da informação essencial dos dados originais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 08:33:58.310054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity_pct</th>\n",
       "      <th>Precipitation_mm</th>\n",
       "      <th>Wind_Speed_kmh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>2024-01-14 21:12:46</td>\n",
       "      <td>10.683001</td>\n",
       "      <td>41.195754</td>\n",
       "      <td>4.020119</td>\n",
       "      <td>8.233540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>2024-05-17 15:22:10</td>\n",
       "      <td>8.734140</td>\n",
       "      <td>58.319107</td>\n",
       "      <td>9.111623</td>\n",
       "      <td>27.715161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>2024-05-11 09:30:59</td>\n",
       "      <td>11.632436</td>\n",
       "      <td>38.820175</td>\n",
       "      <td>4.607511</td>\n",
       "      <td>28.732951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>2024-02-26 17:32:39</td>\n",
       "      <td>-8.628976</td>\n",
       "      <td>54.074474</td>\n",
       "      <td>3.183720</td>\n",
       "      <td>26.367303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>2024-04-29 13:23:51</td>\n",
       "      <td>39.808213</td>\n",
       "      <td>72.899908</td>\n",
       "      <td>9.598282</td>\n",
       "      <td>29.898622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location            Date_Time  Temperature_C  Humidity_pct  \\\n",
       "0     San Diego  2024-01-14 21:12:46      10.683001     41.195754   \n",
       "1     San Diego  2024-05-17 15:22:10       8.734140     58.319107   \n",
       "2     San Diego  2024-05-11 09:30:59      11.632436     38.820175   \n",
       "3  Philadelphia  2024-02-26 17:32:39      -8.628976     54.074474   \n",
       "4   San Antonio  2024-04-29 13:23:51      39.808213     72.899908   \n",
       "\n",
       "   Precipitation_mm  Wind_Speed_kmh  \n",
       "0          4.020119        8.233540  \n",
       "1          9.111623       27.715161  \n",
       "2          4.607511       28.732951  \n",
       "3          3.183720       26.367303  \n",
       "4          9.598282       29.898622  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as colunas numéricas para a normalização e o autoencoder\n",
    "numeric_columns = ['Temperature_C', 'Humidity_pct', 'Precipitation_mm', 'Wind_Speed_kmh']\n",
    "data = df[numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização dos dados\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do Autoencoder\n",
    "input_dim = data_normalized.shape[1]\n",
    "encoding_dim = 2  # Reduzir para 2 características principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a entrada do autoencoder\n",
    "# input_layer define a camada de entrada com o formato dos dados de entrada (input_dim características)\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Definindo a camada de codificação (encoder)\n",
    "# encoder é uma camada densa com encoding_dim neurônios e ativação ReLU\n",
    "# Esta camada reduz a dimensionalidade dos dados de entrada\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# Definindo a camada de decodificação (decoder)\n",
    "# decoder é uma camada densa com o mesmo número de neurônios que a camada de entrada e ativação sigmoid\n",
    "# Esta camada reconstrói os dados para o formato original\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "\n",
    "# Construindo o modelo autoencoder\n",
    "# autoencoder é o modelo que mapeia os dados de entrada para a saída reconstruída\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# Compilação do Autoencoder\n",
    "# O compilador configura o modelo para o treinamento\n",
    "# optimizer: algoritmo de otimização (Adam é um método de descida de gradiente estocástico)\n",
    "# loss: função de perda (mean_squared_error calcula o erro quadrático médio entre a entrada e a saída reconstruída)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 872us/step - loss: 0.0485\n",
      "Epoch 2/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 838us/step - loss: 0.0248\n",
      "Epoch 3/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 953us/step - loss: 0.0247\n",
      "Epoch 4/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 815us/step - loss: 0.0247\n",
      "Epoch 5/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 797us/step - loss: 0.0247\n",
      "Epoch 6/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 7/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0247\n",
      "Epoch 8/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 9/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 10/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 11/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 12/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 13/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 14/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 15/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 16/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 17/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 18/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 19/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 20/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 21/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 22/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 23/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 24/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 25/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 26/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 27/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 28/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 29/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 30/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 31/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 32/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 33/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 34/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0247\n",
      "Epoch 35/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 36/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 37/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 38/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 39/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 40/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 41/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 42/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 43/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 44/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 45/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 46/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 47/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 48/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 49/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n",
      "Epoch 50/50\n",
      "\u001b[1m3907/3907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x135f46de0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do Autoencoder\n",
    "autoencoder.fit(data_normalized, data_normalized, epochs=50, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31250/31250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 861us/step\n"
     ]
    }
   ],
   "source": [
    "# Extração da camada de codificação\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
    "data_reduced = encoder_model.predict(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar a tabela reduzida em um DataFrame\n",
    "df_reduced = pd.DataFrame(data_reduced, columns=['Feature1', 'Feature2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.697906</td>\n",
       "      <td>0.560127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.934213</td>\n",
       "      <td>1.751381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.288642</td>\n",
       "      <td>1.404904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.825730</td>\n",
       "      <td>1.616735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.357215</td>\n",
       "      <td>2.120519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature1  Feature2\n",
       "0  0.697906  0.560127\n",
       "1  0.934213  1.751381\n",
       "2  0.288642  1.404904\n",
       "3  0.825730  1.616735\n",
       "4  1.357215  2.120519"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibir as primeiras linhas da tabela reduzida\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para reconstruir as colunas originais a partir dos dados reduzidos:\n",
    "# Definir o modelo de decodificação\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]  # Última camada do autoencoder\n",
    "decoder_model = Model(inputs=encoded_input, outputs=decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31250/31250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 846us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity_pct</th>\n",
       "      <th>Precipitation_mm</th>\n",
       "      <th>Wind_Speed_kmh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.104754</td>\n",
       "      <td>40.567528</td>\n",
       "      <td>5.107385</td>\n",
       "      <td>7.435331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.582826</td>\n",
       "      <td>57.947834</td>\n",
       "      <td>5.135482</td>\n",
       "      <td>26.707541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.776352</td>\n",
       "      <td>38.975212</td>\n",
       "      <td>5.125752</td>\n",
       "      <td>27.152895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.647844</td>\n",
       "      <td>53.149559</td>\n",
       "      <td>5.132082</td>\n",
       "      <td>26.049852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.395300</td>\n",
       "      <td>74.114098</td>\n",
       "      <td>5.145144</td>\n",
       "      <td>27.556599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature_C  Humidity_pct  Precipitation_mm  Wind_Speed_kmh\n",
       "0      15.104754     40.567528          5.107385        7.435331\n",
       "1      14.582826     57.947834          5.135482       26.707541\n",
       "2      14.776352     38.975212          5.125752       27.152895\n",
       "3      14.647844     53.149559          5.132082       26.049852\n",
       "4      14.395300     74.114098          5.145144       27.556599"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reconstruir os dados originais\n",
    "data_reconstructed = decoder_model.predict(data_reduced)\n",
    "\n",
    "# Reverter a normalização\n",
    "data_reconstructed = scaler.inverse_transform(data_reconstructed)\n",
    "\n",
    "# Transformar os dados reconstruídos em um DataFrame\n",
    "df_reconstructed = pd.DataFrame(data_reconstructed, columns=numeric_columns)\n",
    "\n",
    "# Exibir as primeiras linhas da tabela reconstruída\n",
    "df_reconstructed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity_pct</th>\n",
       "      <th>Precipitation_mm</th>\n",
       "      <th>Wind_Speed_kmh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.683001</td>\n",
       "      <td>41.195754</td>\n",
       "      <td>4.020119</td>\n",
       "      <td>8.233540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.734140</td>\n",
       "      <td>58.319107</td>\n",
       "      <td>9.111623</td>\n",
       "      <td>27.715161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.632436</td>\n",
       "      <td>38.820175</td>\n",
       "      <td>4.607511</td>\n",
       "      <td>28.732951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.628976</td>\n",
       "      <td>54.074474</td>\n",
       "      <td>3.183720</td>\n",
       "      <td>26.367303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.808213</td>\n",
       "      <td>72.899908</td>\n",
       "      <td>9.598282</td>\n",
       "      <td>29.898622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature_C  Humidity_pct  Precipitation_mm  Wind_Speed_kmh\n",
       "0      10.683001     41.195754          4.020119        8.233540\n",
       "1       8.734140     58.319107          9.111623       27.715161\n",
       "2      11.632436     38.820175          4.607511       28.732951\n",
       "3      -8.628976     54.074474          3.183720       26.367303\n",
       "4      39.808213     72.899908          9.598282       29.898622"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe os dados originais\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS: Assim como em outras redes neurais, aqui também lidamos apenas com os dados numéricos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o tamanho total em memória de um DataFrame\n",
    "def memory_usage_df(df):\n",
    "    return df.memory_usage(deep=True).sum() / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de \"data\" em memória: 30.52 MB\n",
      "Tamanho de \"df_reduced\" em memória: 7.63 MB\n",
      "Tamanho de \"df_reconstructed\" em memória: 15.26 MB\n"
     ]
    }
   ],
   "source": [
    "# Tamanho em memória das variáveis\n",
    "size_data = memory_usage_df(data)\n",
    "size_df_reduced = memory_usage_df(df_reduced)\n",
    "size_df_reconstructed = memory_usage_df(df_reconstructed)\n",
    "\n",
    "\n",
    "print(f'Tamanho de \"data\" em memória: {size_data:.2f} MB')\n",
    "print(f'Tamanho de \"df_reduced\" em memória: {size_df_reduced:.2f} MB')\n",
    "print(f'Tamanho de \"df_reconstructed\" em memória: {size_df_reconstructed:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação de DataFrames Usando Métricas de Reconstrução\n",
    "\n",
    "## Função `compare_dataframes`\n",
    "\n",
    "Esta função compara dois DataFrames, um original e um reconstruído, e calcula as métricas de qualidade de reconstrução para cada coluna. As métricas calculadas são:\n",
    "- **Erro Quadrático Médio (MSE)**\n",
    "- **Erro Absoluto Médio (MAE)**\n",
    "- **Coeficiente de Determinação (R² Score)**\n",
    "\n",
    "### Parâmetros\n",
    "- `original_df` (DataFrame): O DataFrame original com os dados antes da redução de dimensionalidade.\n",
    "- `reconstructed_df` (DataFrame): O DataFrame reconstruído a partir da representação de baixa dimensionalidade.\n",
    "\n",
    "### Retorno\n",
    "- DataFrame com as colunas:\n",
    "  - `Column`: Nome da coluna.\n",
    "  - `MSE`: Erro Quadrático Médio para a coluna.\n",
    "  - `MAE`: Erro Absoluto Médio para a coluna.\n",
    "  - `R²`: Coeficiente de Determinação para a coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dataframes(original_df, reconstructed_df):\n",
    "    results = []\n",
    "    \n",
    "    for column in original_df.columns:\n",
    "        mse = mean_squared_error(original_df[column], reconstructed_df[column])\n",
    "        mae = mean_absolute_error(original_df[column], reconstructed_df[column])\n",
    "        r2 = r2_score(original_df[column], reconstructed_df[column])\n",
    "        \n",
    "        results.append({\n",
    "            'Column': column,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'R²': r2\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Column         MSE        MAE        R²\n",
      "0     Temperature_C  209.682369  12.530101  0.000295\n",
      "1      Humidity_pct    3.043488   1.420522  0.989859\n",
      "2  Precipitation_mm    8.690957   2.536440 -0.000032\n",
      "3    Wind_Speed_kmh    0.755801   0.711392  0.989930\n"
     ]
    }
   ],
   "source": [
    "# Aqui você deve ter os dataframes 'data' e 'df_reconstructed'\n",
    "comparison_results = compare_dataframes(data, df_reconstructed)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(comparison_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilização de Autoencoders com Diferentes Tipos de Dados\n",
    "\n",
    "#### Dados Numéricos Contínuos\n",
    "- **Aplicação:** Autoencoders são altamente eficazes para dados numéricos contínuos, como medidas de temperatura, umidade, preços, etc.\n",
    "- **Vantagens:** Redução de dimensionalidade, extração de características principais e compressão de dados.\n",
    "\n",
    "#### Dados Numéricos Inteiros\n",
    "- **Aplicação:** Autoencoders podem ser usados para dados inteiros que representam quantidades, como idade, contagem de itens, etc.\n",
    "- **Considerações:** Normalização pode ser necessária para melhorar a performance do autoencoder.\n",
    "\n",
    "#### Dados Numéricos que Representam Classes\n",
    "- **Aplicação:** Dados inteiros que representam categorias (como níveis educacionais, códigos de produtos) podem não ser adequados para autoencoders diretamente.\n",
    "- **Observação:** Nesses casos, técnicas de pré-processamento como one-hot encoding ou embeddings são recomendadas.\n",
    "\n",
    "#### Dados Textuais\n",
    "- **Aplicação:** Autoencoders não são diretamente aplicáveis a dados textuais brutos.\n",
    "- **Observação:** Dados textuais precisam ser convertidos em representações numéricas (como embeddings) antes de serem usados com autoencoders.\n",
    "\n",
    "### Conclusão\n",
    "Autoencoders são ferramentas poderosas para a redução de dimensionalidade e extração de características, especialmente com dados numéricos contínuos. Para dados inteiros e categóricos, transformações adicionais podem ser necessárias. Dados textuais requerem etapas de pré-processamento para serem utilizados de forma eficaz com autoencoders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios com base de dados preço de casas na California\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  \\\n",
       "0           0  8.3252      41.0  6.984127   1.023810       322.0  2.555556   \n",
       "1           1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842   \n",
       "2           2  7.2574      52.0  8.288136   1.073446       496.0  2.802260   \n",
       "3           3  5.6431      52.0  5.817352   1.073059       558.0  2.547945   \n",
       "4           4  3.8462      52.0  6.281853   1.081081       565.0  2.181467   \n",
       "\n",
       "   Latitude  Longitude  MedHouseVal  \n",
       "0     37.88    -122.23        4.526  \n",
       "1     37.86    -122.22        3.585  \n",
       "2     37.85    -122.24        3.521  \n",
       "3     37.85    -122.25        3.413  \n",
       "4     37.85    -122.25        3.422  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   20640 non-null  int64  \n",
      " 1   MedInc       20640 non-null  float64\n",
      " 2   HouseAge     20640 non-null  float64\n",
      " 3   AveRooms     20640 non-null  float64\n",
      " 4   AveBedrms    20640 non-null  float64\n",
      " 5   Population   20640 non-null  float64\n",
      " 6   AveOccup     20640 non-null  float64\n",
      " 7   Latitude     20640 non-null  float64\n",
      " 8   Longitude    20640 non-null  float64\n",
      " 9   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10319.500000</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "      <td>2.068558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5958.399114</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "      <td>1.153956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "      <td>0.149990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5159.750000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "      <td>1.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10319.500000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "      <td>1.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15479.250000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "      <td>2.647250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20639.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "      <td>5.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        MedInc      HouseAge      AveRooms     AveBedrms  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean   10319.500000      3.870671     28.639486      5.429000      1.096675   \n",
       "std     5958.399114      1.899822     12.585558      2.474173      0.473911   \n",
       "min        0.000000      0.499900      1.000000      0.846154      0.333333   \n",
       "25%     5159.750000      2.563400     18.000000      4.440716      1.006079   \n",
       "50%    10319.500000      3.534800     29.000000      5.229129      1.048780   \n",
       "75%    15479.250000      4.743250     37.000000      6.052381      1.099526   \n",
       "max    20639.000000     15.000100     52.000000    141.909091     34.066667   \n",
       "\n",
       "         Population      AveOccup      Latitude     Longitude   MedHouseVal  \n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000  \n",
       "mean    1425.476744      3.070655     35.631861   -119.569704      2.068558  \n",
       "std     1132.462122     10.386050      2.135952      2.003532      1.153956  \n",
       "min        3.000000      0.692308     32.540000   -124.350000      0.149990  \n",
       "25%      787.000000      2.429741     33.930000   -121.800000      1.196000  \n",
       "50%     1166.000000      2.818116     34.260000   -118.490000      1.797000  \n",
       "75%     1725.000000      3.282261     37.710000   -118.010000      2.647250  \n",
       "max    35682.000000   1243.333333     41.950000   -114.310000      5.000010  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Exclua as colunas 'Unnamed: 0', 'Latitude' e 'Longitude'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'Latitude', 'Longitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Normalize a base de dados com MinMaxScaler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Defina e compile um modelo de autoencoder para reduzir para 3 colunas (encoding_dim = 3).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data_normalized.shape[1]\n",
    "encoding_dim = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Treine o modelo por 50 épocas com batch_size de 64.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a entrada do autoencoder\n",
    "# input_layer define a camada de entrada com o formato dos dados de entrada (input_dim características)\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Definindo a camada de codificação (encoder)\n",
    "# encoder é uma camada densa com encoding_dim neurônios e ativação ReLU\n",
    "# Esta camada reduz a dimensionalidade dos dados de entrada\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# Definindo a camada de decodificação (decoder)\n",
    "# decoder é uma camada densa com o mesmo número de neurônios que a camada de entrada e ativação sigmoid\n",
    "# Esta camada reconstrói os dados para o formato original\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "\n",
    "# Construindo o modelo autoencoder\n",
    "# autoencoder é o modelo que mapeia os dados de entrada para a saída reconstruída\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# Compilação do Autoencoder\n",
    "# O compilador configura o modelo para o treinamento\n",
    "# optimizer: algoritmo de otimização (Adam é um método de descida de gradiente estocástico)\n",
    "# loss: função de perda (mean_squared_error calcula o erro quadrático médio entre a entrada e a saída reconstruída)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1541   \n",
      "Epoch 2/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1277\n",
      "Epoch 3/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0892\n",
      "Epoch 4/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0568\n",
      "Epoch 5/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395\n",
      "Epoch 6/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0310\n",
      "Epoch 7/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0263\n",
      "Epoch 8/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0235\n",
      "Epoch 9/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0215\n",
      "Epoch 10/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0203\n",
      "Epoch 11/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0191\n",
      "Epoch 12/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0180\n",
      "Epoch 13/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171\n",
      "Epoch 14/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0159\n",
      "Epoch 15/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149\n",
      "Epoch 16/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0138\n",
      "Epoch 17/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0126\n",
      "Epoch 18/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117\n",
      "Epoch 19/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0105\n",
      "Epoch 20/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094\n",
      "Epoch 21/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084\n",
      "Epoch 22/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075\n",
      "Epoch 23/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066\n",
      "Epoch 24/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057\n",
      "Epoch 25/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0051\n",
      "Epoch 26/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044\n",
      "Epoch 27/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039\n",
      "Epoch 28/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033\n",
      "Epoch 29/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0030\n",
      "Epoch 30/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028\n",
      "Epoch 31/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025\n",
      "Epoch 32/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0023\n",
      "Epoch 33/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0022\n",
      "Epoch 34/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0021\n",
      "Epoch 35/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020\n",
      "Epoch 36/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0019\n",
      "Epoch 37/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018\n",
      "Epoch 38/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 39/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 40/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0017\n",
      "Epoch 42/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016\n",
      "Epoch 43/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016\n",
      "Epoch 44/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015\n",
      "Epoch 46/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014\n",
      "Epoch 50/50\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13d773890>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(data_normalized, data_normalized, epochs=50, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Faça a extração da camada de codificação (previsão com o modelo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
    "data_reduced = encoder_model.predict(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Crie um DataFrame reduzido com as 3 colunas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.DataFrame(data_reduced, columns=['Feature1', 'Feature2', 'Feature3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - Defina o decodificador para converter os dados reduzidos para o formato original.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o modelo de decodificação\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]  # Última camada do autoencoder\n",
    "decoder_model = Model(inputs=encoded_input, outputs=decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - Reconstrua o DataFrame reduzido para a estrutura do original (usando as mesmas colunas).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.075545</td>\n",
       "      <td>41.557816</td>\n",
       "      <td>2.019270</td>\n",
       "      <td>0.453757</td>\n",
       "      <td>647.549805</td>\n",
       "      <td>3.935999</td>\n",
       "      <td>4.549531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.436614</td>\n",
       "      <td>19.692274</td>\n",
       "      <td>3.208966</td>\n",
       "      <td>0.534403</td>\n",
       "      <td>968.033020</td>\n",
       "      <td>7.545003</td>\n",
       "      <td>4.100762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.918516</td>\n",
       "      <td>47.491276</td>\n",
       "      <td>2.061484</td>\n",
       "      <td>0.533253</td>\n",
       "      <td>689.895386</td>\n",
       "      <td>4.195951</td>\n",
       "      <td>4.073101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.027290</td>\n",
       "      <td>47.602516</td>\n",
       "      <td>2.172661</td>\n",
       "      <td>0.584057</td>\n",
       "      <td>724.516296</td>\n",
       "      <td>4.546252</td>\n",
       "      <td>3.701489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.191662</td>\n",
       "      <td>47.656334</td>\n",
       "      <td>2.193995</td>\n",
       "      <td>0.622497</td>\n",
       "      <td>712.292175</td>\n",
       "      <td>4.548414</td>\n",
       "      <td>3.291351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MedInc   HouseAge  AveRooms  AveBedrms  Population  AveOccup  MedHouseVal\n",
       "0  8.075545  41.557816  2.019270   0.453757  647.549805  3.935999     4.549531\n",
       "1  7.436614  19.692274  3.208966   0.534403  968.033020  7.545003     4.100762\n",
       "2  5.918516  47.491276  2.061484   0.533253  689.895386  4.195951     4.073101\n",
       "3  5.027290  47.602516  2.172661   0.584057  724.516296  4.546252     3.701489\n",
       "4  4.191662  47.656334  2.193995   0.622497  712.292175  4.548414     3.291351"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reconstruir os dados originais\n",
    "data_reconstructed = decoder_model.predict(data_reduced)\n",
    "\n",
    "# Reverter a normalização\n",
    "data_reconstructed = scaler.inverse_transform(data_reconstructed)\n",
    "\n",
    "# Transformar os dados reconstruídos em um DataFrame\n",
    "df_reconstructed = pd.DataFrame(data_reconstructed, columns=df.columns)\n",
    "\n",
    "# Exibir as primeiras linhas da tabela reconstruída\n",
    "df_reconstructed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 - Exiba o tamanho em memória do DataFrame original, do DataFrame reduzido e do DataFrame reconstruído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity_pct</th>\n",
       "      <th>Precipitation_mm</th>\n",
       "      <th>Wind_Speed_kmh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.683001</td>\n",
       "      <td>41.195754</td>\n",
       "      <td>4.020119</td>\n",
       "      <td>8.233540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.734140</td>\n",
       "      <td>58.319107</td>\n",
       "      <td>9.111623</td>\n",
       "      <td>27.715161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.632436</td>\n",
       "      <td>38.820175</td>\n",
       "      <td>4.607511</td>\n",
       "      <td>28.732951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.628976</td>\n",
       "      <td>54.074474</td>\n",
       "      <td>3.183720</td>\n",
       "      <td>26.367303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.808213</td>\n",
       "      <td>72.899908</td>\n",
       "      <td>9.598282</td>\n",
       "      <td>29.898622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature_C  Humidity_pct  Precipitation_mm  Wind_Speed_kmh\n",
       "0      10.683001     41.195754          4.020119        8.233540\n",
       "1       8.734140     58.319107          9.111623       27.715161\n",
       "2      11.632436     38.820175          4.607511       28.732951\n",
       "3      -8.628976     54.074474          3.183720       26.367303\n",
       "4      39.808213     72.899908          9.598282       29.898622"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de \"df\" em memória: 1.10 MB\n",
      "Tamanho de \"df_reduced\" em memória: 0.24 MB\n",
      "Tamanho de \"df_reconstructed\" em memória: 0.55MB\n"
     ]
    }
   ],
   "source": [
    "# Tamanho em memória das variáveis\n",
    "size_data = memory_usage_df(df)\n",
    "size_df_reduced = memory_usage_df(df_reduced)\n",
    "size_df_reconstructed = memory_usage_df(df_reconstructed)\n",
    "\n",
    "\n",
    "print(f'Tamanho de \"df\" em memória: {size_data:.2f} MB')\n",
    "print(f'Tamanho de \"df_reduced\" em memória: {size_df_reduced:.2f} MB')\n",
    "print(f'Tamanho de \"df_reconstructed\" em memória: {size_df_reconstructed:.2f}MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 - Exiba as métricas comparando o DataFrame original e o reconstruído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dataframes(original_df, reconstructed_df):\n",
    "    results = []\n",
    "    \n",
    "    for column in original_df.columns:\n",
    "        mse = mean_squared_error(original_df[column], reconstructed_df[column])\n",
    "        mae = mean_absolute_error(original_df[column], reconstructed_df[column])\n",
    "        r2 = r2_score(original_df[column], reconstructed_df[column])\n",
    "        \n",
    "        results.append({\n",
    "            'Column': column,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'R²': r2\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column           MSE         MAE        R²\n",
      "0       MedInc  6.313927e-01    0.602092  0.825058\n",
      "1     HouseAge  2.387869e+00    1.101141  0.984924\n",
      "2     AveRooms  1.007373e+01    1.930842 -0.645702\n",
      "3    AveBedrms  3.802351e-01    0.359471 -0.693090\n",
      "4   Population  1.438965e+06  754.875215 -0.122080\n",
      "5     AveOccup  2.538544e+02   10.611564 -1.353450\n",
      "6  MedHouseVal  9.059733e-02    0.232371  0.931961\n"
     ]
    }
   ],
   "source": [
    "# Aqui você deve ter os dataframes 'df' e 'df_reconstructed'\n",
    "comparison_results = compare_dataframes(df, df_reconstructed)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(comparison_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
