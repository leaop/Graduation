{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 8: Técnicas de Pré-processamento de Imagens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Pré-processamento de Imagens\n",
    "\n",
    "O pré-processamento é o primeiro passo crítico no fluxo de trabalho de visão computacional e aprendizado profundo, onde preparamos as imagens para modelagem.\n",
    "\n",
    "## Definição de Pré-processamento de Imagens\n",
    "\n",
    "Pré-processamento de imagens é um termo abrangente para várias técnicas aplicadas às imagens antes de serem usadas como entrada em algoritmos de aprendizado de máquina e visão computacional. Estas técnicas podem incluir transformações simples como redimensionamento e normalização, até operações mais complexas como aumento de dados e filtragem de ruído.\n",
    "\n",
    "- **O que isso significa?**\n",
    "  - Em termos simples, o pré-processamento de imagens ajusta as imagens em um formato padrão e melhora sua qualidade para garantir que os algoritmos de aprendizado de máquina possam interpretá-las de maneira mais eficaz.\n",
    "\n",
    "## Importância do Pré-processamento de Imagens\n",
    "\n",
    "O pré-processamento não só ajuda a padronizar as entradas para nossos modelos, mas também melhora significativamente a qualidade das previsões de um modelo. Vamos discutir as principais razões da importância do pré-processamento de imagens:\n",
    "\n",
    "### Melhoria da Qualidade das Imagens\n",
    "\n",
    "- **Por que isso é importante?**\n",
    "  - A qualidade de uma imagem pode diretamente influenciar como um algoritmo percebe e entende essa imagem. Imagens de alta qualidade com características importantes bem destacadas podem ajudar algoritmos a aprender melhor e mais rápido.\n",
    "\n",
    "### Redução de Variabilidade\n",
    "\n",
    "- **O que significa variabilidade?**\n",
    "  - Variabilidade refere-se às diferenças que podem existir entre imagens no mesmo conjunto de dados. Isso pode incluir variações em tamanho, cor, iluminação, e ângulo de visão.\n",
    "- **Por que reduzir a variabilidade?**\n",
    "  - Reduzir a variabilidade ajuda a minimizar as diferenças irrelevantes para o aprendizado do modelo, permitindo que ele se concentre nas características essenciais.\n",
    "\n",
    "### Destaque de Características Importantes\n",
    "\n",
    "- **Como destacamos características importantes?**\n",
    "  - Utilizando técnicas específicas de pré-processamento, podemos realçar detalhes que são cruciais para o problema em questão. Por exemplo, em uma tarefa de reconhecimento facial, poderíamos enfatizar os contornos do rosto ou os olhos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de Pré-processamento de Imagens\n",
    "\n",
    "## 1. Redimensionamento de Imagens\n",
    "\n",
    "### Objetivo\n",
    "O objetivo do redimensionamento de imagens é padronizar todas as imagens para terem o mesmo tamanho antes de serem inseridas na rede neural. Isso é crucial porque a maioria das arquiteturas de rede neural, especialmente as Redes Neurais Convolucionais (CNNs), requer que todas as entradas tenham as mesmas dimensões. Além disso, imagens de tamanhos uniformes permitem que o modelo de aprendizado de máquina processe os dados de maneira mais eficiente e eficaz.\n",
    "\n",
    "### Métodos Comuns de Redimensionamento\n",
    "O redimensionamento pode ser realizado utilizando diferentes técnicas de interpolação. Cada método tem suas características próprias e é escolhido com base no tipo de dados e no requisito do projeto. Os métodos mais comuns incluem:\n",
    "\n",
    "#### Interpolação Bilinear\n",
    "- **Como funciona:** Este método considera os quatro pontos de dados mais próximos do ponto estimado e utiliza uma média ponderada para calcular o valor interpolado. É relativamente rápido e fornece bons resultados para a maioria das aplicações.\n",
    "\n",
    "#### Interpolação Bicúbica\n",
    "- **Como funciona:** A interpolação bicúbica é um passo adiante em relação à interpolação bilinear, considerando 16 pontos próximos (em vez de 4) para uma aproximação mais refinada. Embora seja computacionalmente mais intensiva, ela tende a manter melhor as características da imagem, especialmente em termos de suavidade das bordas.\n",
    "\n",
    "### Escolha do Método\n",
    "A escolha entre interpolação bilinear e bicúbica geralmente depende de uma compensação entre qualidade de imagem e velocidade de processamento. Para aplicações em tempo real onde a velocidade é crítica, a interpolação bilinear pode ser a melhor escolha. Por outro lado, para aplicações onde a qualidade da imagem é mais crítica, a interpolação bicúbica pode ser preferida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ler_imagem(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Esta função lê uma imagem de um caminho de arquivo e retorna como um array numpy.\n",
    "    A imagem é lida no formato de cor.\n",
    "\n",
    "    Args:\n",
    "    caminho_imagem (str): O caminho do arquivo da imagem.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: O array da imagem no espaço de cor BGR (Azul, Verde, Vermelho).\n",
    "    \"\"\"\n",
    "    # Lê a imagem usando o OpenCV\n",
    "    imagem = cv2.imread(caminho_imagem)\n",
    "    if imagem is None:\n",
    "        raise ValueError(\"Imagem não encontrada ou o caminho está incorreto\")\n",
    "    \n",
    "    return imagem\n",
    "\n",
    "def redimensionar_imagem_bilinear(caminho_imagem, dimensoes=(256, 256)):\n",
    "    \"\"\"\n",
    "    Esta função redimensiona uma imagem usando o método de interpolação bilinear.\n",
    "    \n",
    "    Args:\n",
    "    caminho_imagem (str): O caminho do arquivo da imagem.\n",
    "    dimensoes (tuple): O tamanho alvo da imagem redimensionada (largura, altura).\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: A imagem redimensionada.\n",
    "    \"\"\"\n",
    "    # Primeiro, lê a imagem do caminho fornecido\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    \n",
    "    # Redimensiona a imagem usando interpolação bilinear\n",
    "    imagem_redimensionada = cv2.resize(imagem, dimensoes, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Plota as imagens original e redimensionada para comparação\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Imagem Original')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(imagem_redimensionada, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Imagem Redimensionada (Bilinear)')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_redimensionada\n",
    "\n",
    "def redimensionar_imagem_bicubica(caminho_imagem, dimensoes=(256, 256)):\n",
    "    \"\"\"\n",
    "    Esta função redimensiona uma imagem usando o método de interpolação bicúbica.\n",
    "    \n",
    "    Args:\n",
    "    caminho_imagem (str): O caminho do arquivo da imagem.\n",
    "    dimensoes (tuple): O tamanho alvo da imagem redimensionada (largura, altura).\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: A imagem redimensionada.\n",
    "    \"\"\"\n",
    "    # Primeiro, lê a imagem do caminho fornecido\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    \n",
    "    # Redimensiona a imagem usando interpolação bicúbica\n",
    "    imagem_redimensionada = cv2.resize(imagem, dimensoes, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Plota as imagens original e redimensionada para comparação\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Imagem Original')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(imagem_redimensionada, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Imagem Redimensionada (Bicúbica)')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_redimensionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o caminho para o arquivo de imagem aqui\n",
    "caminho_imagem = \"imagens/pica_pau.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imagem_bilinear = redimensionar_imagem_bilinear(caminho_imagem, (50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imagem_bicubica = redimensionar_imagem_bicubica(caminho_imagem, (50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o caminho para o arquivo de imagem aqui\n",
    "caminho_imagem = \"imagens/naruto.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imagem_bilinear = redimensionar_imagem_bilinear(caminho_imagem, (80,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imagem_bicubica = redimensionar_imagem_bicubica(caminho_imagem, (80,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o caminho para o arquivo de imagem aqui\n",
    "caminho_imagem = \"imagens/paisagem.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imagem_bilinear = redimensionar_imagem_bilinear(caminho_imagem, (120,120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imagem_bicubica = redimensionar_imagem_bicubica(caminho_imagem, (120,120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "imagem_bilinear = redimensionar_imagem_bilinear(caminho_imagem, (240,240))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalização e Padronização\n",
    "\n",
    "### Objetivos\n",
    "Normalização e padronização são duas técnicas fundamentais de pré-processamento que ajudam a modificar os valores dos pixels das imagens para uma escala comum. Isso é crucial para que os modelos de deep learning, como as CNNs, processem os dados de maneira uniforme e eficaz.\n",
    "\n",
    "### Normalização (Min-Max Scaling)\n",
    "\n",
    "#### Descrição\n",
    "A normalização ajusta a escala dos dados de pixel para um intervalo padrão, geralmente 0 a 1. Isso é feito para garantir que os modelos não se tornem tendenciosos para certas características apenas por causa da variação nas escalas dos dados.\n",
    "\n",
    "- **Método:**\n",
    "  - Cada pixel da imagem é dividido pelo valor máximo possível (255 no caso de imagens RGB), transformando todos os valores para um intervalo entre 0 e 1.\n",
    "  \n",
    "#### Benefícios\n",
    "- Facilita a convergência do algoritmo durante o treinamento, pois os gradientes são mais estáveis.\n",
    "- Reduz a dominância de características com valores numéricos mais altos sobre aqueles com valores baixos.\n",
    "\n",
    "### Padronização (Z-score Normalization)\n",
    "\n",
    "#### Descrição\n",
    "A padronização envolve redimensionar os dados para terem uma média (μ) de 0 e um desvio padrão (σ) de 1. Este método é também conhecido como Z-score normalization.\n",
    "\n",
    "- **Método:**\n",
    "  - A média dos valores de pixel é subtraída de cada pixel e o resultado é então dividido pelo desvio padrão dos valores de pixel. Isso é feito para cada canal de cor independente.\n",
    "  \n",
    "#### Benefícios\n",
    "- Torna os dados mais consistentes e normalizados, permitindo que o modelo não seja sensível a pequenas flutuações nos dados de entrada.\n",
    "- Melhora a eficiência do algoritmo de otimização (como o gradiente descendente) ao manter todos os atributos na mesma escala.\n",
    "\n",
    "### Quando usar cada um?\n",
    "\n",
    "- **Normalização** é geralmente usada quando sabemos os valores mínimos e máximos possíveis dos dados (como pixels de uma imagem). É muito comum em imagens, pois limita os valores de pixel a um intervalo fixo [0, 1].\n",
    "  \n",
    "- **Padronização** pode ser mais apropriada quando os dados têm uma distribuição que é aproximadamente normal, mas os extremos são importantes ou quando não conhecemos os valores de escala mínima e máxima dos dados.\n",
    "\n",
    "\n",
    "Ambas as técnicas são essenciais no pré-processamento de dados para redes neurais, ajudando a normalizar ou estandardizar as variações nos dados de entrada. A escolha entre normalização e padronização depende do tipo de dados e do modelo de rede neural que está sendo utilizado. Estas técnicas garantem que o modelo seja justo e não tendencioso em relação à escala dos dados, facilitando o processo de aprendizado e melhorando a performance geral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def normalizar_imagem(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Esta função aplica a normalização Min-Max à imagem, escalando os pixels\n",
    "    para o intervalo [0, 1].\n",
    "\n",
    "    Args:\n",
    "    caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A imagem normalizada.\n",
    "    \"\"\"\n",
    "    # Primeiro, lê a imagem do caminho fornecido\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Converte a imagem para float para evitar problemas de tipo\n",
    "    imagem = imagem.astype(np.float32)\n",
    "    \n",
    "    # Aplica a normalização Min-Max\n",
    "    imagem_normalizada = imagem / 255.0\n",
    "    \n",
    "    # Exibe a imagem normalizada\n",
    "    plt.imshow(imagem_normalizada)\n",
    "    plt.title('Imagem Normalizada')\n",
    "    plt.axis('off')  # Desliga os eixos\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_normalizada\n",
    "\n",
    "def padronizar_imagem(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Esta função aplica a padronização Z-score à imagem, ajustando os pixels\n",
    "    para terem média zero e desvio padrão um.\n",
    "\n",
    "    Args:\n",
    "    caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A imagem padronizada.\n",
    "    \"\"\"\n",
    "    # Primeiro, lê a imagem do caminho fornecido\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Converte a imagem para float para facilitar cálculos\n",
    "    imagem = imagem.astype(np.float32)\n",
    "    \n",
    "    # Calcula a média e o desvio padrão da imagem\n",
    "    media = np.mean(imagem)\n",
    "    desvio_padrao = np.std(imagem)\n",
    "    \n",
    "    # Aplica a padronização Z-score\n",
    "    imagem_padronizada = (imagem - media) / desvio_padrao\n",
    "    \n",
    "    # Exibe a imagem padronizada\n",
    "    plt.imshow(imagem_padronizada)\n",
    "    plt.title('Imagem Padronizada')\n",
    "    plt.axis('off')  # Desliga os eixos\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_padronizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso:\n",
    "caminho_imagem = 'imagens/pica_pau.jpeg'\n",
    "imagem_normalizada = normalizar_imagem(caminho_imagem)\n",
    "imagem_padronizada = padronizar_imagem(caminho_imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aumento de Dados (Data Augmentation)\n",
    "\n",
    "### Objetivo\n",
    "O objetivo do aumento de dados é enriquecer o conjunto de dados de treinamento sem coletar novos dados, aplicando transformações que geram novas imagens a partir das existentes. Esta técnica é essencial para melhorar a robustez e eficácia dos modelos de deep learning, especialmente em situações com conjuntos de dados limitados.\n",
    "\n",
    "### Técnicas Utilizadas\n",
    "\n",
    "#### Transformações Geométricas\n",
    "- **Rotação:** Gira a imagem em um ângulo específico, simulando a variação na orientação do objeto visto.\n",
    "- **Translação:** Desloca a imagem em direção horizontal ou vertical, ajudando o modelo a não ser sensível à posição do objeto na imagem.\n",
    "- **Escala:** Altera o tamanho do objeto na imagem, simulando o efeito de objetos sendo mais próximos ou mais distantes da câmera.\n",
    "- **Espelhamento Horizontal/Vertical:** Inverte a imagem ao longo do eixo horizontal ou vertical, imitando a mudança na perspectiva.\n",
    "\n",
    "#### Alterações de Iluminação\n",
    "- Modificações no brilho e contraste das imagens para simular diferentes condições de iluminação.\n",
    "\n",
    "#### Cortes Aleatórios\n",
    "- **Cropping:** Corta partes da imagem aleatoriamente, o que pode ajudar o modelo a focar em diferentes características do objeto.\n",
    "\n",
    "### Benefícios do Aumento de Dados\n",
    "\n",
    "#### Aumenta a Diversidade do Conjunto de Dados\n",
    "- Ao introduzir variações nas imagens, o modelo pode aprender a reconhecer os objetos em diversas condições e perspectivas, o que é crucial para tarefas de visão computacional em ambientes reais.\n",
    "\n",
    "#### Ajuda a Evitar o Overfitting\n",
    "- O overfitting ocorre quando um modelo aprende detalhes e ruídos no conjunto de dados de treinamento ao ponto de prejudicar a performance em dados novos. Ao expandir artificialmente o conjunto de dados de treinamento, o aumento de dados permite que o modelo generalize melhor, reduzindo o risco de overfitting.\n",
    "\n",
    "#### Melhora a Generalização do Modelo\n",
    "- As redes neurais treinadas com mais exemplos podem desenvolver uma melhor generalização. Ao ver várias versões modificadas de uma mesma imagem, o modelo aprende a ignorar variações irrelevantes e a focar nas características essenciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def rotacionar_imagem(caminho_imagem, angulo, metodo_preenchimento=cv2.BORDER_CONSTANT):\n",
    "    \"\"\"\n",
    "    Rotaciona a imagem pelo ângulo especificado e permite escolher o método de preenchimento.\n",
    "    \n",
    "    Args:\n",
    "    caminho_imagem (str): O caminho para o arquivo de imagem.\n",
    "    angulo (float): O ângulo de rotação em graus.\n",
    "    metodo_preenchimento (cv2.BORDER_*): Método de preenchimento dos espaços vazios após a rotação.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: A imagem rotacionada.\n",
    "    \"\"\"\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    altura, largura = imagem.shape[:2]\n",
    "    centro = (largura // 2, altura // 2)\n",
    "    matriz_rotacao = cv2.getRotationMatrix2D(centro, angulo, 1.0)\n",
    "    imagem_rotacionada = cv2.warpAffine(imagem, matriz_rotacao, (largura, altura), borderMode=metodo_preenchimento)\n",
    "    \n",
    "    plt.imshow(imagem_rotacionada)\n",
    "    plt.title(f'Imagem Rotacionada {angulo}°')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_rotacionada\n",
    "\n",
    "def aplicar_zoom_centralizado(caminho_imagem, fator_zoom):\n",
    "    \"\"\"\n",
    "    Aplica um zoom centralizado na imagem, focando no centro e ampliando.\n",
    "    Isso cortará as bordas externas se o fator de zoom for maior que 1.\n",
    "    \n",
    "    Args:\n",
    "    caminho_imagem (str): O caminho para o arquivo de imagem.\n",
    "    fator_zoom (float): Fator de zoom (>1 para zoom in, <1 para zoom out).\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: A imagem com zoom centralizado aplicado.\n",
    "    \"\"\"\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    altura, largura = imagem.shape[:2]\n",
    "\n",
    "    # Primeiro, redimensiona a imagem com o fator de zoom especificado\n",
    "    nova_largura = int(largura * fator_zoom)\n",
    "    nova_altura = int(altura * fator_zoom)\n",
    "    imagem_redimensionada = cv2.resize(imagem, (nova_largura, nova_altura), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Agora, corta o centro da imagem redimensionada para manter o tamanho original\n",
    "    if fator_zoom >= 1:\n",
    "        inicio_x = (nova_largura - largura) // 2\n",
    "        inicio_y = (nova_altura - altura) // 2\n",
    "        imagem_zoom = imagem_redimensionada[inicio_y:inicio_y + altura, inicio_x:inicio_x + largura]\n",
    "    else:\n",
    "        borda_x = (largura - nova_largura) // 2\n",
    "        borda_y = (altura - nova_altura) // 2\n",
    "        imagem_zoom = cv2.copyMakeBorder(imagem_redimensionada, top=borda_y, bottom=borda_y, \n",
    "                                         left=borda_x, right=borda_x, borderType=cv2.BORDER_CONSTANT, \n",
    "                                         value=[0, 0, 0])\n",
    "\n",
    "    plt.imshow(imagem_zoom)\n",
    "    plt.title(f'Imagem com Zoom Centralizado {fator_zoom:.2f}x')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return imagem_zoom\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def espelhar_imagem(caminho_imagem, horizontal=True):\n",
    "    \"\"\"\n",
    "    Aplica espelhamento horizontal ou vertical na imagem.\n",
    "    \n",
    "    Args:\n",
    "    caminho_imagem (str): O caminho para o arquivo de imagem.\n",
    "    horizontal (bool): Se True, aplica espelhamento horizontal; se False, vertical.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: A imagem espelhada.\n",
    "    \"\"\"\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    # Aplica espelhamento\n",
    "    if horizontal:\n",
    "        imagem_espelhada = cv2.flip(imagem, 1)\n",
    "        titulo = 'Horizontalmente Espelhada'\n",
    "    else:\n",
    "        imagem_espelhada = cv2.flip(imagem, 0)\n",
    "        titulo = 'Verticalmente Espelhada'\n",
    "    \n",
    "    plt.imshow(imagem_espelhada)\n",
    "    plt.title(titulo)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_espelhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "caminho_imagem = 'imagens/pica_pau.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_rotacionada = rotacionar_imagem(caminho_imagem, 45, metodo_preenchimento=cv2.BORDER_REFLECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_rotacionada_constante = rotacionar_imagem(caminho_imagem, 45, metodo_preenchimento=cv2.BORDER_CONSTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_rotacionada_reflect = rotacionar_imagem(caminho_imagem, 45, metodo_preenchimento=cv2.BORDER_REFLECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_rotacionada_replicate = rotacionar_imagem(caminho_imagem, 45, metodo_preenchimento=cv2.BORDER_REPLICATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_zoom = aplicar_zoom_centralizado(caminho_imagem, 1.5)  # Zoom in de 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_espelhada = espelhar_imagem(caminho_imagem, True)  # Espelhamento horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_espelhada = espelhar_imagem(caminho_imagem, False)  # Espelhamento vertical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversão de Espaço de Cor\n",
    "\n",
    "### Objetivo\n",
    "A conversão de espaço de cor é uma técnica de pré-processamento que envolve mudar a representação de cor das imagens. Esta transformação é crucial para ajustar as imagens às necessidades específicas dos algoritmos de processamento e análise de imagens, facilitando a extração de características e a melhoria da performance dos modelos de visão computacional.\n",
    "\n",
    "### Técnicas Utilizadas\n",
    "\n",
    "#### RGB para Escala de Cinza\n",
    "\n",
    "- **Descrição:**\n",
    "  - Esta conversão reduz uma imagem RGB, que possui três canais de cor (vermelho, verde e azul), para um único canal de intensidade de cinza. Isso simplifica a análise ao reduzir a complexidade computacional dos dados.\n",
    "  \n",
    "- **Como Funciona:**\n",
    "  - A conversão geralmente utiliza uma ponderação para cada canal de cor para refletir a luminância percebida normalmente pelo olho humano. Por exemplo, uma combinação comum é 0.2989 * R + 0.5870 * G + 0.1140 * B.\n",
    "  \n",
    "- **Benefícios:**\n",
    "  - Diminuição significativa na quantidade de dados processados, o que pode acelerar outras operações de pré-processamento e análise.\n",
    "  - Concentração na informação de luminosidade, que muitas vezes é suficiente para tarefas de reconhecimento de padrões e características.\n",
    "\n",
    "#### RGB para YUV ou HSV\n",
    "\n",
    "- **Descrição:**\n",
    "  - Estas são conversões para espaços de cor que separam a luminância (ou intensidade) dos componentes de cor, o que pode ser extremamente útil para algumas aplicações de visão computacional e processamento de imagem.\n",
    "  \n",
    "- **YUV:**\n",
    "  - Separa a luminância (Y) da crominância (canais U e V). Isso é particularmente útil para compressão e redução de ruído.\n",
    "  \n",
    "- **HSV (Matiz, Saturação, Valor):**\n",
    "  - Separa a informação de cor (matiz) da intensidade (valor), com a saturação descrevendo a profundidade da cor. Este modelo é muito útil para segmentação baseada em cor e reconhecimento de objetos.\n",
    "  \n",
    "- **Benefícios:**\n",
    "  - Facilita tipos específicos de análise de imagem, como segmentação de cor e rastreamento.\n",
    "  - Permite que os modelos se concentrem nas variações de intensidade e matiz de cor independentemente do brilho, melhorando o desempenho em tarefas que são sensíveis à cor, mas não ao brilho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter_para_cinza(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Converte uma imagem RGB para escala de cinza usando a percepção de luminância do olho humano.\n",
    "    Args:\n",
    "    caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Imagem em escala de cinza.\n",
    "    \"\"\"\n",
    "    imagem_rgb = ler_imagem(caminho_imagem)\n",
    "    # Converte para escala de cinza utilizando a fórmula de luminância\n",
    "    imagem_cinza = 0.2989 * imagem_rgb[:,:,0] + 0.5870 * imagem_rgb[:,:,1] + 0.1140 * imagem_rgb[:,:,2]\n",
    "    imagem_cinza = imagem_cinza.astype(np.uint8)\n",
    "    \n",
    "    plt.imshow(imagem_cinza, cmap='gray')\n",
    "    plt.title('Imagem em Escala de Cinza')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_cinza\n",
    "\n",
    "def converter_para_yuv(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Converte uma imagem RGB para o espaço de cor YUV.\n",
    "    Args:\n",
    "    caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Imagem no espaço de cor YUV.\n",
    "    \"\"\"\n",
    "    imagem_rgb = ler_imagem(caminho_imagem)\n",
    "    imagem_yuv = cv2.cvtColor(imagem_rgb, cv2.COLOR_RGB2YUV)\n",
    "    \n",
    "    plt.imshow(imagem_yuv)\n",
    "    plt.title('Imagem em Espaço de Cor YUV')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_yuv\n",
    "\n",
    "def converter_para_hsv(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Converte uma imagem RGB para o espaço de cor HSV para facilitar a segmentação de cor.\n",
    "    Args:\n",
    "    caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Imagem no espaço de cor HSV.\n",
    "    \"\"\"\n",
    "    imagem_rgb = ler_imagem(caminho_imagem)\n",
    "    imagem_hsv = cv2.cvtColor(imagem_rgb, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    plt.imshow(imagem_hsv)\n",
    "    plt.title('Imagem em Espaço de Cor HSV')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_imagem = 'imagens/pica_pau.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_cinza = converter_para_cinza(caminho_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_yuv = converter_para_yuv(caminho_imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_hsv = converter_para_hsv(caminho_imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Binarização de Imagens\n",
    "\n",
    "### Objetivo\n",
    "Binarização é o processo de transformar uma imagem colorida ou em tons de cinza em uma imagem preto e branco, baseando-se em um limiar específico. Este método é fundamental em diversas aplicações de visão computacional, especialmente para simplificar a análise posterior da imagem e destacar características importantes.\n",
    "\n",
    "### Método: Thresholding\n",
    "\n",
    "#### Definição\n",
    "- **Thresholding** ou limiarização é uma técnica simples de segmentação de imagens. Consiste em converter uma imagem em escala de cinza para uma imagem binária, onde os pixels podem ter apenas dois possíveis valores de intensidade, tipicamente 0 (preto) e 255 (branco).\n",
    "\n",
    "#### Como Funciona\n",
    "- Um valor de limiar (threshold) é escolhido, por exemplo, 128. Todos os pixels na imagem que têm valores abaixo do limiar são convertidos para 0 (preto), e todos os pixels com valores acima do limiar são convertidos para 255 (branco).\n",
    "\n",
    "### Utilidade da Binarização\n",
    "\n",
    "#### Remoção de Pequenos Ruídos\n",
    "- Ao eliminar as variações de intensidade abaixo de um certo limiar, a binarização pode efetivamente remover pequenos ruídos presentes na imagem. Isso torna a imagem mais \"limpa\" para análises subsequentes.\n",
    "\n",
    "#### Destaque de Características\n",
    "- Características importantes que têm uma diferença de intensidade significativa comparada ao fundo podem ser mais facilmente detectadas após a binarização. Isso é particularmente útil em aplicações como reconhecimento de padrões e processamento de texto (OCR - Optical Character Recognition).\n",
    "\n",
    "### Benefícios do Thresholding\n",
    "\n",
    "- **Simplicidade:** É um método extremamente simples e rápido de processar imagens, ideal para aplicações em tempo real.\n",
    "- **Eficácia:** Apesar da sua simplicidade, pode ser incrivelmente eficaz para segmentar objetos em uma imagem, especialmente em condições controladas de iluminação.\n",
    "- **Versatilidade:** Pode ser utilizado em uma grande variedade de tarefas, desde a preparação de dados para OCR até a base para sistemas de reconhecimento de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_binarizacao_thresholding(caminho_imagem, limiar=128):\n",
    "    \"\"\"\n",
    "    Aplica binarização usando o método de Thresholding na imagem.\n",
    "    Argumentos:\n",
    "    - caminho_imagem (str): O caminho para o arquivo de imagem.\n",
    "    - limiar (int): O valor do limiar para definir o corte entre preto e branco.\n",
    "    \n",
    "    Retorna:\n",
    "    - numpy.ndarray: A imagem binarizada.\n",
    "    \"\"\"\n",
    "    # Carrega a imagem em escala de cinza\n",
    "    imagem_cinza = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    \n",
    "    # Aplica thresholding para binarizar a imagem\n",
    "    _, imagem_binarizada = cv2.threshold(imagem_cinza, limiar, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Mostra a imagem binarizada\n",
    "    plt.imshow(imagem_binarizada, cmap='gray')\n",
    "    plt.title(f'Imagem Binarizada com Limiar {limiar}')\n",
    "    plt.axis('off')  # Não mostrar os eixos\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_binarizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_binarizada = aplicar_binarizacao_thresholding(caminho_imagem, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_binarizada = aplicar_binarizacao_thresholding(caminho_imagem, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_binarizada = aplicar_binarizacao_thresholding(caminho_imagem, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_binarizada = aplicar_binarizacao_thresholding('imagens/paisagem.jpg', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_binarizada = aplicar_binarizacao_thresholding('imagens/paisagem.jpg', 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_binarizada = aplicar_binarizacao_thresholding('imagens/paisagem.jpg', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detecção de Bordas\n",
    "\n",
    "### Objetivo\n",
    "A detecção de bordas é uma técnica crucial no pré-processamento de imagens para identificar pontos numa imagem digital onde a intensidade de luminância muda drasticamente. Estas mudanças são usadas para marcar limites significativos de objetos numa imagem, o que é vital para diversas aplicações de visão computacional e reconhecimento de padrões.\n",
    "\n",
    "### Métodos: Operadores de Gradiente\n",
    "\n",
    "#### Sobel Operator\n",
    "- **Descrição:**\n",
    "  - O operador Sobel detecta bordas horizontais e verticais separadamente ou em conjunto. Utiliza dois conjuntos de máscaras convolucionais (3x3) que são aplicadas à imagem para calcular aproximações do gradiente horizontal e vertical.\n",
    "- **Utilização:**\n",
    "  - Ideal para ambientes com variação de textura moderada onde as bordas são mais definidas.\n",
    "\n",
    "#### Prewitt Operator\n",
    "- **Descrição:**\n",
    "  - Semelhante ao Sobel, o operador Prewitt também utiliza máscaras convolucionais para detectar bordas horizontais e verticais. No entanto, as máscaras do Prewitt são configuradas de maneira diferente para dar uma resposta ligeiramente mais suavizada em comparação com o Sobel.\n",
    "- **Utilização:**\n",
    "  - Utilizado quando as bordas na imagem são menos abruptas.\n",
    "\n",
    "#### Roberts Operator\n",
    "- **Descrição:**\n",
    "  - O operador de Roberts aplica um par de máscaras convolucionais 2x2 que são menos sensíveis ao ruído, mas também menos precisas na localização de bordas em comparação com Sobel e Prewitt.\n",
    "- **Utilização:**\n",
    "  - Boa escolha para imagens com alto nível de ruído onde a robustez é prioritária sobre a precisão na detecção de bordas.\n",
    "\n",
    "#### Canny Edge Detector\n",
    "- **Descrição:**\n",
    "  - Considerado um dos detectores de borda mais robustos, o Canny utiliza um algoritmo multi-etapa que inclui suavização com um filtro Gaussiano, detecção de gradientes, aplicação de um duplo limiar (thresholding) e rastreamento de bordas por histerese.\n",
    "- **Utilização:**\n",
    "  - Recomendado para situações onde é necessária alta precisão na detecção de bordas e a robustez contra ruído é crucial.\n",
    "\n",
    "### Importância da Detecção de Bordas\n",
    "\n",
    "- **Identificação de Formas e Contornos:**\n",
    "  - As bordas formam a base para o reconhecimento de objetos e a segmentação de formas dentro de uma imagem, facilitando tarefas mais complexas de visão computacional.\n",
    "  \n",
    "- **Melhoria na Análise de Imagens:**\n",
    "  - Ao destacar as bordas, reduz-se significativamente a quantidade de dados a serem processados para análises subsequentes, permitindo foco nas características mais importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_bordas_sobel(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Aplica o operador de Sobel para detectar bordas na imagem.\n",
    "    Argumentos:\n",
    "    - caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    \n",
    "    Retorna:\n",
    "    - numpy.ndarray: Imagem resultante com as bordas destacadas.\n",
    "    \"\"\"\n",
    "    imagem = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)\n",
    "    # Calcula os gradientes horizontal e vertical\n",
    "    grad_x = cv2.Sobel(imagem, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(imagem, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    # Combina os gradientes horizontal e vertical\n",
    "    sobel = cv2.magnitude(grad_x, grad_y)\n",
    "    plt.imshow(sobel, cmap='gray')\n",
    "    plt.title('Detecção de Bordas - Sobel')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return sobel\n",
    "\n",
    "def detectar_bordas_prewitt(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Aplica o operador de Prewitt para detectar bordas na imagem.\n",
    "    Argumentos:\n",
    "    - caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    \n",
    "    Retorna:\n",
    "    - numpy.ndarray: Imagem resultante com as bordas destacadas.\n",
    "    \"\"\"\n",
    "    imagem = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)\n",
    "    # Define Prewitt kernels\n",
    "    kernel_x = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
    "    kernel_y = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
    "    \n",
    "    # Filter the image using filter2D, which applies a convolution.\n",
    "    grad_x = cv2.filter2D(imagem, cv2.CV_64F, kernel_x)\n",
    "    grad_y = cv2.filter2D(imagem, cv2.CV_64F, kernel_y)\n",
    "    \n",
    "    # Convert gradients to absolute values and then to 8-bit unsigned integers\n",
    "    abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "    abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "    \n",
    "    # Combine gradients using cv2.addWeighted method to obtain final edge detected image\n",
    "    prewitt = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "    \n",
    "    plt.imshow(prewitt, cmap='gray')\n",
    "    plt.title('Detecção de Bordas - Prewitt')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return prewitt\n",
    "\n",
    "def detectar_bordas_canny(caminho_imagem, limiar_baixo=50, limiar_alto=150):\n",
    "    \"\"\"\n",
    "    Aplica o detector de bordas Canny para identificar bordas na imagem.\n",
    "    Argumentos:\n",
    "    - caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    - limiar_baixo (int): Limiar baixo para o processo de histerese.\n",
    "    - limiar_alto (int): Limiar alto para o processo de histerese.\n",
    "    \n",
    "    Retorna:\n",
    "    - numpy.ndarray: Imagem resultante com as bordas destacadas.\n",
    "    \"\"\"\n",
    "    imagem = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)\n",
    "    # Aplica o detector de bordas Canny\n",
    "    canny = cv2.Canny(imagem, limiar_baixo, limiar_alto)\n",
    "    plt.imshow(canny, cmap='gray')\n",
    "    plt.title('Detecção de Bordas - Canny')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return canny\n",
    "\n",
    "caminho_imagem = 'imagens/paisagem.jpg'\n",
    "\n",
    "bordas_sobel = detectar_bordas_sobel(caminho_imagem)\n",
    "bordas_prewitt = detectar_bordas_prewitt(caminho_imagem)\n",
    "bordas_canny = detectar_bordas_canny(caminho_imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padrão Binário Local (Local Binary Patterns - LBP)\n",
    "\n",
    "### O que é LBP?\n",
    "\n",
    "O **Padrão Binário Local (LBP)** é um descritor de textura poderoso e eficiente, conhecido por sua capacidade de classificar texturas na área de visão computacional. Originado na análise de texturas, o LBP é amplamente utilizado para reconhecimento facial e outras tarefas de reconhecimento de padrões em imagens.\n",
    "\n",
    "### Como Funciona?\n",
    "\n",
    "O LBP funciona por meio de um método simples, porém robusto:\n",
    "\n",
    "- Para cada pixel na imagem, um bairro (geralmente de tamanho 3x3) é considerado.\n",
    "- O pixel central do bairro é comparado com seus vizinhos.\n",
    "- Para cada vizinho, um bit de um novo número binário é atribuído: 1 se o vizinho é maior ou igual ao pixel central, e 0 se é menor.\n",
    "- Os bits atribuídos aos vizinhos são então combinados em um número binário (ou padrão binário), e este número é usado para representar o pixel central.\n",
    "\n",
    "### Vantagens do LBP\n",
    "\n",
    "- **Robustez a Mudanças de Iluminação:** O LBP é invariante a mudanças de iluminação, uma vez que compara apenas os valores relativos de luminância.\n",
    "- **Eficiência Computacional:** Devido à sua simplicidade, o LBP pode ser calculado rapidamente, tornando-o adequado para sistemas em tempo real.\n",
    "- **Adaptabilidade:** O LBP pode ser facilmente modificado e adaptado para melhor atender às necessidades específicas de diferentes aplicações e melhorias de desempenho.\n",
    "\n",
    "### Aplicações\n",
    "\n",
    "- **Reconhecimento Facial:** O LBP é amplamente utilizado no reconhecimento facial, onde padrões de textura da pele são importantes para identificar indivíduos.\n",
    "- **Análise de Movimento:** Usado para detectar movimentos através de mudanças nos padrões de textura.\n",
    "- **Segmentação de Imagens:** O LBP pode ajudar a segmentar diferentes partes de uma imagem com base nas texturas.\n",
    "\n",
    "O LBP tem se mostrado uma ferramenta valiosa na visão computacional, ajudando na extração eficiente de informações úteis de imagens, o que facilita uma variedade de tarefas de reconhecimento e análise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_lbp(caminho_imagem):\n",
    "    imagem = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)\n",
    "    \"\"\"\n",
    "    Calcula o Local Binary Pattern de uma imagem.\n",
    "    Argumentos:\n",
    "    - imagem (numpy.ndarray): A imagem de entrada em escala de cinza.\n",
    "    \n",
    "    Retorna:\n",
    "    - numpy.ndarray: A imagem LBP.\n",
    "    \"\"\"\n",
    "    lbp = np.zeros_like(imagem)\n",
    "    neigh = np.array([[1,  1,  1],\n",
    "                      [1, -8,  1],\n",
    "                      [1,  1,  1]])\n",
    "    \n",
    "    for i in range(1, imagem.shape[0] - 1):\n",
    "        for j in range(1, imagem.shape[1] - 1):\n",
    "            center = imagem[i, j]\n",
    "            binary = (imagem[i-1:i+2, j-1:j+2] >= center)\n",
    "            binary[1, 1] = 0  # Reset the center value\n",
    "            value = (binary * neigh).sum() + 8\n",
    "            lbp[i, j] = value\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(imagem, cmap='gray')\n",
    "    plt.title('Imagem Original')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(lbp, cmap='gray')\n",
    "    plt.title('Imagem LBP')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "imagem_lbp = calcular_lbp(caminho_imagem)\n",
    "imagem_lbp = calcular_lbp('imagens/pica_pau.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Filtragem de Imagens\n",
    "\n",
    "### Objetivo\n",
    "O objetivo da filtragem de imagens é suavizar, realçar, ou remover ruídos de uma imagem. Filtragem é uma técnica crucial no pré-processamento de imagens para melhorar a qualidade visual das imagens ou para prepará-las para análises computacionais e operações de nível superior, como detecção de bordas e reconhecimento de padrões.\n",
    "\n",
    "### Métodos de Filtragem Utilizados\n",
    "\n",
    "#### Filtros Gaussianos\n",
    "\n",
    "- **Descrição:**\n",
    "  - O filtro Gaussiano é utilizado para suavizar a imagem e reduzir detalhes e ruídos. Ele funciona convolvendo a imagem com um kernel Gaussiano que representa uma função Gaussiana (curva em forma de sino).\n",
    "  \n",
    "- **Aplicações:**\n",
    "  - Útil para remover ruídos e suavizar texturas dentro de uma imagem sem perder demasiados detalhes de bordas.\n",
    "  \n",
    "#### Filtros de Média\n",
    "\n",
    "- **Descrição:**\n",
    "  - Este filtro suaviza a imagem substituindo cada pixel pela média dos pixels em sua vizinhança definida pelo kernel. O filtro de média é um exemplo simples de um filtro passa-baixa.\n",
    "  \n",
    "- **Aplicações:**\n",
    "  - Bom para reduzir ruído aleatório da imagem, especialmente útil em imagens onde o ruído é distribuído uniformemente.\n",
    "\n",
    "#### Filtros de Mediana\n",
    "\n",
    "- **Descrição:**\n",
    "  - Similar ao filtro de média, mas substitui cada pixel pelo valor mediano dos pixels no kernel ao invés da média. Isso ajuda a preservar bordas nítidas na imagem enquanto ainda reduz o ruído.\n",
    "  \n",
    "- **Aplicações:**\n",
    "  - Eficiente para remover ruído de \"sal e pimenta\" e é frequentemente usado em aplicações de processamento de imagem digital onde a preservação de bordas é crucial.\n",
    "\n",
    "### Benefícios da Filtragem\n",
    "\n",
    "- **Suavização de Imagem:**\n",
    "  - Ajuda a reduzir a variação de intensidade entre os pixels, o que pode facilitar a segmentação e outras operações de processamento de imagem.\n",
    "  \n",
    "- **Remoção de Ruído:**\n",
    "  - Elimina variações indesejadas de pixel que não são parte do objeto de interesse na imagem, o que melhora a análise visual e computacional.\n",
    "  \n",
    "- **Preparação para Operações de Nível Superior:**\n",
    "  - Imagens que são suavizadas e livres de ruídos são mais fáceis de processar em tarefas subsequentes como detecção de bordas e reconhecimento de padrões, pois as características irrelevantes são minimizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_filtro_gaussiano(caminho_imagem, tamanho_kernel=5):\n",
    "    \"\"\"\n",
    "    Aplica um filtro Gaussiano para suavizar a imagem.\n",
    "    Argumentos:\n",
    "    - caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    - tamanho_kernel (int): Tamanho do kernel Gaussiano; deve ser um número ímpar.\n",
    "    \n",
    "    Retorna:\n",
    "    - numpy.ndarray: A imagem suavizada.\n",
    "    \"\"\"\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    imagem_suavizada = cv2.GaussianBlur(imagem, (tamanho_kernel, tamanho_kernel), 0)\n",
    "    \n",
    "    plt.imshow(imagem_suavizada)\n",
    "    plt.title('Imagem com Filtro Gaussiano')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_suavizada\n",
    "\n",
    "def aplicar_filtro_media(caminho_imagem, tamanho_kernel=5):\n",
    "    \"\"\"\n",
    "    Aplica um filtro de média para reduzir o ruído na imagem.\n",
    "    Argumentos:\n",
    "    - caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    - tamanho_kernel (int): Tamanho do kernel; deve ser um número ímpar.\n",
    "    \n",
    "    Retorna:\n",
    "    - numpy.ndarray: A imagem com ruído reduzido.\n",
    "    \"\"\"\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    imagem_suavizada = cv2.blur(imagem, (tamanho_kernel, tamanho_kernel))\n",
    "    \n",
    "    plt.imshow(imagem_suavizada)\n",
    "    plt.title('Imagem com Filtro de Média')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_suavizada\n",
    "\n",
    "def aplicar_filtro_mediana(caminho_imagem, tamanho_kernel=5):\n",
    "    \"\"\"\n",
    "    Aplica um filtro de mediana para reduzir o ruído.\n",
    "    Argumentos:\n",
    "    - caminho_imagem (str): Caminho para o arquivo de imagem.\n",
    "    - tamanho_kernel (int): Tamanho do kernel; deve ser um número ímpar.\n",
    "    \n",
    "    Retorna:\n",
    "    - numpy.ndarray: A imagem com ruído reduzido.\n",
    "    \"\"\"\n",
    "    imagem = ler_imagem(caminho_imagem)\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    imagem_suavizada = cv2.medianBlur(imagem, tamanho_kernel)\n",
    "    \n",
    "    plt.imshow(imagem_suavizada)\n",
    "    plt.title('Imagem com Filtro de Mediana')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return imagem_suavizada\n",
    "\n",
    "caminho_imagem = 'imagens/paisagem.jpg'\n",
    "imagem_gauss = aplicar_filtro_gaussiano(caminho_imagem, 1)\n",
    "imagem_gauss = aplicar_filtro_gaussiano(caminho_imagem, 25)\n",
    "imagem_media = aplicar_filtro_media(caminho_imagem, 25)\n",
    "imagem_mediana = aplicar_filtro_mediana(caminho_imagem, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício de Processamento de Imagens\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Este exercício visa aplicar várias técnicas de processamento de imagens em um conjunto de dados organizado de imagens de animais. As imagens serão transformadas usando diferentes métodos e salvas em pastas correspondentes para análise futura.\n",
    "\n",
    "## Estrutura de Diretórios\n",
    "\n",
    "- **imagens/**\n",
    "  - **animais/**\n",
    "    - **nome_do_animal/** (aproximadamente 130 imagens cada)\n",
    "\n",
    "## Tarefas de Processamento\n",
    "\n",
    "### 1. Preparação das Imagens\n",
    "\n",
    "Primeiramente, você deverá ler todas as imagens na pasta `animais`, redimensionar cada imagem para 70x70 pixels e converter para escala de cinza. \n",
    "\n",
    "- **Saída Esperada:**\n",
    "  - Salve estas imagens na pasta `animais_preto_branco`, preservando a organização em subpastas por animal.\n",
    "\n",
    "### 2. Binarização das Imagens\n",
    "\n",
    "Após redimensionar, aplique a técnica de binarização com um threshold de 128 nas imagens coloridas originais redimensionadas.\n",
    "\n",
    "- **Saída Esperada:**\n",
    "  - Crie e salve essas imagens na pasta `animais_binarizados_threshold_128`, mantendo a estrutura de subpastas por animal.\n",
    "\n",
    "### 3. Detecção de Bordas\n",
    "\n",
    "Utilize o operador de Prewitt para detectar bordas nas imagens coloridas redimensionadas.\n",
    "\n",
    "- **Saída Esperada:**\n",
    "  - Salve os resultados na pasta `animais_bordas_prewitt`.\n",
    "\n",
    "### 4. Local Binary Patterns (LBP)\n",
    "\n",
    "Calcule o Local Binary Pattern para cada imagem na escala de cinza e salve os resultados.\n",
    "\n",
    "- **Saída Esperada:**\n",
    "  - As imagens processadas devem ser armazenadas na pasta `animais_lbp`.\n",
    "\n",
    "### 5. Filtro de Mediana\n",
    "\n",
    "Aplique um filtro de mediana nas imagens em escala de cinza para suavizar a imagem preservando as bordas.\n",
    "\n",
    "- **Saída Esperada:**\n",
    "  - Salve estas imagens na pasta `animais_filtro_mediana`.\n",
    "\n",
    "### 6. Filtro de Média\n",
    "\n",
    "Finalmente, aplique um filtro de média para suavizar as imagens em escala de cinza.\n",
    "\n",
    "- **Saída Esperada:**\n",
    "  - As imagens resultantes devem ser guardadas na pasta `animais_filtro_media`.\n",
    "\n",
    "``Este exercício é para ser apresentado até terça feira que vem e irá compor parte da nota de exercícios.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
