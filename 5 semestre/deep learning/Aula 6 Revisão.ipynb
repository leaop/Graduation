{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilização das RNAs em Aprendizado Supervisionado\n",
    "\n",
    "As Redes Neurais Artificiais (RNAs) são amplamente utilizadas em tarefas de aprendizado supervisionado, especialmente em problemas de classificação e regressão. Abaixo iremos ver detalhadamente como as RNAs são aplicadas a essas tarefas, destacando a estrutura e abordagens específicas para cada tipo de problema.\n",
    "\n",
    "## Classificação\n",
    "Classificação é uma das principais tarefas em aprendizado de máquina e Deep Learning, onde o objetivo é categorizar os dados de entrada em classes pré-definidas.\n",
    "\n",
    "### Classificação Binária\n",
    "- **Objetivo**: Prever duas classes exclusivas (0 ou 1, verdadeiro ou falso, sim ou não).\n",
    "- **Exemplos de Aplicação**: Detecção de spam em e-mails, diagnóstico médico (doença presente ou ausente), aprovação de crédito.\n",
    "\n",
    "### Classificação Multiclasse\n",
    "- **Objetivo**: Prever entre três ou mais classes que são mutuamente exclusivas.\n",
    "- **Exemplos de Aplicação**: Classificação de tipos de flores, identificação de dígitos escritos à mão, categorização de notícias.\n",
    "\n",
    "### Considerações Específicas\n",
    "- **Representação do Target**: Em classificação multiclasse, o target é geralmente representado em formato \"one-hot encoding\" para que cada classe seja representada por um vetor binário. (iremos ver isto em códigos mais a frente)\n",
    "- **Função de Ativação na Camada de Saída**:\n",
    "  - **Binária**: Utiliza-se a função sigmoid, que fornece uma saída entre 0 e 1, representando a probabilidade da classe positiva.\n",
    "  - **Multiclasse**: Emprega-se a função softmax, que generaliza a função sigmoid para múltiplas classes, fornecendo uma distribuição de probabilidade sobre as várias classes.\n",
    "\n",
    "## Regressão\n",
    "Em contraste com a classificação, a regressão lida com a previsão de um valor contínuo.\n",
    "\n",
    "### Objetivo\n",
    "- Prever uma quantidade contínua a partir de variáveis de entrada.\n",
    "- **Exemplos de Aplicação**: Previsão de preços de imóveis, estimativa de demanda de produtos, previsão de índices de poluição.\n",
    "\n",
    "### Considerações Específicas\n",
    "- **Representação do Target**: O target é um valor numérico contínuo.\n",
    "- **Função de Ativação na Camada de Saída**: Geralmente usa-se a função de ativação linear (ou identidade) que permite que a rede possa prever valores em uma ampla gama.\n",
    "\n",
    "## Abordagens Comuns\n",
    "- **Preparação dos Dados**: Independente do tipo de tarefa, é crucial a preparação e pré-processamento adequados dos dados, incluindo normalização ou padronização dos recursos de entrada e, no caso de classificação multiclasse, a aplicação de \"one-hot encoding\" ao target.\n",
    "- **Escolha da Função de Perda**:\n",
    "  - **Classificação**: binary_crossentropy (binária) ou categorical_crossentropy (multiclasse).\n",
    "  - **Regressão**: mean_squared_error, mean_absolute_error, entre outras métricas para regressão.\n",
    "- **Seleção do Otimizador**: Otimizadores como Adam e SGD são comumente utilizados, ajustando os pesos da rede durante o treinamento para minimizar a função de perda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estrutura de uma Rede Neural Artificial\n",
    "\n",
    "A arquitetura fundamental de uma Rede Neural Artificial é dividida em três partes principais: a camada de entrada, as camadas ocultas, e a camada de saída. Cada uma dessas partes desempenha um papel crucial no aprendizado de padrões complexos dos dados.\n",
    "\n",
    "## Camada de Entrada\n",
    "\n",
    "- **Quantidade de Colunas do X (Features)**: A camada de entrada é a primeira interface da rede com os dados. O número de neurônios nesta camada deve ser igual ao número de características (features) dos dados de entrada. Cada neurônio nesta camada representa uma variável de entrada independente.\n",
    "\n",
    "## Camadas Ocultas\n",
    "\n",
    "### Função de Ativação\n",
    "\n",
    "- As camadas ocultas são responsáveis por transformar os sinais de entrada em algo que a camada de saída possa usar para realizar a tarefa desejada (por exemplo, classificação ou regressão). As funções de ativação ajudam a introduzir não-linearidade no modelo, permitindo que a rede aprenda padrões complexos e abstrações.\n",
    "- **Tipos Comuns de Funções de Ativação**:\n",
    "  - **ReLU (Rectified Linear Unit)**: Permite passar valores positivos enquanto os valores negativos são ajustados para zero. É a função de ativação mais utilizada devido à sua eficiência computacional e capacidade de mitigar o problema do desvanecimento do gradiente em redes profundas.\n",
    "  - **Sigmoid**: Transforma os valores de entrada para um intervalo entre 0 e 1. É comumente usada na última camada de redes destinadas à classificação binária, devido à sua interpretação probabilística.\n",
    "  - **Tanh (Hyperbolic Tangent)**: Similar à função sigmoid, mas transforma os valores para um intervalo entre -1 e 1. Frequentemente usada nas camadas ocultas pela sua capacidade de centralizar os dados de saída.\n",
    "\n",
    "### Quantidade de Neurônios\n",
    "\n",
    "- A quantidade de neurônios em cada camada oculta é um fator determinante na capacidade da rede de capturar a complexidade dos dados. Um número maior de neurônios pode aumentar a capacidade da rede de aprender, mas também pode levar a um maior risco de overfitting.\n",
    "- **Determinação da Quantidade de Neurônios**: Não existe uma regra exata para a escolha do número de neurônios nas camadas ocultas; essa decisão é geralmente baseada na experiência, experimentação e validação cruzada.\n",
    "\n",
    "## Camada de Saída\n",
    "\n",
    "### Classificação Binária\n",
    "\n",
    "- **Quantidade de Neurônios**: 1. Um único neurônio é suficiente para modelar a probabilidade de a entrada pertencer a uma das duas classes.\n",
    "- **Função de Ativação**: Sigmoid. Esta função é ideal para problemas de classificação binária, pois mapeia a saída do modelo para um valor entre 0 e 1, que pode ser interpretado como a probabilidade da classe positiva.\n",
    "\n",
    "### Classificação Multiclasse\n",
    "\n",
    "- **Quantidade de Neurônios**: Número de classes. Cada neurônio na camada de saída representa uma classe única, e a rede deve prever a qual classe a entrada pertence.\n",
    "- **Função de Ativação**: Softmax. A função softmax é adequada para classificação multiclasse, pois ela normaliza as saídas para uma distribuição de probabilidade sobre as classes, garantindo que a soma das probabilidades de todas as classes seja 1.\n",
    "\n",
    "### Regressão\n",
    "\n",
    "- **Quantidade de Neurônios**: 1. Para tarefas de regressão, um único neurônio é suficiente, pois o objetivo é prever um valor contínuo.\n",
    "- **Função de Ativação**: Linear (ou nenhuma função de ativação especificada). A função linear é a escolha padrão para problemas de regressão, pois permite que a rede produza uma gama de valores contínuos sem restringir a saída a um intervalo específico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o input_dim representa quantas colunas tem o X\n",
    "input_dim = 3\n",
    "\n",
    "# Modelo para Classificação Binária\n",
    "modelo_classificacao_binaria = models.Sequential([\n",
    "    # Camada de entrada definida na primeira camada oculta\n",
    "    layers.Dense(128, activation='relu', input_shape=(input_dim,)),  # input_dim é a quantidade de features\n",
    "    # Camadas ocultas\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    # Camada de saída para classificação binária com 1 neurônio e função de ativação sigmoid\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Modelo para Classificação Multiclasse (5 classes)\n",
    "modelo_classificacao_multiclasse = models.Sequential([\n",
    "    # Camada de entrada definida na primeira camada oculta\n",
    "    layers.Dense(128, activation='relu', input_shape=(input_dim,)),  # input_dim é a quantidade de features\n",
    "    # Camadas ocultas\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    # Camada de saída para classificação multiclasse com 5 neurônios (uma por classe)\n",
    "    # e função de ativação softmax para distribuição de probabilidade entre as classes\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Modelo para Regressão\n",
    "modelo_regressao = models.Sequential([\n",
    "    # Camada de entrada definida na primeira camada oculta\n",
    "    layers.Dense(128, activation='relu', input_shape=(input_dim,)),  # input_dim é a quantidade de features\n",
    "    # Camadas ocultas\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    # Camada de saída para regressão com 1 neurônio\n",
    "    # Função de ativação linear é usada para previsão de valores contínuos\n",
    "    layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de Dados Antes do Treinamento\n",
    "\n",
    "O tratamento adequado dos dados antes do treinamento de Redes Neurais Artificiais é crucial para o desempenho e eficácia do modelo. Este processo inclui a separação dos dados, normalização, e transformações específicas para tarefas de classificação ou regressão.\n",
    "\n",
    "## Separação dos Dados em X e y\n",
    "\n",
    "- **X (Features)**: Conjunto de características ou variáveis independentes que são usadas como entrada para o modelo.\n",
    "- **y (Target)**: Variável dependente que o modelo tenta prever. Representa as labels ou valores de saída correspondentes às entradas.\n",
    "\n",
    "## Separação dos Dados de Treinamento, Validação e Teste\n",
    "\n",
    "### Conceito de Validação\n",
    "\n",
    "- A validação é o processo de avaliar a eficácia de um modelo usando dados que não foram vistos durante o treinamento. \n",
    "\n",
    "### Processo de Separação\n",
    "\n",
    "- Os dados são divididos em conjuntos de treinamento, validação e teste.\n",
    "  - **Treinamento**: Usado para ajustar os pesos do modelo.\n",
    "  - **Validação**: Usado para ajustar os hiperparâmetros e evitar o overfitting.\n",
    "  - **Teste**: Usado para avaliar a performance final do modelo.\n",
    "\n",
    "## Normalização dos Dados\n",
    "\n",
    "### Importância da Normalização para RNAs\n",
    "\n",
    "- A normalização ajuda a garantir que todos os inputs do modelo estejam em uma escala similar, facilitando a convergência durante o treinamento e melhorando o desempenho geral.\n",
    "\n",
    "### Uso do MinMax Scaler com Função de Ativação ReLU\n",
    "\n",
    "- **MinMax Scaler**: Escala cada característica para um intervalo especificado, geralmente entre 0 e 1.\n",
    "- Usar o MinMax Scaler é particularmente benéfico com a função de ativação ReLU para evitar valores negativos que poderiam inativar os neurônios.\n",
    "\n",
    "### Aplicação da Normalização\n",
    "\n",
    "- **fit_transform**: Usado no conjunto de treinamento para calcular os parâmetros de escala e aplicar a transformação.\n",
    "- **transform**: Usado nos conjuntos de validação e teste para aplicar a mesma transformação do conjunto de treinamento, garantindo a consistência entre os dados.\n",
    "\n",
    "## Classificação\n",
    "\n",
    "### Normalização Apenas do X\n",
    "\n",
    "- Para tarefas de classificação, normalmente apenas os dados de entrada (X) são normalizados, enquanto os labels (y) são transformados conforme a necessidade do problema.\n",
    "\n",
    "### Transformação do y para Categórico\n",
    "\n",
    "- Em classificações multiclasse, os labels são frequentemente convertidos para o formato categórico (one-hot encoding) para facilitar o treinamento e avaliação do modelo.\n",
    "\n",
    "### Classificação Binária\n",
    "\n",
    "- Para classificação binária, o y é mantido como está, geralmente codificado como 0 ou 1, representando as duas classes.\n",
    "\n",
    "## Regressão\n",
    "\n",
    "### Normalização de X e y\n",
    "\n",
    "- Tanto os dados de entrada quanto os de saída são normalizados para melhorar a estabilidade e a eficiência do treinamento.\n",
    "\n",
    "### Uso de um Scaler para X e Outro para y\n",
    "\n",
    "- Normalmente, utilizam-se escaladores separados para X e y, permitindo que cada conjunto de dados seja normalizado de maneira adequada e independente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de dados hipotéticos para Classificação Multiclasse\n",
    "dados_multiclasse = pd.DataFrame({\n",
    "    'feature1': np.random.rand(100),\n",
    "    'feature2': np.random.rand(100),\n",
    "    'feature3': np.random.rand(100),\n",
    "    'classe': np.random.randint(0, 5, 100)  # 5 classes diferentes\n",
    "})\n",
    "dados_multiclasse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados em X e y para Classificação Multiclasse\n",
    "X_multiclasse = dados_multiclasse.drop('classe', axis=1)\n",
    "y_multiclasse = dados_multiclasse['classe']\n",
    "\n",
    "# Divisão dos dados em treino, validação e teste\n",
    "X_treino_multi, X_teste_multi, y_treino_multi, y_teste_multi = train_test_split(X_multiclasse, y_multiclasse, test_size=0.2, random_state=42)\n",
    "X_treino_multi, X_validacao_multi, y_treino_multi, y_validacao_multi = train_test_split(X_treino_multi, y_treino_multi, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Normalização dos dados de entrada\n",
    "scaler_multi = MinMaxScaler()\n",
    "X_treino_multi_scaled = scaler_multi.fit_transform(X_treino_multi)\n",
    "X_validacao_multi_scaled = scaler_multi.transform(X_validacao_multi)\n",
    "X_teste_multi_scaled = scaler_multi.transform(X_teste_multi)\n",
    "\n",
    "# Transformação dos labels em one-hot encoding para Classificação Multiclasse\n",
    "encoder = OneHotEncoder()\n",
    "y_treino_multi_encoded = encoder.fit_transform(y_treino_multi.values.reshape(-1, 1)).toarray()\n",
    "y_validacao_multi_encoded = encoder.transform(y_validacao_multi.values.reshape(-1, 1)).toarray()\n",
    "y_teste_multi_encoded = encoder.transform(y_teste_multi.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste_multi_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de dados hipotéticos para Classificação Binária\n",
    "dados_binarios = pd.DataFrame({\n",
    "    'feature1': np.random.rand(100),\n",
    "    'feature2': np.random.rand(100),\n",
    "    'feature3': np.random.rand(100),\n",
    "    'classe': np.random.randint(0, 2, 100)  # 2 classes diferentes\n",
    "})\n",
    "dados_binarios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados em X e y para Classificação Binária\n",
    "X_binarios = dados_binarios.drop('classe', axis=1)\n",
    "y_binarios = dados_binarios['classe']\n",
    "\n",
    "# Divisão dos dados em treino, validação e teste\n",
    "X_treino_bin, X_teste_bin, y_treino_bin, y_teste_bin = train_test_split(X_binarios, y_binarios, test_size=0.2, random_state=42)\n",
    "X_treino_bin, X_validacao_bin, y_treino_bin, y_validacao_bin = train_test_split(X_treino_bin, y_treino_bin, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Normalização dos dados de entrada\n",
    "scaler_bin = MinMaxScaler()\n",
    "X_treino_bin_scaled = scaler_bin.fit_transform(X_treino_bin)\n",
    "X_validacao_bin_scaled = scaler_bin.transform(X_validacao_bin)\n",
    "X_teste_bin_scaled = scaler_bin.transform(X_teste_bin)\n",
    "\n",
    "# Não é necessário transformar y para Classificação Binária, pois já está no formato adequado (0 ou 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de dados hipotéticos para Regressão\n",
    "dados_regressao = pd.DataFrame({\n",
    "    'feature1': np.random.rand(100),\n",
    "    'feature2': np.random.rand(100),\n",
    "    'feature3': np.random.rand(100),\n",
    "    'valor': np.random.rand(100) * 100  # Valores contínuos\n",
    "})\n",
    "dados_regressao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados em X e y para Regressão\n",
    "X_regressao = dados_regressao.drop('valor', axis=1)\n",
    "y_regressao = dados_regressao['valor']\n",
    "\n",
    "# Divisão dos dados em treino, validação e teste\n",
    "X_treino_reg, X_teste_reg, y_treino_reg, y_teste_reg = train_test_split(X_regressao, y_regressao, test_size=0.2, random_state=42)\n",
    "X_treino_reg, X_validacao_reg, y_treino_reg, y_validacao_reg = train_test_split(X_treino_reg, y_treino_reg, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Normalização dos dados de entrada para Regressão\n",
    "scaler_reg_X = MinMaxScaler()\n",
    "X_treino_reg_scaled = scaler_reg_X.fit_transform(X_treino_reg)\n",
    "X_validacao_reg_scaled = scaler_reg_X.transform(X_validacao_reg)\n",
    "X_teste_reg_scaled = scaler_reg_X.transform(X_teste_reg)\n",
    "\n",
    "# Normalização dos dados de saída (y) para Regressão\n",
    "scaler_reg_y = MinMaxScaler()\n",
    "y_treino_reg_scaled = scaler_reg_y.fit_transform(y_treino_reg.values.reshape(-1, 1))\n",
    "y_validacao_reg_scaled = scaler_reg_y.transform(y_validacao_reg.values.reshape(-1, 1))\n",
    "y_teste_reg_scaled = scaler_reg_y.transform(y_teste_reg.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilação do Modelo\n",
    "\n",
    "A compilação do modelo em Redes Neurais Artificiais é um passo crucial que prepara o modelo para o treinamento. Nesta fase, definimos a função de perda (loss), as métricas de avaliação e o otimizador. Além disso, podemos especificar técnicas de otimização adicionais para melhorar o desempenho do modelo durante o treinamento.\n",
    "\n",
    "## Loss\n",
    "\n",
    "A função de perda mede quão bem o modelo está performando durante o treinamento, fornecendo um valor numérico que o otimizador tenta minimizar.\n",
    "\n",
    "### Classificação Binária\n",
    "\n",
    "- **binary_crossentropy**: Utilizada quando há apenas duas classes de labels. Mede o desempenho de um modelo de classificação cuja saída é um valor de probabilidade entre 0 e 1.\n",
    "\n",
    "### Classificação Multiclasse\n",
    "\n",
    "- **categorical_crossentropy**: Aplicada em problemas de classificação onde há duas ou mais classes de labels. Requer que as labels sejam fornecidas em um formato categórico (geralmente one-hot encoded).\n",
    "\n",
    "### Regressão\n",
    "\n",
    "- **mean_squared_error (MSE)**: Utilizada para problemas de regressão, mede a média dos quadrados das diferenças entre os valores preditos e os reais.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Métricas são usadas para monitorar e avaliar o desempenho do modelo durante o treinamento e teste.\n",
    "\n",
    "### Classificação\n",
    "\n",
    "- **accuracy**: Mede a porcentagem de labels corretamente preditas pelo modelo. É a métrica mais comum para problemas de classificação.\n",
    "\n",
    "### Regressão\n",
    "\n",
    "- **mse (Mean Squared Error)**: Média dos quadrados das diferenças entre os valores preditos e os valores reais.\n",
    "- **rmse (Root Mean Squared Error)**: Raiz quadrada do MSE, fornece uma medida da magnitude do erro na mesma unidade dos valores preditos.\n",
    "- **mae (Mean Absolute Error)**: Média do valor absoluto das diferenças entre os valores preditos e os reais. Fornece uma ideia da magnitude do erro sem considerar sua direção.\n",
    "\n",
    "## Otimizadores\n",
    "\n",
    "Os otimizadores ajustam os pesos da rede com base nos dados de entrada e na função de perda para minimizar o erro.\n",
    "\n",
    "- **Adam**: Um otimizador baseado em gradiente que adapta a taxa de aprendizado para cada peso do modelo, considerado eficiente e eficaz para uma grande variedade de problemas.\n",
    "- **SGD (Stochastic Gradient Descent)**: Um dos otimizadores mais simples e mais utilizados. Atualiza os pesos de forma iterativa em direção ao gradiente da função de perda.\n",
    "\n",
    "# Treinamento\n",
    "\n",
    "O treinamento de uma Rede Neural Artificial envolve a utilização de conjuntos de dados específicos para treino e validação, além do uso de callbacks para otimização do processo de treinamento e monitoramento do desempenho do modelo através do histórico de treinamento.\n",
    "\n",
    "## Utilização de X e y de Treinamento e Validação\n",
    "\n",
    "- **X de Treinamento**: Conjunto de dados de entrada usados para treinar o modelo. Cada elemento de X corresponde a uma observação completa das características (features) usadas para previsão.\n",
    "- **y de Treinamento**: Conjunto de dados de saída ou labels correspondentes ao X de treinamento. Representa a verdade fundamental que o modelo tenta aprender durante o treinamento.\n",
    "- **X de Validação**: Conjunto de dados de entrada usados para validar a precisão do modelo durante o treinamento. Não é usado para ajustar os pesos do modelo, mas para avaliar sua performance.\n",
    "- **y de Validação**: Conjunto de dados de saída ou labels correspondentes ao X de validação. Usado junto ao X de validação para avaliar a performance do modelo sem afetar o processo de aprendizado.\n",
    "\n",
    "## Callbacks\n",
    "\n",
    "Os callbacks são ferramentas utilizadas para visualizar, ajustar e salvar métricas de desempenho do modelo durante o treinamento. Eles permitem realizar ações em diferentes etapas do treinamento, como ajustar a taxa de aprendizado ou interromper o treinamento quando uma condição é atendida.\n",
    "\n",
    "### ReduceLROnPlateau\n",
    "\n",
    "- **Descrição**: Reduz a taxa de aprendizado quando uma métrica de avaliação parou de melhorar.\n",
    "- **Parâmetros Principais**:\n",
    "  - **Monitor**: Métrica a ser monitorada, como a perda de validação.\n",
    "  - **Factor**: Fator pelo qual a taxa de aprendizado será reduzida. Novo_lr = lr * factor.\n",
    "  - **Patience**: Número de épocas sem melhoria após o qual a taxa de aprendizado será reduzida.\n",
    "  - **Min_lr**: Limite inferior da taxa de aprendizado.\n",
    "\n",
    "### EarlyStopping\n",
    "\n",
    "- **Descrição**: Interrompe o treinamento quando uma métrica monitorada deixa de melhorar.\n",
    "- **Parâmetros Principais**:\n",
    "  - **Monitor**: Métrica a ser monitorada para interrupção.\n",
    "  - **Patience**: Número de épocas sem melhoria após o qual o treinamento será interrompido.\n",
    "  - **Restore_best_weights**: Se verdadeiro, restaura os pesos do modelo do ponto onde a métrica monitorada teve o melhor valor.\n",
    "\n",
    "## History\n",
    "\n",
    "- **Descrição**: Objeto retornado pela função de treinamento do modelo contendo um registro dos valores das métricas de treinamento e validação ao longo das épocas.\n",
    "- **Utilização**:\n",
    "  - **Acesso a Métricas**: Permite acessar os valores de perda e outras métricas tanto para o conjunto de treinamento quanto para o de validação após cada época.\n",
    "  - **Visualização de Desempenho**: Facilita a visualização do progresso do treinamento e a identificação de possíveis problemas, como overfitting ou underfitting, através de gráficos das métricas ao longo do tempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot do histórico para Classificação Binária\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Configuração do ReduceLROnPlateau para reduzir a taxa de aprendizado quando uma métrica de avaliação parar de melhorar\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=5, min_lr=0.001, verbose=1)\n",
    "\n",
    "# Configuração do EarlyStopping para interromper o treinamento quando uma métrica de avaliação parar de melhorar\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do otimizador Adam com parâmetros padrão\n",
    "adam_binaria = tf.keras.optimizers.Adam()\n",
    "# Compilação do modelo de classificação binária\n",
    "modelo_classificacao_binaria.compile(optimizer=adam_binaria,  # Utilização do otimizador Adam\n",
    "                                     loss='binary_crossentropy',  # Uso da perda de entropia cruzada binária para classificação binária\n",
    "                                     metrics=['accuracy'])  # Acurácia como métrica de avaliação\n",
    "\n",
    "# Treinamento do modelo de classificação binária\n",
    "history_binaria = modelo_classificacao_binaria.fit(\n",
    "    X_treino_bin_scaled, y_treino_bin,  # Dados de treinamento\n",
    "    epochs=100,  # Número de épocas\n",
    "    batch_size=32,  # Tamanho do lote\n",
    "    validation_data=(X_validacao_bin_scaled, y_validacao_bin),  # Dados de validação\n",
    "    callbacks=[reduce_lr, early_stopping],  # Callbacks para ajuste da taxa de aprendizado e parada antecipada\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "# Plot da perda de treinamento e validação\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_binaria.history['loss'], label='Perda de Treinamento')\n",
    "plt.plot(history_binaria.history['val_loss'], label='Perda de Validação')\n",
    "plt.title('Perda')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "\n",
    "# Plot da acurácia de treinamento e validação\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_binaria.history['accuracy'], label='Acurácia de Treinamento')\n",
    "plt.plot(history_binaria.history['val_accuracy'], label='Acurácia de Validação')\n",
    "plt.title('Acurácia')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do otimizador Adam com parâmetros padrão\n",
    "adam_multiclasse = tf.keras.optimizers.Adam()\n",
    "# Compilação do modelo de classificação multiclasse\n",
    "modelo_classificacao_multiclasse.compile(optimizer=adam_multiclasse,  # Utilização do otimizador Adam\n",
    "                                         loss='categorical_crossentropy',  # Uso da perda de entropia cruzada categórica para classificação multiclasse\n",
    "                                         metrics=['accuracy'])  # Acurácia como métrica de avaliação\n",
    "\n",
    "# Treinamento do modelo de classificação multiclasse\n",
    "history_multiclasse = modelo_classificacao_multiclasse.fit(\n",
    "    X_treino_multi_scaled, y_treino_multi_encoded,  # Dados de treinamento\n",
    "    epochs=100,  # Número de épocas\n",
    "    batch_size=32,  # Tamanho do lote\n",
    "    validation_data=(X_validacao_multi_scaled, y_validacao_multi_encoded),  # Dados de validação\n",
    "    callbacks=[reduce_lr, early_stopping],  # Callbacks para ajuste da taxa de aprendizado e parada antecipada\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "# Plot da perda de treinamento e validação\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_multiclasse.history['loss'], label='Perda de Treinamento')\n",
    "plt.plot(history_multiclasse.history['val_loss'], label='Perda de Validação')\n",
    "plt.title('Perda')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "\n",
    "# Plot da acurácia de treinamento e validação\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_multiclasse.history['accuracy'], label='Acurácia de Treinamento')\n",
    "plt.plot(history_multiclasse.history['val_accuracy'], label='Acurácia de Validação')\n",
    "plt.title('Acurácia')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do otimizador Adam com parâmetros padrão\n",
    "adam_regressao = tf.keras.optimizers.Adam()\n",
    "# Compilação do modelo de regressão\n",
    "modelo_regressao.compile(optimizer=adam_regressao,  # Utilização do otimizador Adam\n",
    "                         loss='mean_squared_error',  # Uso do erro quadrático médio como função de perda para regressão\n",
    "                         metrics=['mae', 'mse'])  # Métricas incluem erro absoluto médio (MAE) e erro quadrático médio (MSE)\n",
    "\n",
    "# Treinamento do modelo de regressão\n",
    "history_regressao = modelo_regressao.fit(\n",
    "    X_treino_reg_scaled, y_treino_reg_scaled,  # Dados de treinamento\n",
    "    epochs=100,  # Número de épocas\n",
    "    batch_size=32,  # Tamanho do lote\n",
    "    validation_data=(X_validacao_reg_scaled, y_validacao_reg_scaled),  # Dados de validação\n",
    "    callbacks=[reduce_lr, early_stopping],  # Callbacks para ajuste da taxa de aprendizado e parada antecipada\n",
    "    verbose = 0\n",
    ")\n",
    "\n",
    "# Plot da perda de treinamento e validação\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_regressao.history['loss'], label='Perda de Treinamento')\n",
    "plt.plot(history_regressao.history['val_loss'], label='Perda de Validação')\n",
    "plt.title('Perda')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "\n",
    "# Considerando 'mae' como métrica principal para o modelo de regressão\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_regressao.history['mae'], label='MAE de Treinamento')\n",
    "plt.plot(history_regressao.history['val_mae'], label='MAE de Validação')\n",
    "plt.title('MAE')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação\n",
    "\n",
    "Avaliar a performance de modelos de Machine Learning é crucial para entender sua eficácia em tarefas de previsão. Existem várias métricas de avaliação, cada uma oferecendo insights sobre diferentes aspectos do desempenho do modelo. Estas métricas são divididas principalmente entre tarefas de classificação e regressão.\n",
    "\n",
    "## Classificação\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "- **Descrição**: A acurácia mede a proporção de previsões corretas (tanto positivas quanto negativas) em relação ao total de previsões feitas.\n",
    "- **Utilização**: É uma medida inicial útil, mas pode ser enganosa em conjuntos de dados desbalanceados.\n",
    "\n",
    "### Precision\n",
    "\n",
    "- **Descrição**: A precisão mede a proporção de previsões positivas corretas (verdadeiros positivos) em relação ao total de previsões positivas feitas (verdadeiros positivos + falsos positivos).\n",
    "- **Utilização**: Útil quando o custo de um falso positivo é alto.\n",
    "\n",
    "### Recall\n",
    "\n",
    "- **Descrição**: O recall (sensibilidade) mede a proporção de previsões positivas corretas (verdadeiros positivos) em relação ao total de casos positivos reais (verdadeiros positivos + falsos negativos).\n",
    "- **Utilização**: Importante quando é crítico identificar todos os casos positivos.\n",
    "\n",
    "### F1-Score\n",
    "\n",
    "- **Descrição**: O F1-Score é a média harmônica da precisão e do recall, oferecendo um balanço entre essas duas métricas.\n",
    "- **Utilização**: Útil quando se busca um equilíbrio entre precisão e recall, especialmente em conjuntos de dados desbalanceados.\n",
    "\n",
    "## Regressão\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "\n",
    "- **Descrição**: O MSE mede a média dos quadrados das diferenças entre os valores preditos pelo modelo e os valores reais.\n",
    "- **Utilização**: Fornece uma noção da magnitude dos erros do modelo, penalizando mais fortemente grandes desvios.\n",
    "\n",
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "- **Descrição**: O RMSE é a raiz quadrada do MSE, trazendo os valores de erro de volta para a unidade de medida original dos dados.\n",
    "- **Utilização**: Oferece uma interpretação mais intuitiva da magnitude média dos erros do modelo.\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "- **Descrição**: O MAE mede a média do valor absoluto das diferenças entre as previsões e os valores reais.\n",
    "- **Utilização**: Fornece uma medida direta da magnitude média dos erros do modelo, sem dar ênfase excessiva a grandes desvios, ao contrário do MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões para classificação binária\n",
    "y_pred_bin = (modelo_classificacao_binaria.predict(X_teste_bin_scaled) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Classification Report para Classificação Binária\n",
    "print(\"Relatório de Classificação - Classificação Binária:\")\n",
    "print(classification_report(y_teste_bin, y_pred_bin, target_names=['Classe 0', 'Classe 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Previsões para classificação multiclasse\n",
    "y_pred_multi = modelo_classificacao_multiclasse.predict(X_teste_multi_scaled)\n",
    "y_pred_multi_classes = np.argmax(y_pred_multi, axis=1)\n",
    "\n",
    "# Conversão das labels one-hot encoded para suas classes correspondentes\n",
    "y_teste_multi_classes = np.argmax(y_teste_multi_encoded, axis=1)\n",
    "\n",
    "# Calculamos as métricas\n",
    "acc_multi = accuracy_score(y_teste_multi_classes, y_pred_multi_classes)\n",
    "prec_multi = precision_score(y_teste_multi_classes, y_pred_multi_classes, average='macro')\n",
    "rec_multi = recall_score(y_teste_multi_classes, y_pred_multi_classes, average='macro')\n",
    "f1_multi = f1_score(y_teste_multi_classes, y_pred_multi_classes, average='macro')\n",
    "\n",
    "print(\"\\nClassificação Multiclasse:\")\n",
    "print(\"Acurácia:\", acc_multi)\n",
    "print(\"Precisão:\", prec_multi)\n",
    "print(\"Recall:\", rec_multi)\n",
    "print(\"F1-Score:\", f1_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Previsões para regressão\n",
    "y_pred_reg = modelo_regressao.predict(X_teste_reg_scaled)\n",
    "# Desnormalização das previsões de regressão\n",
    "y_pred_reg_desnorm = scaler_reg_y.inverse_transform(y_pred_reg)\n",
    "\n",
    "# Desnormalização dos dados reais de teste para comparação\n",
    "y_teste_reg_desnorm = scaler_reg_y.inverse_transform(y_teste_reg_scaled.reshape(-1, 1))\n",
    "\n",
    "# Calculamos as métricas\n",
    "mse_reg = mean_squared_error(y_teste_reg_desnorm, y_pred_reg)\n",
    "rmse_reg = np.sqrt(mse_reg)  # Calculando RMSE a partir do MSE\n",
    "mae_reg = mean_absolute_error(y_teste_reg_desnorm, y_pred_reg)\n",
    "\n",
    "print(\"\\nRegressão:\")\n",
    "print(\"MSE:\", mse_reg)\n",
    "print(\"RMSE:\", rmse_reg)\n",
    "print(\"MAE:\", mae_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
