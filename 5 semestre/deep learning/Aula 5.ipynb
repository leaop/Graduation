{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 5: Redes Neurais Artificiais (RNAs) - Algoritmos de Otimização e Backpropagation, Perda e Custo, Descida do Gradiente e Learning Rate\n",
    "\n",
    "## Objetivos da Aula\n",
    "- Entender os conceitos fundamentais dos algoritmos de otimização e backpropagation em Redes Neurais Artificiais.\n",
    "- Aprender sobre as funções de perda e custo, como elas são calculadas e sua importância no treinamento de modelos.\n",
    "- Compreender a descida do gradiente e seu papel na otimização dos pesos da rede.\n",
    "- Discutir o conceito de learning rate e como ele afeta o treinamento da rede.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parte 1: Algoritmos de Otimização e Backpropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Algoritmos de Otimização\n",
    "- Definição e importância dos algoritmos de otimização.\n",
    "- Tipos de algoritmos de otimização (Gradiente Descendente, Gradiente Descendente Estocástico, Adam, RMSprop).\n",
    "\n",
    "Os algoritmos de otimização desempenham um papel crucial no treinamento de redes neurais artificiais (RNAs), ajustando os parâmetros do modelo — pesos e bias — para minimizar a função de custo. Esses algoritmos são fundamentais porque orientam o processo de aprendizado do modelo, influenciando diretamente sua performance e eficácia.\n",
    "\n",
    "### Definição e Importância\n",
    "\n",
    "Um algoritmo de otimização busca os melhores parâmetros para um modelo, minimizando ou maximizando uma função objetivo (normalmente, a função de custo ou perda no contexto de RNAs). A otimização eficaz é crucial para garantir que o modelo aprenda corretamente a partir dos dados, evitando problemas como o sobreajuste ou o ajuste insuficiente e melhorando sua capacidade de generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de Algoritmos de Otimização\n",
    "\n",
    "Os algoritmos de otimização são fundamentais no processo de treinamento de redes neurais, permitindo a atualização dos pesos de forma a minimizar a função de custo. Cada algoritmo tem suas características, vantagens e desvantagens, sendo mais adequado para determinados tipos de problemas.\n",
    "\n",
    "#### Gradiente Descendente (GD)\n",
    "\n",
    "- **Detalhes**: O GD atualiza todos os parâmetros simultaneamente após calcular o gradiente da função de custo em relação a todos os exemplos no conjunto de dados. É um método determinístico e direto.\n",
    "- **Casos de Uso Recomendados**: Efetivo em conjuntos de dados menores onde o cálculo do gradiente em todo o conjunto é computacionalmente viável.\n",
    "- **Pontos Positivos**: Simplicidade e previsibilidade na convergência para mínimos locais ou globais em funções convexas.\n",
    "- **Pontos Negativos**: Ineficiência em conjuntos de dados grandes devido à necessidade de calcular o gradiente em todo o conjunto a cada atualização.\n",
    "\n",
    "#### Gradiente Descendente Estocástico (SGD)\n",
    "\n",
    "- **Detalhes**: O SGD atualiza os parâmetros para cada amostra ou pequeno lote, introduzindo uma componente estocástica que pode ajudar a escapar de mínimos locais.\n",
    "- **Casos de Uso Recomendados**: Apropriado para conjuntos de dados grandes, onde o GD é impraticável devido ao custo computacional.\n",
    "- **Pontos Positivos**: Maior eficiência e capacidade de escapar de mínimos locais em funções não-convexas.\n",
    "- **Pontos Negativos**: A convergência pode ser irregular e requer cuidadosa seleção do tamanho do lote e do learning rate.\n",
    "\n",
    "#### Adam (Adaptive Moment Estimation)\n",
    "\n",
    "- **Detalhes**: Combina as vantagens do Momentum (que acelera a convergência em direções consistentes) e do RMSprop (que ajusta o learning rate de forma adaptativa para cada parâmetro), tornando-o robusto em uma ampla gama de cenários.\n",
    "- **Casos de Uso Recomendados**: Efetivo em muitos problemas de deep learning, especialmente aqueles com grandes conjuntos de dados ou parâmetros.\n",
    "- **Pontos Positivos**: Alta eficiência, necessita de menos ajustes manuais do learning rate, e geralmente converge mais rápido que outros métodos.\n",
    "- **Pontos Negativos**: Pode ser mais difícil de ajustar quando o comportamento da função de custo é muito irregular ou quando a otimização estagna em pontos planos.\n",
    "\n",
    "#### RMSprop\n",
    "\n",
    "- **Detalhes**: Ajusta a taxa de aprendizado para cada parâmetro, dividindo o learning rate pela média móvel do gradiente quadrático recente, permitindo ajustes mais finos e evitando a diminuição muito rápida ou o aumento do learning rate.\n",
    "- **Casos de Uso Recomendados**: Particularmente útil em problemas com gradientes ruidosos ou em redes profundas onde o SGD falha em convergir devido a oscilações.\n",
    "- **Pontos Positivos**: Permite um ajuste mais fino do learning rate, podendo acelerar a convergência em cenários complicados.\n",
    "- **Pontos Negativos**: Assim como o Adam, pode ser desafiador de ajustar em funções de custo com muitos mínimos locais ou pontos planos.\n",
    "\n",
    "Cada um desses algoritmos tem um papel a desempenhar, dependendo das especificidades do problema e das características do conjunto de dados. A escolha do algoritmo de otimização pode significar a diferença entre um modelo que aprende de forma eficiente e outro que luta para encontrar uma solução ótima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão do Valor do Bitcoin para o Dia Seguinte Usando Regressão\n",
    "\n",
    "## Introdução\n",
    "\n",
    "O Bitcoin, como uma das criptomoedas mais valiosas e voláteis do mercado, tem atraído a atenção de investidores, traders e pesquisadores. A previsão do seu valor diário pode oferecer insights valiosos para estratégias de investimento e análise de mercado. Neste contexto, propomos uma abordagem de modelagem preditiva para estimar o valor do Bitcoin para o dois dias a frente, com base em dados históricos.\n",
    "\n",
    "## Base de Dados\n",
    "\n",
    "Utilizaremos uma base de dados histórica contendo os preços diários do Bitcoin, disponível publicamente no link: [Bitcoin Daily Prices](https://raw.githubusercontent.com/coinmetrics/data/master/csv/btc.csv). Esta base de dados inclui vários indicadores de cada dia, tais como preço de abertura, preço de fechamento, volume negociado, entre outros.\n",
    "\n",
    "## Engenharia de Atributos\n",
    "\n",
    "Para desenvolver nosso modelo de regressão, é essencial aplicar técnicas de engenharia de atributos para criar variáveis preditivas significativas e a classe alvo. A classe alvo, em nosso caso, será o valor do Bitcoin em dois dias para a frente. Abaixo estão os passos propostos para a preparação dos dados:\n",
    "\n",
    "1. **Criação da Classe Alvo**: A classe alvo será o preço de fechamento do Bitcoin para o dois dias a frente. Para criar essa coluna, podemos deslocar a coluna de preço de fechamento ('close') duas posição para cima. Isso alinhará o preço de fechamento de um dia com os indicadores do dia anterior.\n",
    "\n",
    "2. **Seleção de Atributos**: A base de dados contém múltiplas variáveis que podem ser usadas como preditores. Selecionaremos atributos baseados na sua correlação com o preço do Bitcoin e na sua relevância teórica para a previsão de preços de ativos financeiros. Exemplos de atributos a serem considerados incluem preço de abertura, volume negociado e valores máximos e mínimos do dia.\n",
    "\n",
    "3. **Tratamento de Valores Faltantes**: É crucial verificar a presença de valores faltantes nos dados e aplicar técnicas adequadas para tratá-los, como imputação ou remoção de linhas/colunas com valores ausentes.\n",
    "\n",
    "4. **Normalização ou Padronização**: Dependendo do algoritmo de regressão utilizado, pode ser necessário normalizar ou padronizar os atributos para melhorar o desempenho do modelo.\n",
    "\n",
    "## Modelagem Preditiva\n",
    "\n",
    "Com os dados preparados, procederemos à fase de modelagem, onde diferentes algoritmos de regressão serão testados para determinar o mais adequado para nossa tarefa de previsão. Alguns dos algoritmos comuns de regressão incluem regressão linear, árvores de decisão, florestas aleatórias e gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Marcando o tempo de início\n",
    "inicio = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/coinmetrics/data/master/csv/btc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temos um registro para cada dia\n",
    "df[['time','PriceUSD']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como podemos fazer para prever o valor do dia seguinte?\n",
    "Se nossa classe alvo não existe (valor daqui a 2 dias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['10/12/2023',\n",
    "        '11/12/2023',\n",
    "        '12/12/2023',\n",
    "        '13/12/2023',\n",
    "        '14/12/2023',\n",
    "        '15/12/2023',\n",
    "        '16/12/2023']\n",
    "valor_dia = [1,2,3,4,5,6,7]\n",
    "valor_dois_dias = valor_dia.copy()\n",
    "print('Valores do dia', valor_dia)\n",
    "\n",
    "# Exclui o primeiro registro da valor_dois_dias\n",
    "valor_dois_dias.pop(0)\n",
    "# Exclui o segundo registro da valor_dois_dias\n",
    "valor_dois_dias.pop(0)\n",
    "print('Lista sem o primeiro registro', valor_dois_dias)\n",
    "\n",
    "# Acrescenta zero ao último valor da valor_dois_dias\n",
    "valor_dois_dias.append(0)\n",
    "# Acrescenta zero ao penúltimo valor da valor_dois_dias\n",
    "valor_dois_dias.append(0)\n",
    "print('Lista com 0 na última posição', valor_dois_dias)\n",
    "\n",
    "df_exemplo = pd.DataFrame({'Data':data,'Valor do dia':valor_dia,'Valor daqui 2 dias':valor_dois_dias})\n",
    "df_exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a coluna Time para o tipo de dados de data\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menor Dia\n",
    "df['time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maior Dia\n",
    "df['time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a quantidade de dias do menor para o maior dia\n",
    "(df['time'].max() - df['time'].min()).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe quantas datas únicas tem na coluna Data\n",
    "df['time'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra a diferença entre o maior e o menor valor de uma lista sequencial\n",
    "lista = [1,2,3,4,5]\n",
    "max(lista) - min(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe quantos registros (linhas) tem na base\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista com os valores do preço do bitcoin nos dias\n",
    "lista_preco = list(df['PriceUSD'].values)\n",
    "\n",
    "# Remove o primeiro elemento desta lista\n",
    "lista_preco.pop(0)\n",
    "# Remove o segundo elemento desta lista\n",
    "lista_preco.pop(0)\n",
    "\n",
    "#Acrescenta 0 no final\n",
    "lista_preco.append(0)\n",
    "lista_preco.append(0)\n",
    "\n",
    "# Cria a coluna preco_dia_seguinte e acrescenta a lista que alteramos\n",
    "df['preco_dois_dias'] = lista_preco\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar nulos na coluna PriceUSD\n",
    "df.dropna(subset=['PriceUSD'], inplace = True)\n",
    "\n",
    "# Apagar nulos na coluna preco_dia_seguinte\n",
    "df.dropna(subset=['preco_dois_dias'], inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar todas colunas com mais de 1 valor nulo\n",
    "null_counts = df.isnull().sum()\n",
    "colunas_apagar = null_counts[null_counts > 1].index.tolist()\n",
    "df.drop(colunas_apagar, axis = 1, inplace  = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar colunas de data\n",
    "df['ano'] = df['time'].dt.year\n",
    "df['mes'] = df['time'].dt.month\n",
    "df['dia'] = df['time'].dt.day\n",
    "df['dia_semana'] = df['time'].dt.day_of_week\n",
    "df['dia_ano'] = df['time'].dt.day_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna a correlação dos atributos com o valor que queremos prever\n",
    "correlation_matrix = df.drop(['time'], axis = 1).corr()['preco_dois_dias']\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar as colunas com pouca correlação ao preco_dia_seguinte\n",
    "colunas_interesse = ['mes', 'dia', 'dia_semana', 'dia_ano', 'PriceUSD']\n",
    "colunas_remover = correlation_matrix[(correlation_matrix >= -0.3) & (correlation_matrix <= 0.3)].index.tolist()\n",
    "colunas_remover = [coluna for coluna in colunas_remover if coluna not in colunas_interesse]\n",
    "colunas_remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar as colunas com pouca correlação ao preco_dia_seguinte\n",
    "df.drop(colunas_remover, axis=1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['preco_dois_dias'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclui todas as linhas que possuem ao menos 1 registro nulo\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias para o pré-processamento dos dados\n",
    "from sklearn.preprocessing import MinMaxScaler  # Usado para normalizar os dados\n",
    "from sklearn.model_selection import train_test_split  # Usado para dividir os dados em conjuntos de treinamento, validação e teste\n",
    "\n",
    "# Dividindo o dataframe em conjuntos de teste e treinamento/validação com base em 98% dos dados para treinamento/validação\n",
    "# e os 2% restantes para teste\n",
    "df_test = df[round(len(df) * 0.98) :]  # Conjunto de teste contém os últimos 2% dos dados\n",
    "df_train_val = df[:round(len(df) * 0.98)]  # Conjunto de treinamento e validação contém os primeiros 98% dos dados\n",
    "\n",
    "# Preparando os conjuntos de features (X) e labels (y) para teste, descartando colunas 'time' e 'preco_dois_dias'\n",
    "# para o conjunto de features e mantendo apenas 'preco_dois_dias' para o conjunto de labels\n",
    "X_test = df_test.drop(['time', 'preco_dois_dias'], axis=1)  # Features para teste\n",
    "y_test = df_test[['preco_dois_dias']]  # Labels para teste\n",
    "\n",
    "# Repetindo o processo de preparação dos dados para os conjuntos de treinamento e validação\n",
    "X_train_val = df_train_val.drop(['time', 'preco_dois_dias'], axis=1)  # Features para treinamento e validação\n",
    "y_train_val = df_train_val[['preco_dois_dias']]  # Labels para treinamento e validação\n",
    "\n",
    "# Dividindo o conjunto de treinamento/validação em treinamento e validação individuais\n",
    "# shuffle=True embaralha os dados para garantir uma distribuição aleatória\n",
    "# test_size=0.2 indica que 20% dos dados serão usados para validação\n",
    "# random_state=50 é usado para garantir a reprodutibilidade do processo de divisão\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, shuffle=True, test_size=0.2, random_state=50)\n",
    "\n",
    "# Inicializando o objeto MinMaxScaler para normalizar as features\n",
    "scale_X = MinMaxScaler()\n",
    "X_train = scale_X.fit_transform(X_train)  # Ajustando e transformando os dados de treinamento\n",
    "X_val = scale_X.transform(X_val)  # Transformando os dados de validação\n",
    "X_test = scale_X.transform(X_test)  # Transformando os dados de teste\n",
    "\n",
    "# Inicializando outro objeto MinMaxScaler para normalizar os labels\n",
    "scale_y = MinMaxScaler()\n",
    "y_train = scale_y.fit_transform(y_train)  # Ajustando e transformando os labels de treinamento\n",
    "y_val = scale_y.transform(y_val)  # Transformando os labels de validação\n",
    "y_test = scale_y.transform(y_test)  # Transformando os labels de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(X_train, optimizer_name='sgd', learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Constrói e compila uma rede neural simples com o otimizador especificado.\n",
    "\n",
    "    Parâmetros:\n",
    "    - X_train: Dados para definir a quantidade de neurônios na camada de entrada.\n",
    "    - optimizer_name: Uma string que especifica o otimizador a ser usado ('sgd', 'adam', 'rmsprop').\n",
    "    - learning_rate: A taxa de aprendizado para o otimizador.\n",
    "\n",
    "    Retorna:\n",
    "    - Um modelo compilado de rede neural.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a arquitetura do modelo\n",
    "    model = Sequential([\n",
    "        Dense(128, input_shape=(X_train.shape[1], ), activation='relu'),  # Camada densa com 128 unidades e ativação ReLU\n",
    "        Dense(64, activation='relu'),  # Camada densa com 64 unidades e ativação ReLU\n",
    "        Dense(32, activation='relu'),  # Camada densa com 32 unidades e ativação ReLU\n",
    "        Dense(1, activation='linear') # Camada de saída com 1 unidades para regressão\n",
    "    ])\n",
    "    \n",
    "    # Seleciona o otimizador com base no nome e define a taxa de aprendizado\n",
    "    if optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Otimizador não reconhecido! Escolha entre 'sgd', 'adam' ou 'rmsprop'.\")\n",
    "\n",
    "    # Compila o modelo com o otimizador escolhido, função de perda e métricas\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Exemplos de como construir e compilar modelos com diferentes otimizadores\n",
    "model_sgd = build_and_compile_model(X_train, optimizer_name='sgd', learning_rate=0.01)\n",
    "model_adam = build_and_compile_model(X_train, optimizer_name='adam', learning_rate=0.001)\n",
    "model_rmsprop = build_and_compile_model(X_train, optimizer_name='rmsprop', learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_sgd.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_adam.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_rmsprop.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_teste = list(df_test['time'])\n",
    "valor_real_teste = list(df_test['preco_dois_dias'])\n",
    "\n",
    "predict_sgd = scale_y.inverse_transform(model_sgd.predict(X_test))\n",
    "predict_adam = scale_y.inverse_transform(model_adam.predict(X_test))\n",
    "predict_rmsprop = scale_y.inverse_transform(model_rmsprop.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparar_previsoes(data_teste, previsoes_modelos, nome_modelos):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for cont in range(len(previsoes_modelos)):\n",
    "        plt.plot(data_teste, previsoes_modelos[cont], label=nome_modelos[cont])\n",
    "    plt.title('Comparando valores reais e preditos de teste')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Valor')\n",
    "    plt.show()\n",
    "\n",
    "previsoes_modelos = [valor_real_teste, predict_sgd, predict_adam, predict_rmsprop]\n",
    "nome_modelos = ['Real', 'SGD', 'ADAM', 'RMSPROP']\n",
    "\n",
    "comparar_previsoes(data_teste, previsoes_modelos, nome_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Backpropagation\n",
    "- Conceito e mecânica do algoritmo Backpropagation.\n",
    "- Cálculo do gradiente e atualização dos pesos.\n",
    "- Importância do backpropagation no aprendizado profundo.\n",
    "\n",
    "\n",
    "Backpropagation, ou retropropagação, é um algoritmo central no treinamento de redes neurais artificiais (RNAs), permitindo que elas aprendam a partir dos erros e ajustem seus pesos e bias de forma eficaz. Este processo é fundamental para o aprendizado profundo e para a otimização do desempenho dos modelos.\n",
    "\n",
    "### Conceito e Mecânica do Algoritmo Backpropagation\n",
    "\n",
    "Backpropagation é um método utilizado para calcular o gradiente da função de custo em relação a todos os pesos na rede. O algoritmo propaga o erro de saída de volta pela rede, da camada de saída até a camada de entrada, atualizando os pesos em cada camada à medida que procede. Este processo se baseia na regra da cadeia do cálculo diferencial para computar os gradientes de forma eficiente, permitindo que a rede aprenda padrões complexos a partir dos dados de entrada.\n",
    "\n",
    "### Cálculo do Gradiente e Atualização dos Pesos\n",
    "\n",
    "O cálculo do gradiente durante o backpropagation envolve duas fases principais:\n",
    "\n",
    "1. **Propagação para frente (forward pass)**: Nesta fase, os dados de entrada são passados através da rede, camada por camada, até gerar uma saída. Durante a propagação para frente, os valores intermediários (ativações) são armazenados, pois serão utilizados posteriormente no cálculo do gradiente.\n",
    "\n",
    "2. **Propagação para trás (backward pass)**: A partir da saída, o erro é calculado usando uma função de custo (por exemplo, MSE para regressão ou entropia cruzada para classificação). Este erro é então propagado de volta pela rede (da última camada para a primeira), utilizando a regra da cadeia para calcular os gradientes do erro em relação a cada peso e bias. Finalmente, os pesos são atualizados na direção oposta ao gradiente para minimizar o erro.\n",
    "\n",
    "### Importância do Backpropagation no Aprendizado Profundo\n",
    "\n",
    "O backpropagation é crucial para o sucesso do aprendizado profundo por várias razões:\n",
    "\n",
    "- **Eficiência**: Permite o cálculo eficiente dos gradientes necessários para atualizar os pesos da rede, mesmo em redes profundas com muitas camadas e parâmetros.\n",
    "- **Capacidade de aprendizado**: Habilita a rede a aprender padrões complexos e nuances nos dados, ajustando os pesos de forma que o erro de saída seja minimizado.\n",
    "- **Generalização**: Ao otimizar os pesos para minimizar a função de custo, o backpropagation ajuda a rede a generalizar melhor a partir dos dados de treinamento, melhorando seu desempenho em dados não vistos anteriormente.\n",
    "\n",
    "O backpropagation é o coração do treinamento de redes neurais, possibilitando que esses modelos poderosos aprendam a partir dos dados e façam previsões ou classificações precisas em uma vasta gama de aplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Funções de Perda e Custo\n",
    "\n",
    "### Diferença entre Função de Custo e Função de Perda\n",
    "\n",
    "Embora frequentemente usados de maneira intercambiável no contexto de treinamento de modelos de aprendizado de máquina, os termos \"função de custo\" e \"função de perda\" possuem nuances que os diferenciam.\n",
    "\n",
    "#### Função de Perda\n",
    "\n",
    "A função de perda, também conhecida como função de erro, calcula a discrepância entre a previsão do modelo para um único exemplo de treinamento e o valor real desse exemplo. É um indicador do erro para uma única instância de dados. Em outras palavras, mede o erro para cada exemplo de treinamento, fornecendo uma medida de precisão para previsões individuais.\n",
    "\n",
    "Exemplos comuns de funções de perda incluem:\n",
    "- Erro Quadrático Médio (MSE) para regressão\n",
    "- Entropia Cruzada para classificação\n",
    "\n",
    "#### Função de Custo\n",
    "\n",
    "A função de custo, por outro lado, é o agregado das funções de perda sobre todo o conjunto de treinamento. Ela fornece uma visão geral do desempenho do modelo em todo o conjunto de dados. A função de custo é o que o algoritmo de otimização (por exemplo, o gradiente descendente) tenta minimizar durante o treinamento do modelo. Minimizar a função de custo significa encontrar o conjunto de parâmetros (pesos e bias) que resulta no menor erro médio em todo o conjunto de treinamento.\n",
    "\n",
    "A função de custo é, portanto, uma medida agregada que reflete o desempenho do modelo em todos os exemplos do conjunto de treinamento, enquanto a função de perda se concentra no erro para um único exemplo de treinamento.\n",
    "\n",
    "#### Resumo\n",
    "\n",
    "- **Função de Perda**: Foca no erro para um único exemplo de treinamento, medindo a discrepância entre a previsão do modelo e o valor real.\n",
    "- **Função de Custo**: Agrega as funções de perda sobre todo o conjunto de treinamento, fornecendo uma medida global do desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Funções de Perda\n",
    "\n",
    "Funções de perda são essenciais no treinamento de redes neurais, pois quantificam o quão bem o modelo está performando em relação aos dados reais. O objetivo durante o treinamento é minimizar essa função, o que, por sua vez, aprimora a precisão do modelo.\n",
    "\n",
    "### Principais Tipos de Funções de Perda\n",
    "\n",
    "- **Erro Quadrático Médio (MSE)**: Utilizado primariamente em problemas de regressão, foca na minimização da diferença quadrática entre as previsões do modelo e os valores reais observados.\n",
    "\n",
    "- **Entropia Cruzada (Cross-Entropy)**: Mais adequada para tarefas de classificação, esta função de perda mede a discrepância entre as distribuições de probabilidade previstas pelo modelo e as distribuições reais dos dados.\n",
    "\n",
    "### Seleção da Função de Perda Baseada no Tipo de Problema\n",
    "\n",
    "- **MSE para Regressão**: Se o objetivo é prever valores contínuos, o MSE é ideal pois penaliza erros maiores de forma mais severa, incentivando o modelo a ser mais preciso.\n",
    "\n",
    "- **Entropia Cruzada para Classificação**: Para tarefas onde é necessário classificar entradas em categorias mutuamente exclusivas, a entropia cruzada é preferível pois otimiza as probabilidades atribuídas às classes corretas pelo modelo. Binária para classificação entre duas classes e categórica para mais de duas possíveis classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Função de Custo\n",
    "\n",
    "A função de custo é fundamental no treinamento de redes neurais, servindo como um indicador de desempenho do modelo. Ela reflete quão bem as previsões do modelo estão alinhadas com os valores reais dos dados. Durante o treinamento, o objetivo é minimizar essa função de custo.\n",
    "\n",
    "#### Quando Aplicar\n",
    "\n",
    "- Use a **função de perda de erro quadrático médio (MSE)** para problemas de regressão, onde o foco está em minimizar a diferença quadrada entre previsões e valores reais.\n",
    "- Para problemas de **classificação**, a **entropia cruzada** é preferida, pois mede a discrepância entre as distribuições de probabilidade previstas pelo modelo e as distribuições reais dos rótulos.\n",
    "\n",
    "#### Avaliação do Desempenho do Modelo\n",
    "O custo total oferece uma visão abrangente do erro do modelo em todo o conjunto de treinamento. Um valor baixo indica que o modelo está fazendo previsões precisas. No entanto, é crucial avaliar o modelo não apenas pelo custo de treinamento, mas também pelo desempenho em um conjunto de dados de validação para garantir que o modelo generalize bem e evite o sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação para Modelos de Regressão\n",
    "\n",
    "Ao avaliar o desempenho de modelos de regressão, várias métricas são utilizadas para capturar diferentes aspectos dos erros de previsão. Aqui está um detalhamento das métricas comuns e o que seus valores sugerem sobre o desempenho do modelo:\n",
    "\n",
    "## MSE (Erro Quadrático Médio)\n",
    "\n",
    "- **O que é**: O MSE mede a média dos quadrados dos erros, isto é, a diferença quadrada entre os valores previstos e os reais.\n",
    "- **Valores**: Valores menores indicam melhores ajustes do modelo, pois significam que o erro entre as previsões e os valores reais é baixo. Valores grandes sugerem um ajuste pobre.\n",
    "\n",
    "## RMSE (Raiz do Erro Quadrático Médio)\n",
    "\n",
    "- **O que é**: O RMSE é simplesmente a raiz quadrada do MSE, trazendo a métrica de volta à escala original dos dados.\n",
    "- **Valores**: Assim como o MSE, valores menores são melhores. O RMSE é particularmente útil porque está na mesma unidade que a variável de resposta, facilitando a interpretação.\n",
    "\n",
    "## MAE (Erro Absoluto Médio)\n",
    "\n",
    "- **O que é**: O MAE calcula a média das diferenças absolutas entre as previsões e os valores reais, fornecendo uma ideia da magnitude do erro sem considerar sua direção.\n",
    "- **Valores**: Valores menores indicam um melhor desempenho. Diferentemente do MSE e RMSE, o MAE não penaliza tanto os erros grandes, sendo uma medida mais robusta a outliers.\n",
    "\n",
    "## R² (Coeficiente de Determinação)\n",
    "\n",
    "- **O que é**: O R² quantifica a proporção da variância na variável dependente que é previsível a partir das variáveis independentes, variando de 0 a 1.\n",
    "- **Valores**: Um valor próximo de 1 indica que o modelo explica uma grande proporção da variância nos dados, sugerindo um bom ajuste. Valores próximos de 0 indicam um ajuste pobre.\n",
    "\n",
    "## MAPE (Erro Percentual Absoluto Médio)\n",
    "\n",
    "- **O que é**: O MAPE mede o erro como uma porcentagem da verdade, oferecendo uma interpretação intuitiva do tamanho do erro em relação ao valor verdadeiro.\n",
    "- **Valores**: Valores menores indicam previsões mais precisas. Um MAPE de 10% sugere que, em média, as previsões desviam 10% dos valores reais. Valores maiores indicam menos precisão.\n",
    "\n",
    "## Interpretação dos Valores\n",
    "\n",
    "- **Pequenos**: MSE, RMSE, MAE e MAPE pequenos indicam que as previsões do modelo estão próximas dos valores reais, sugerindo um modelo preciso.\n",
    "- **Grandes**: Valores grandes para essas métricas indicam um modelo impreciso, com previsões que se desviam significativamente dos valores reais.\n",
    "- **R²**: Um valor alto indica que o modelo capta bem a variabilidade dos dados, enquanto um valor baixo ou negativo sugere que o modelo é incapaz de captar a tendência dos dados.\n",
    "\n",
    "Essas métricas, quando usadas em conjunto, oferecem uma visão abrangente do desempenho do modelo de regressão, destacando tanto a precisão das previsões quanto a capacidade do modelo de explicar a variabilidade nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "def metricas_modelo(nome_modelo, y_predict, y_test):\n",
    "    \"\"\"\n",
    "    Avalia o desempenho de um modelo de regressão com várias métricas.\n",
    "\n",
    "    Parâmetros:\n",
    "    - nome_modelo: O nome do modelo.\n",
    "    - y_predict: Os valores preditos.\n",
    "    - y_test: os valores reais de saída para os dados de teste.\n",
    "\n",
    "    Retorna:\n",
    "    - Imprime as métricas MSE, RMSE, MAE, R² e MAPE.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculando as métricas\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_predict)\n",
    "    \n",
    "    # Imprimindo as métricas\n",
    "    print(f\"Métricas de Avaliação do Modelo:{nome_modelo}\")\n",
    "    print(f\"MSE (Erro Quadrático Médio): {mse:.4f}\")\n",
    "    print(f\"RMSE (Raiz do Erro Quadrático Médio): {rmse:.4f}\")\n",
    "    print(f\"MAE (Erro Absoluto Médio): {mae:.4f}\")\n",
    "    print(f\"R² (Coeficiente de Determinação): {r2:.4f}\")\n",
    "    print(f\"MAPE (Erro Percentual Absoluto Médio): {mape:.4f}\\n\")\n",
    "\n",
    "for cont in range(len(previsoes_modelos)-1):\n",
    "    metricas_modelo(nome_modelos[cont+1], previsoes_modelos[cont+1], valor_real_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parte 3: Descida do Gradiente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Conceito de Descida do Gradiente\n",
    "- Entendimento do conceito de descida do gradiente.\n",
    "- Visualização da descida do gradiente no espaço de parâmetros.\n",
    "\n",
    "\n",
    "A descida do gradiente é um algoritmo de otimização fundamental usado no treinamento de redes neurais artificiais e em muitos outros algoritmos de aprendizado de máquina. O objetivo principal da descida do gradiente é minimizar a função de custo — um indicador de quão bem ou mal o modelo está realizando sua tarefa.\n",
    "\n",
    "### Entendimento do Conceito de Descida do Gradiente\n",
    "\n",
    "A ideia básica por trás da descida do gradiente é iterativamente ajustar os parâmetros do modelo (geralmente, os pesos) de forma a reduzir a função de custo. Isso é feito movendo-se na direção oposta ao gradiente da função de custo com relação aos parâmetros do modelo. O \"gradiente\" aqui representa a inclinação da função de custo e aponta na direção de maior aumento. Consequentemente, para minimizar a função, movemos na direção oposta.\n",
    "\n",
    "### Visualização da Descida do Gradiente no Espaço de Parâmetros\n",
    "\n",
    "Visualmente, podemos imaginar a função de custo como uma superfície em um espaço multidimensional, onde cada ponto na superfície representa um conjunto particular de parâmetros do modelo, e a altura representa o valor da função de custo para aqueles parâmetros. O objetivo da descida do gradiente é encontrar o ponto mais baixo nesta superfície — o mínimo global da função de custo.\n",
    "\n",
    "#### Representação Gráfica\n",
    "\n",
    "Imaginando uma superfície 3D, com os eixos X e Y representando os parâmetros do modelo e o eixo Z representando o valor da função de custo. Iniciamos em um ponto aleatório nesta superfície e, em cada etapa, tomamos um passo na direção onde a superfície desce mais acentuadamente. Este passo é determinado pelo gradiente negativo da função de custo na posição atual.\n",
    "\n",
    "#### Taxa de Aprendizado\n",
    "\n",
    "A \"taxa de aprendizado\" determina o tamanho dos passos que damos ao seguir a direção oposta ao gradiente. Uma taxa de aprendizado muito pequena pode tornar a convergência para o mínimo muito lenta, enquanto uma taxa de aprendizado muito alta pode fazer com que saltemos para além do mínimo ou até divergir.\n",
    "\n",
    "A descida do gradiente é uma ferramenta poderosa, mas seu sucesso na localização do mínimo global depende de vários fatores, incluindo a forma da função de custo e a escolha adequada da taxa de aprendizado. Em funções de custo complexas, com muitos mínimos locais, encontrar o mínimo global pode ser desafiador, mas a descida do gradiente ainda é uma das técnicas mais utilizadas para otimização em aprendizado de máquina.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Definindo a função de perda e o gradiente para duas variáveis\n",
    "def funcao_perda(x, y):\n",
    "    return np.sin(x) ** 2 + np.sin(y) ** 2 + 0.1 * (x ** 2 + y ** 2)\n",
    "\n",
    "# Criando um grid de valores para X e Y\n",
    "x = np.linspace(-6, 6, 400)\n",
    "y = np.linspace(-6, 6, 400)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Calculando os valores da função de perda para cada ponto no grid\n",
    "Z = funcao_perda(X, Y)\n",
    "\n",
    "# Criando o gráfico\n",
    "fig = go.Figure(data=[go.Surface(z=Z, x=X, y=Y, colorscale='Viridis')])\n",
    "\n",
    "# Configurações adicionais do gráfico\n",
    "fig.update_layout(title='Função de Perda em 3D: Mínimos Locais e Global', autosize=False,\n",
    "                  width=700, height=700,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90),\n",
    "                  scene=dict(\n",
    "                      xaxis_title='$x$',\n",
    "                      yaxis_title='$y$',\n",
    "                      zaxis_title='$f(x, y)$'))\n",
    "\n",
    "# Exibindo o gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Implementação da Descida do Gradiente e Algoritmos de Otimização Avançados\n",
    "\n",
    "A descida do gradiente é uma técnica fundamental na otimização de redes neurais, ajustando os parâmetros do modelo para minimizar a função de custo. Esta seção explora não apenas a implementação básica da descida do gradiente, mas também variantes avançadas como Adam e RMSprop.\n",
    "\n",
    "#### Gradiente Descendente (GD)\n",
    "\n",
    "- **Visão Geral**: Calcula o gradiente da função de custo em relação a todos os dados de treinamento para (para cada época) atualizar os parâmetros. É preciso, mas pode ser lento em grandes conjuntos de dados.\n",
    "\n",
    "#### Gradiente Descendente Estocástico (SGD)\n",
    "\n",
    "- **Visão Geral**: Atualiza os parâmetros para cada amostra. Mais rápido que o GD tradicional, introduz ruído que pode ajudar a evitar mínimos locais.\n",
    "\n",
    "#### Mini-Batch Gradient Descent\n",
    "\n",
    "- **Visão Geral**: Combina as abordagens GD e SGD ao atualizar os parâmetros para pequenos lotes de dados. Oferece um equilíbrio entre eficiência computacional e estabilidade do treinamento.\n",
    "\n",
    "#### Adam (Adaptive Moment Estimation)\n",
    "\n",
    "- **Visão Geral**: Combina ideias de momentum e RMSprop, ajustando a taxa de aprendizado de cada parâmetro com base na estimativa de momentos de primeira e segunda ordem dos gradientes. É eficaz em muitos problemas de deep learning.\n",
    "\n",
    "- **Quando Usar**: Recomendado para a maioria dos casos devido à sua eficiência e pouca necessidade de ajuste manual do learning rate.\n",
    "\n",
    "#### RMSprop\n",
    "\n",
    "- **Visão Geral**: Adapta a taxa de aprendizado para cada parâmetro, ajudando a resolver o problema do decrescimento do learning rate no SGD. É particularmente útil em redes profundas e problemas com gradientes ruidosos.\n",
    "\n",
    "- **Quando Usar**: Útil em cenários onde o Adam não proporciona convergência ideal ou em problemas com gradientes muito variáveis.\n",
    "\n",
    "A escolha do algoritmo de otimização é crítica para o sucesso do treinamento de modelos de rede neural. Enquanto o GD e SGD são os métodos fundamentais, algoritmos como Adam e RMSprop oferecem vantagens significativas em termos de eficiência e robustez, tornando-se frequentemente as escolhas preferenciais para uma ampla gama de aplicações de deep learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parte 4: Learning Rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Importância do Learning Rate\n",
    "- Definição e importância do learning rate na otimização de redes neurais.\n",
    "- Efeitos de um learning rate muito alto ou muito baixo.\n",
    "\n",
    "O learning rate, ou taxa de aprendizado, é um dos hiperparâmetros mais críticos na configuração do treinamento de redes neurais artificiais (RNAs). Ele determina o tamanho dos passos que o algoritmo de otimização dá em direção ao mínimo da função de custo. Por isso, o learning rate tem um impacto direto na rapidez e eficácia com que uma rede neural aprende.\n",
    "\n",
    "### Definição e Importância\n",
    "\n",
    "O learning rate é um escalar usado para ponderar a magnitude das atualizações aplicadas aos parâmetros do modelo durante o processo de treinamento. Um learning rate adequado garante que a rede neural converge para um mínimo global (ou um bom mínimo local) da função de custo de maneira eficiente. Se o learning rate for escolhido incorretamente, o treinamento pode ser muito lento (se for muito baixo) ou pode falhar em convergir (se for muito alto).\n",
    "\n",
    "### Efeitos de um Learning Rate Muito Alto ou Muito Baixo\n",
    "\n",
    "- **Learning Rate Muito Alto**: Se o learning rate for muito alto, os passos durante a atualização dos pesos podem ser tão grandes que o algoritmo \"salta\" sobre o mínimo, possivelmente divergindo e levando a uma falha no treinamento. Isso pode ser observado através de uma função de custo que oscila ou até mesmo aumenta com o tempo.\n",
    "\n",
    "- **Learning Rate Muito Baixo**: Por outro lado, um learning rate muito baixo resulta em passos muito pequenos durante a atualização dos pesos, o que pode tornar o treinamento extremamente lento. Além disso, há o risco de a otimização ficar presa em mínimos locais, nunca alcançando o mínimo global (ou um mínimo local aceitável) dentro de um número razoável de iterações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Ajuste do Learning Rate\n",
    "- Estratégias para ajustar o learning rate (learning rate schedules, adaptive learning rates).\n",
    "\n",
    "\n",
    "Ajustar o learning rate é uma estratégia crucial para otimizar o desempenho e a eficiência do treinamento de redes neurais artificiais. Existem diversas abordagens para ajustar o learning rate ao longo do treinamento, cada uma com suas vantagens em contextos específicos.\n",
    "\n",
    "### Estratégias para Ajustar o Learning Rate\n",
    "\n",
    "#### Learning Rate Schedules\n",
    "\n",
    "Learning rate schedules alteram o learning rate ao longo do tempo durante o treinamento. Alguns dos métodos mais comuns incluem:\n",
    "\n",
    "- **Decaimento por época**: O learning rate é reduzido por um fator em intervalos regulares (por exemplo, após cada época). Isso pode ajudar a otimização a \"refinar\" os parâmetros do modelo à medida que se aproxima de um mínimo.\n",
    "\n",
    "- **Decaimento exponencial**: O learning rate é reduzido exponencialmente em função do número de épocas. Isso fornece uma diminuição mais suave do learning rate em comparação com o decaimento por época.\n",
    "\n",
    "- **Warm restarts**: O learning rate é periodicamente reiniciado para um valor mais alto e então reduzido novamente. Esse método pode ajudar a escapar de mínimos locais ao introduzir uma forma de \"reinicialização\" no processo de otimização.\n",
    "\n",
    "#### Adaptive Learning Rates\n",
    "\n",
    "Algoritmos de otimização com learning rates adaptativos ajustam automaticamente o learning rate com base na evolução do treinamento, sem necessidade de definição explícita de um cronograma. Exemplos incluem:\n",
    "\n",
    "- **Adagrad**: Adapta o learning rate para cada parâmetro, dando passos menores para parâmetros com gradientes frequentes e maiores para parâmetros com gradientes raros.\n",
    "\n",
    "- **RMSprop**: Modifica o Adagrad para melhorar seu desempenho em redes neurais profundas, ajustando o learning rate com base na média móvel do quadrado dos gradientes.\n",
    "\n",
    "- **Adam**: Combina ideias do momentum e RMSprop, ajustando o learning rate com base em estimativas de momentos de primeira e segunda ordem dos gradientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias do TensorFlow para construir e compilar modelos de rede neural\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad\n",
    "\n",
    "# Definição da função para construir e compilar o modelo de rede neural\n",
    "def build_and_compile_model(optimizer):\n",
    "    \"\"\"\n",
    "    Constrói e compila um modelo de rede neural.\n",
    "\n",
    "    Parâmetros:\n",
    "    - optimizer: Uma instância do otimizador a ser usado para treinar o modelo.\n",
    "    \n",
    "    Retorna:\n",
    "    - Um modelo compilado de rede neural.\n",
    "    \"\"\"\n",
    "    # Iniciando a construção do modelo sequencial\n",
    "    model = Sequential([\n",
    "        # Primeira camada densa com 128 neurônios e função de ativação ReLU. Define também o tamanho da entrada.\n",
    "        Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        # Segunda camada densa com 64 neurônios e função de ativação ReLU.\n",
    "        Dense(64, activation='relu'),\n",
    "        # Terceira camada densa com 32 neurônios e função de ativação ReLU.\n",
    "        Dense(32, activation='relu'),\n",
    "        # Camada de saída com 1 neurônio e função de ativação linear para problemas de regressão.\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    # Compilando o modelo com o otimizador escolhido, função de perda mean squared error e acompanhamento da métrica mean absolute error.\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com Decaimento por Época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando LearningRateScheduler para ajustes no learning rate e math para cálculos matemáticos\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "# Definição da função scheduler para decaimento do learning rate por época\n",
    "def scheduler(epoch, lr):\n",
    "    \"\"\"\n",
    "    Função para ajustar o learning rate com base no número da época.\n",
    "\n",
    "    Parâmetros:\n",
    "    - epoch: A época atual durante o treinamento.\n",
    "    - lr: O learning rate atual.\n",
    "\n",
    "    Retorna:\n",
    "    - O novo learning rate ajustado.\n",
    "    \"\"\"\n",
    "    # Se estiver antes da 10ª época, mantém o learning rate atual, caso contrário, aplica decaimento.\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * math.exp(-0.1)\n",
    "\n",
    "# Criando um callback que ajustará o learning rate baseado na função scheduler\n",
    "callback_lr_schedule = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Construindo e compilando o modelo com SGD como otimizador e treinando com decaimento do learning rate por época\n",
    "model_epoch_decay = build_and_compile_model(SGD(learning_rate=0.01))\n",
    "model_epoch_decay.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[callback_lr_schedule], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com Decaimento Exponencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de outra função para decaimento exponencial do learning rate\n",
    "def exponential_decay_fn(epoch):\n",
    "    \"\"\"\n",
    "    Função para decaimento exponencial do learning rate.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - epoch: A época atual durante o treinamento.\n",
    "    \n",
    "    Retorna:\n",
    "    - O novo learning rate ajustado exponencialmente.\n",
    "    \"\"\"\n",
    "    return 0.01 * 0.1 ** (epoch / 20)\n",
    "\n",
    "# Criando um callback para o decaimento exponencial do learning rate\n",
    "callback_exponential_decay = LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "# Construindo e compilando outro modelo com SGD e treinando com decaimento exponencial do learning rate\n",
    "model_exponential_decay = build_and_compile_model(SGD(learning_rate=0.01))\n",
    "model_exponential_decay.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[callback_exponential_decay], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com Warm Restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando tensorflow_addons para acesso ao otimizador SGDW que suporta warm restarts\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Construindo e compilando modelos com diferentes otimizadores adaptativos (SGDW, Adagrad, RMSprop, Adam)\n",
    "# e treinando cada um com os respectivos ajustes de learning rate ou características do otimizador.\n",
    "model_warm_restarts = build_and_compile_model(tfa.optimizers.SGDW(learning_rate=0.01, momentum=0.9, weight_decay=0.001, nesterov=True))\n",
    "model_warm_restarts.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adagrad = build_and_compile_model(Adagrad(learning_rate=0.01))\n",
    "model_adagrad.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmsprop = build_and_compile_model(RMSprop(learning_rate=0.001))\n",
    "model_rmsprop.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adam = build_and_compile_model(Adam(learning_rate=0.001))\n",
    "model_adam.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo com redução do Learning Rate por métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model_reduce_lr = build_and_compile_model(Adam(learning_rate=0.001))\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.000001)\n",
    "model_reduce_lr.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), verbose=0, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_epoch_decay = scale_y.inverse_transform(model_epoch_decay.predict(X_test))\n",
    "predict_exponential_decay = scale_y.inverse_transform(model_exponential_decay.predict(X_test))\n",
    "predict_warm_restarts = scale_y.inverse_transform(model_warm_restarts.predict(X_test))\n",
    "predict_adagrad = scale_y.inverse_transform(model_adagrad.predict(X_test))\n",
    "predict_rmsprop = scale_y.inverse_transform(model_rmsprop.predict(X_test))\n",
    "predict_adam = scale_y.inverse_transform(model_adam.predict(X_test))\n",
    "predict_reduce_lr = scale_y.inverse_transform(model_reduce_lr.predict(X_test))\n",
    "\n",
    "\n",
    "previsoes_modelos = [valor_real_teste, predict_epoch_decay, predict_exponential_decay, predict_warm_restarts, predict_adagrad, predict_rmsprop, predict_adam, predict_reduce_lr]\n",
    "nome_modelos = ['Real', 'epoch_decay', 'exponential_decay', 'warm_restarts', 'adagrad', 'rmsprop', 'adam', 'reduce_lr']\n",
    "\n",
    "comparar_previsoes(data_teste, previsoes_modelos, nome_modelos)\n",
    "\n",
    "for cont in range(len(previsoes_modelos)-1):\n",
    "    metricas_modelo(nome_modelos[cont+1], previsoes_modelos[cont+1], valor_real_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marcando o tempo de fim\n",
    "fim = time.time()\n",
    "\n",
    "# Calculando o tempo total de execução\n",
    "tempo_execucao = fim - inicio\n",
    "\n",
    "print(f\"Tempo de execução: {tempo_execucao} segundos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
