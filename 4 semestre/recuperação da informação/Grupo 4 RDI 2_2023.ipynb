{"cells":[{"cell_type":"markdown","metadata":{"id":"-1m3pgE3ynMj"},"source":["# Avaliação Prática: Recuperação da Informação\n","\n","### Bacharelado em Ciência de Dados e Machine Learning (Inteligência Artificial)\n","### Faculdade de Tecnologia e Ciências Sociais Aplicadas - FATEC\n","### Centro de Ensino Superior de Brasília - CEUB\n","\n","\n","\n","---\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EWWUSEcJ5xYw"},"source":["## Componentes do Grupo\n","\n","\n","*  **Leão Pereira Neto**\n","*   Vinicius Mendes da Silva\n","*   João Gustavo Borges Souza\n","*   Enzo Silvério Borges Dias\n","*   Matheus El-Moor Pereira\n","\n","---\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QfFxdpxT4gDW"},"source":["## Orientações\n","\n","Desenvolver um sistema de recuperação de informação (webscraping) que possa ser usado para buscar informações sobre preços em e-commerces ou comparativos.\n","\n","**Nota total:** 100\n","\n","\n","\n","## Prazo final de entrega:\n","\n","O trabalho deve ser entregue **até o dia 07/12/2023**, às 12h00.\n","\n","**Para a entrega do te trabalho, ocultem ou excluam essa seção**\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eMUCazB-zzVr"},"source":["#INTRODUÇÃO\n","\n","***conforme orientações do Classroom***\n","\n","***Introdução***\n","\n","\tUtilizando a Biblioteca Selenium para realizar o Web Scraping no site do Mercado Livre, com o intuito de extrair informações sobre as placas de vídeo do modelo RTX. Portanto, a partir do uso dessa técnica foi possível extrair dados de forma automatizada, e sendo útil para a coleta de informações.  As informações extraídas foram: títulos, preços, avaliações e informações de frete dos produtos listados.\n","\t\n","\tSendo assim, a realização do Web Scraping permitiu o acesso a informações específicas de produtos disponíveis no Mercado Livre de maneira automatizada, para assim, facilitar a análise e comparação de diferentes ofertas de placas de vídeo RTX.\n","\n","***Teoria sobre RI focada em Webscraping***\n","\n","\tOs processos de Recuperação da informação (R.I) se aprimoraram muito com os avanços da era digital, possibilitando o uso de todo o ambiente Web para a sintese de informação, tomada de decisão e até como se fosse uma extensao do próproio ambiente de trabalho.\n","\n","\tA recuperação da informação tem uma importância estratégica, pois na sociedade atual a informação e o conhecimento são recursos estratégicos utilizados para aprimorar a atuação de profissionais, empresas, organizações, governos, pessoas etc. A tirar pelas noticias de vazemento de informações - a titulo de exemplo: https://www.tecmundo.com.br/seguranca/214952-vazamento-dados-expoe-500-milhoes-de-usuarios-facebook.htm - sempre temos um amplo alcance hoje em dia mesmo com uma simples busca na web.\n","\n","\tHoje há diversos modelos de RI: Booleano, Vetorial e Probabilistico. No modelo Booleano temos uma dicotonomia emtre os documentos que são classificados como relevantes ou não. Já no modelo Vetorial temos uma ordenação de resultados que atendem os parametros estabelecidos conforme um grau de similaridade. E o modelo probabilistico é julgado conforme os retornos o usuário ao resultado da ultima busca. \n","\n","\tA raspagem de dados da web ou Web Scraping é a coleta de dados de sites por meio do HTTP ou dos navegadores web, para assim, convertê-los em informação estruturada para posterior análise. Portanto, o Web Scraping ou coleta de dados é uma solução para quem deseja adquirir acesso a dados estruturados da web.\n","    \n","\tO Web Scraping pode ser usado para monitorar preços, notícias, pesquisa de mercado, entre outras opções. Sendo assim, o uso da web scraping por pessoas e empresas possibilita o acesso a uma grande quantidade de dados da web, para assim, conseguir tomar decisões inteligentes.\n","\n","\tO maior exemplo de RI focada em webscrapping é o proprio google que se utiliza de um modelo probabilistico para ir rankeando os resultados conforme o uso continuo do usuário. \n","\n","\n","\n","***Webscrapping para e-commerce***\n","\n","    No ambiente dos e-commerce é necessário que as empresas desse ramo adotem preços competitivos como parte de sua estratégia de negócio. Para alcançar o sucesso é inegável a necessidade de monitorar de perto as estratégias de preços dos concorrentes. Dessa forma, é possível basear-se nos dados de preços extraídos dos concorrentes, para assim, ajustar os próprios preços de maneira estratégica.\n","    \n","\tO Web Scraping possibilita adquirir a inteligência de preço ao extrair informações de produtos e preços de sites de e-commerce. Transformando esses dados em inteligência, as empresas podem tomar decisões mais informadas sobre a precificação, tornando a coleta de dados nesse segmento crucial para aprimorar estratégias e decisões empresariais.\n","    \n","\tDesse modo, o uso do Web Scraping no e-commerce possibilita a extração de dados relativos a produtos e preços de diversas plataformas de e-commerce. Após a captura desses dados as empresas podem realizar análises com o objetivo de estimar os concorrentes e compreender o panorama do mercado.\n","    \n","\tOs benefícios dos dados de preços na web e a inteligência de preços:\n","        1)Implementação de precificação dinâmica;\n","        2)Otimização da receita;\n","        3)Acompanhamento dos concorrentes;\n","        4)Garantia de conformidade de marca e MAP (Preço Mínimo Anunciado).\n","    \n","\tCom a ajuda do Web Scraping, torna-se viável identificar as pesquisas de mercado realizadas pelos consumidores, comparar preços de produtos em diversas lojas e monitorar o tempo de permanência em determinados sites, entre outras possibilidades.\n","\n","\n","\n","***Referencias ***\n","\n","\tRepresentação e recuperação da informação na web: aspectos teóricos e tecnológicos - Pesq. Bras. em Ci. da Inf. e Bib., João Pessoa, v. 13, n. 2, p. 409-426, 2018.\n","\n","\tSistemas de Recuperação de Informações e Mecanismos de Busca na web : panorama atual e tendências - Perspect. ciênc. inf., Belo Horizonte, v.11 n.2, p. 161 -173, mai./ago. 2006\n","\n","\t\n","\n","\n","\t\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"67Fk0vgl0g4e"},"source":["##REVISÃO TEÓRICA\n","\n","O objetivo da busca é buscar o melhor valor de uma placa de vídeo RTX, levando em consideração o preço, as avaliações e o valor do frete. Para melhorar a informação recuperada, será feito um tratamento dos dados captados, através de bibliotecas do pandas como descrição de valores (minimo, média, máximo, quartis), eliminação de valores nulos, tratativas dos dados (conversão caso necessário). E por fim, seleção do melhor produto captado através da informação capturada pelo Webscrapping\n","\n","\n","\n","---\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"brqGqi4X1vu8"},"source":["## REVISÃO TEÓRICA\n","\n","\n","**SUBSTITUA ESSE TEXTO, INCLUA O QUE FOI ELABORADO PELO GRUPO***\n","\n","* **Ponto importante**: ainda não é o seu TCC, então não precisam escrever várias laudas sobre toda a revisão literária sobre webscraping;\n","\n","Existem diversas formas de se praticar a recuperação de informação atraves do python e webscrapping. A biblioteca Requets é excelente para requisições mais complicadas, com diversos cookies e detalhes da pagina. \n","\n","Contudo a biblioteca selecionada foi o Selenium, que a principio foi desenvolvida para teste de sites. Hoje ele não tem nenhum navegador proprio, por isso, para sua correta execução é necessário tambem baixar um driver para o navegador de preferencia. No caso, o navegador selecionado pelo grupo foi o Chrome (Google), sendo necessário baixar o chromedriver compativel - https://googlechromelabs.github.io/chrome-for-testing/#stable.\n","\n","Para quem prefere utilizar em \"segundo plano\", ainda é possivel a utilização do PhantomJS.\n","\n","O Selenium é uma biblioteca que permite usar o objeto WebDriver como uma interface de programação de aplicativos (API). O WebDriver funciona de forma semelhante a um navegador, pois pode acessar sites, mas também pode ser usado como um objeto BeautifulSoup para localizar elementos da página, interagir com eles (digitar, clicar etc.) e realizar outras ações para controlar os web scrapers.\n","\n","Um dos beneficios do Selenium foi a utilização de localizadores no campo de busca na página (usando o atributo name \"as_word\") e insere a consulta search_query. Em seguida, pressiona a tecla Enter para iniciar a pesquisa.\n","\n","Claro que a depender do site de busca, podemos implementar o Selenium com algumas condições esperadas de usuários para que não pareca uma captura de informações e não ative os \"mecanismos de defesa\" do site. Aqui, temos o time.sleep(5) que espera por 5 segundos (pode ser substituído por WebDriverWait para tornar o código mais robusto, esperando até que certos elementos estejam presentes na página).\n","\n","O Xpath -  linguagem de consulta e seleção de elementos do XML - foi usado para extrair títulos, preços, avaliações e informações de frete. O BeautifulSoup não tem suporte para XPath, um dos motivos pelo qual foi feita a exclusão do seu uso. \n","\n","Por fim, a biblioteca Pandas foi utilizada para tratativa dos dados e extração do melhor resultado possivel para a busca feita. \n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qilewqQS2Mep"},"source":["#PRÁTICA\n","\n","```\n","Nesta seção inicia a prática do seu trabalho, insira abaixo o código produzido e ***comentado***\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85KoBx3d2ip_"},"outputs":[],"source":["#Web Scraping RDI- Avaliação Final\n","#INSIRA AQUI O CÓDIGO PRODUZIDOPELO GRUPO E NÃO ESQUEÇA OS COMENTÁRIOS"]},{"cell_type":"markdown","metadata":{"id":"q2qf1Km_2wDP"},"source":["\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UFV0lfCb2_Fk"},"source":["#RESULTADOS\n","\n","**SUBSTITUA ESSE TEXTO**\n","\n","Escreva de forma objetiva os resultados apresentados no seu Scraping;\n","\n","Se tiver duvidas, consulte o material de Orientação [AQUI](https://sway.office.com/4XVzlyoFto3z9IU0?ref=Link&authuser=0\n",")\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PJyyjBir3d4e"},"source":["#ESPAÇO PARA O PROFESSOR\n","\n","* Avaliação;\n","* Comentários;\n","* Menção Final;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4XeJ1x-3OVh"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP9jeB9ZsLyw3oYx28ZdReb","provenance":[{"file_id":"1Zd8B2wrE9WTbfyfrB5gvL3pSBfVB4fBL","timestamp":1701677499309},{"file_id":"1QoscMA0JCTknptmZwejwgLGq-k3HaZzp","timestamp":1701677389871},{"file_id":"1v7Dk5z1qt8bPJFSC1dqUN29WDXSqiMJ6","timestamp":1701677343779}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
