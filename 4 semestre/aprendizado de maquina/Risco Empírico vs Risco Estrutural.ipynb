{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Risco em Aprendizado de Máquina\n",
    "\n",
    "A aprendizagem de máquina é, em essência, sobre a construção de modelos a partir de dados. No entanto, como podemos saber se um modelo é 'bom'? E o que realmente significa dizer que um modelo é 'bom'?\n",
    "\n",
    "É aqui que entram os conceitos de **risco empírico** e **risco estrutural**. Eles nos ajudam a quantificar quão bem nossos modelos estão desempenhando e onde podem estar falhando. Entender esses conceitos não apenas nos ajuda a construir modelos melhores, mas também a compreender os limites fundamentais do que nossos modelos são capazes de aprender a partir de dados.\n",
    "\n",
    "## Risco Empírico vs. Risco Estrutural\n",
    "\n",
    "- **Risco Empírico:** Este é o erro que vemos nos nossos dados de treinamento. Ele nos diz quão bem nosso modelo está se ajustando aos dados com os quais foi treinado. É, efetivamente, uma medida do erro de treinamento.\n",
    "\n",
    "- **Risco Estrutural:** Este é um pouco mais abstrato. Refere-se ao erro que nós esperaríamos ver em novos dados, ou em outras palavras, o erro em um novo conjunto de dados que nosso modelo nunca viu antes. Dá-nos uma ideia da capacidade de generalização do nosso modelo. Em essência, é uma medida do erro de teste ou validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Definindo a semente aleatória para garantir que os resultados sejam reprodutíveis.\n",
    "np.random.seed(0)\n",
    "\n",
    "# Gerando 80 números aleatórios entre 0 e 5. \n",
    "# np.random.rand(80, 1) cria um array 80x1 de números aleatórios entre 0 e 1.\n",
    "# Multiplicar por 5 escala esses números para o intervalo [0,5].\n",
    "# A função np.sort() é usada para ordenar esses números em ordem crescente.\n",
    "X = np.sort(5 * np.random.rand(80, 1), axis=0)\n",
    "\n",
    "# Criando a saída 'y' baseada em 'X'.\n",
    "# np.sin(X) calcula o seno de cada valor em 'X'.\n",
    "# .ravel() é usado para transformar o array 2D em 1D (achatar o array).\n",
    "# np.random.normal(0, 0.5, X.shape[0]) adiciona ruído aos dados. \n",
    "# Esse ruído é gerado de uma distribuição normal com média 0 e desvio padrão 0.5.\n",
    "# O ruído é adicionado para simular variações reais nos dados e torná-los menos perfeitos.\n",
    "y = np.sin(X).ravel() + np.random.normal(0, 0.5, X.shape[0])\n",
    "\n",
    "\n",
    "# Plotando os dados\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Dados de Demonstração\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array de 2 D\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array de 1 D\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risco Empírico\n",
    "\n",
    "Quando falamos sobre treinar modelos de aprendizado de máquina, muitas vezes estamos tentando minimizar algum tipo de erro. No contexto de regressão, por exemplo, queremos minimizar a diferença entre as previsões do nosso modelo e os valores reais. Esta diferença é muitas vezes referida como \"erro\".\n",
    "\n",
    "\n",
    "## Como é Calculado\n",
    "\n",
    "Vamos usar uma analogia para tornar isso mais simples. Imagine que você esteja tentando acertar dardos em um alvo. Cada vez que você joga o dardo e erra o centro, você tem um erro - a distância entre onde o dardo acertou e o centro do alvo.\n",
    "\n",
    "Agora, vamos elevar ao quadrado essa distância. Por que elevar ao quadrado? Porque queremos que os erros maiores tenham um impacto ainda maior. Então, se você errar o alvo por uma pequena distância, terá um pequeno erro quadrático. Mas se errar por uma grande distância, o erro quadrático será muito maior.\n",
    "\n",
    "O **risco empírico**, então, é a média de todos esses erros quadráticos nos nossos dados de treinamento. É como uma média das \"penalidades\" por cada erro que nosso modelo comete.\n",
    "\n",
    "Isso é o que chamamos de Erro Quadrático Médio ou, em inglês, Mean Squared Error (MSE).\n",
    "\n",
    "Para quem gosta de fórmulas:\n",
    "\n",
    "### Erro Quadrático Médio (MSE - Mean Squared Error)\n",
    "\n",
    "Dado um conjunto de observações reais \\( y_1, y_2, ..., y_n \\) e suas respectivas previsões \\( \\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_n \\), o MSE é calculado como:\n",
    "\n",
    "\\[ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \\]\n",
    "\n",
    "Onde:\n",
    "- \\( n \\) é o número total de observações (ou exemplos).\n",
    "- \\( y_i \\) é o valor real da i-ésima observação.\n",
    "- \\( \\hat{y}_i \\) é o valor previsto pelo modelo para a i-ésima observação.\n",
    "- \\( \\sum \\) denota a soma de todos os termos.\n",
    "\n",
    "Em palavras simples:\n",
    "O MSE é a média dos quadrados das diferenças entre os valores reais e os valores previstos. Ele mede o quanto, em média, as previsões do nosso modelo estão distantes dos valores reais.\n",
    "\"\n",
    "\n",
    "## Destaque: Referente ao Erro no Conjunto de Treinamento\n",
    "\n",
    "O risco empírico se refere especificamente ao erro no conjunto de treinamento. É uma estimativa do erro \"em amostra\", ou seja, é uma medida de quão bem nosso modelo está se ajustando aos dados que já viu. No entanto, um risco empírico baixo não garante que o modelo terá um bom desempenho em dados novos ou não vistos, o que nos leva ao conceito de risco estrutural (que será discutido posteriormente).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar Modelos\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Dados fictícios (gerados na seção anterior)\n",
    "# Aqui, vamos apenas reutilizar o exemplo anterior para calcular o risco empírico\n",
    "\n",
    "# Treinando um modelo de regressão \n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X.shape[1],)))  # Camada de entrada explícita\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Saída linear para regressão\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(X, y, epochs=20,verbose=0)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Calculando o erro quadrático médio (MSE) que é uma representação do risco empírico\n",
    "mse = mean_squared_error(y, predictions)\n",
    "\n",
    "print(f\"Risco Empírico (MSE): {mse:.3f}\")\n",
    "\n",
    "# Plotando os dados\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"Dados Reais\")\n",
    "plt.scatter(X, predictions, color=\"blue\", label=\"Previsão\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Dados de Demonstração\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados fictícios\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Treinando o modelo de regressão\n",
    "model.fit(X, y, epochs=20,verbose=0)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Calculando o Risco Empírico (erro quadrático médio)\n",
    "mse = mean_squared_error(y, predictions)\n",
    "print(f\"Risco Empírico (MSE): {mse:.3f}\")\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"Dados Reais\")\n",
    "plt.scatter(X, predictions, color=\"blue\", label=\"Previsão\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Dados de Demonstração\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='blue', label='Dados reais')\n",
    "plt.plot(X, predictions, color='red', label='Regressão linear')\n",
    "plt.title('Regressão Linear e Resíduos')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "\n",
    "# Plotando os resíduos\n",
    "for i in range(len(X)):\n",
    "    plt.plot([X[i], X[i]], [y[i], predictions[i]], color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting e Underfitting\n",
    "\n",
    "Quando estamos treinando modelos de aprendizado de máquina, muitas vezes nos encontramos no dilema de quão complexo nosso modelo deve ser. Essa complexidade pode levar a dois cenários opostos, mas problemáticos: **overfitting** e **underfitting**.\n",
    "\n",
    "## O que são Overfitting e Underfitting?\n",
    "\n",
    "- **Overfitting (sobreajuste):** Acontece quando o modelo é excessivamente complexo e começa a \"decorar\" os dados de treinamento em vez de aprender padrões generalizáveis. Um modelo que sofre de overfitting terá um desempenho muito bom (baixo erro) no conjunto de treinamento, mas um desempenho ruim (erro alto) em dados novos ou no conjunto de teste.\n",
    "\n",
    "- **Underfitting (subajuste):** Ocorre quando o modelo é muito simples para capturar os padrões subjacentes dos dados. Em termos práticos, isso significa que o modelo tem um desempenho ruim tanto no conjunto de treinamento quanto no conjunto de teste.\n",
    "\n",
    "## Relação com o Risco Empírico\n",
    "\n",
    "O risco empírico nos dá uma visão do desempenho do nosso modelo no conjunto de treinamento. Portanto:\n",
    "\n",
    "- Se um modelo apresenta um risco empírico muito baixo (ou erro de treinamento), mas tem um erro alto em um conjunto de validação/teste, é provável que esteja sofrendo de **overfitting**.\n",
    "  \n",
    "- Por outro lado, se um modelo tem um risco empírico alto e também tem um alto erro de validação/teste, está provavelmente **underfitting** os dados.\n",
    "\n",
    "O desafio no aprendizado de máquina é encontrar o equilíbrio certo entre um modelo suficientemente complexo para aprender padrões significativos nos dados, mas não tão complexo que comece a memorizar ruídos ou variações aleatórias no conjunto de treinamento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "**Dropout** é uma técnica de regularização para redes neurais. Ela ajuda a prevenir o overfitting das seguintes maneiras:\n",
    "\n",
    "- **Desligamento Aleatório**: Durante o treinamento, neurônios específicos são \"desligados\" aleatoriamente. Isso significa que eles não têm impacto durante uma iteração específica do treinamento.\n",
    "  \n",
    "- **Previne Dependências**: Ao desligar neurônios aleatoriamente, a rede evita desenvolver dependências excessivas em qualquer neurônio particular, incentivando a rede a ser mais robusta e a distribuir o aprendizado.\n",
    "\n",
    "- **Aumenta a Generalização**: Como o modelo não pode confiar em qualquer neurônio específico, ele se torna mais generalizado, reduzindo a chance de overfitting.\n",
    "\n",
    "- **Camadas Iniciais vs. Camadas Profundas**: Muitas vezes, o dropout é mais benéfico nas camadas mais profundas da rede. As camadas iniciais tendem a aprender características mais gerais e básicas dos dados, enquanto as camadas mais profundas aprendem características mais complexas e específicas. Portanto, desativar aleatoriamente neurônios nas camadas iniciais pode não ser tão eficaz quanto nas camadas mais profundas.\n",
    "\n",
    "**Taxa de Dropout**: A taxa de dropout também é um hiperparâmetro importante. Uma taxa muito alta pode levar a underfitting, pois muitos neurônios são desligados, enquanto uma taxa muito baixa pode não proporcionar regularização suficiente.\n",
    "\n",
    "---\n",
    "\n",
    "## Regularização L1 e L2\n",
    "\n",
    "Ambas são técnicas de regularização que adicionam uma penalidade ao termo de custo/loss da rede, ajudando a evitar overfitting.\n",
    "\n",
    "- **L1 (Lasso)**:\n",
    "  - Adiciona a soma absoluta dos valores dos pesos à função de loss.\n",
    "  - Pode levar a alguns pesos se tornarem exatamente zero, o que é útil para seleção de características.\n",
    "  \n",
    "- **L2 (Ridge)**:\n",
    "  - Adiciona a soma quadrada dos valores dos pesos à função de loss.\n",
    "  - Mantém todos os pesos pequenos, distribuindo a influência dos pesos de forma mais uniforme.\n",
    "  \n",
    "- **Como ajudam**:\n",
    "  - Penalizando pesos grandes: Modelos com pesos grandes são complexos e podem ajustar demais aos dados de treinamento. Penalizando esses pesos, incentivamos o modelo a ser mais simples.\n",
    "  - Distribuição uniforme: Ao distribuir a influência de características/pesos de forma mais uniforme, evitamos que certas características dominem as previsões, levando a um modelo mais generalizável.\n",
    "\n",
    "- **Escolhendo entre L1 e L2**: \n",
    "  - Em alguns casos, você pode querer usar apenas L1 ou apenas L2. Se você perceber que seu modelo `tem muitos pesos e suspeita que muitos deles possam ser irrelevantes`, o L1 pode ajudar a induzir esparsidade. Se você apenas quer `penalizar pesos grandes` sem induzir esparsidade, o L2 pode ser mais apropriado.\n",
    "\n",
    "- **Primeiras vs Últimas Camadas**: \n",
    "  - A regularização nas primeiras camadas pode afetar mais drasticamente o modelo, uma vez que os erros ali propagarão através da rede. Se você estiver encontrando overfitting, pode começar regularizando as camadas finais e, se necessário, mover-se para as camadas anteriores. Isso permite manter as características mais fundamentais (aprendidas nas primeiras camadas) menos penalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Ordenando os dados para que os plots fiquem mais intuitivos\n",
    "X_sorted = np.sort(X, axis=0)\n",
    "\n",
    "# Modelo de Overfitting: \n",
    "# Usamos um modelo polinomial de grau 15 para intencionalmente causar overfitting.\n",
    "# Isso cria um modelo muito complexo que tentará ajustar todos os pontos dos dados, incluindo o ruído.\n",
    "overfitting_model = make_pipeline(PolynomialFeatures(15), LinearRegression())\n",
    "overfitting_model.fit(X, y)\n",
    "overfitting_predictions = overfitting_model.predict(X_sorted)\n",
    "\n",
    "# Modelo de Underfitting: \n",
    "# Usamos um simples modelo de regressão linear. \n",
    "# Dado que os dados originais são não-lineares, um modelo linear não capturará bem a relação, causando underfitting.\n",
    "underfitting_model = LinearRegression()\n",
    "underfitting_model.fit(X, y)\n",
    "underfitting_predictions = underfitting_model.predict(X_sorted)\n",
    "\n",
    "\n",
    "# Modelo equilibrado: Polinomial de grau 3\n",
    "# Um polinômio de grau 3 pode capturar relações não-lineares enquanto evita o superajuste.\n",
    "balanced_model = make_pipeline(PolynomialFeatures(3), LinearRegression())\n",
    "balanced_model.fit(X, y)\n",
    "balanced_predictions = balanced_model.predict(X_sorted)\n",
    "\n",
    "\n",
    "# Calculamos o Risco Empírico (MSE) para ambos os modelos.\n",
    "# Isso nos dá uma métrica de desempenho sobre como cada modelo se ajusta aos dados de treinamento.\n",
    "mse_overfitting = mean_squared_error(y, overfitting_model.predict(X))\n",
    "mse_underfitting = mean_squared_error(y, underfitting_model.predict(X))\n",
    "mse_balanced = mean_squared_error(y, balanced_model.predict(X))\n",
    "\n",
    "\n",
    "# Imprimindo os erros quadráticos médios para ambos os modelos\n",
    "print(f\"Risco Empírico do modelo Overfitting (MSE): {mse_overfitting:.3f}\")\n",
    "print(f\"Risco Empírico do modelo Underfitting (MSE): {mse_underfitting:.3f}\")\n",
    "print(f\"Risco Empírico do modelo equilibrado (MSE): {mse_balanced:.3f}\")\n",
    "\n",
    "\n",
    "# Plotando os resultados:\n",
    "# Este gráfico mostrará a diferença entre um modelo que sofre de overfitting, \n",
    "# um modelo que sofre de underfitting e os dados reais.\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X, y, color='blue', s=20, label='Dados reais')  # Plotando os dados reais\n",
    "plt.plot(X_sorted, overfitting_predictions, color='red', label='Overfitting (polinomial de grau 15)')  # Plotando as previsões do modelo overfitting\n",
    "plt.plot(X_sorted, underfitting_predictions, color='green', linestyle='--', label='Underfitting (linear simples)')  # Plotando as previsões do modelo underfitting\n",
    "plt.plot(X_sorted, balanced_predictions, color='orange', linestyle='-.', label='Modelo Equilibrado (polinomial de grau 3')  # Plotando as previsões do modelo underfitting\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Overfitting vs. Underfitting')\n",
    "plt.legend()  # Adicionando a legenda ao gráfico\n",
    "plt.show()  # Mostrando o gráfico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos Polinomiais de Diferentes Graus\n",
    "\n",
    "Os modelos polinomiais são uma extensão da regressão linear que visa capturar padrões não-lineares nos dados. Em vez de ajustar apenas uma linha reta (como na regressão linear), os modelos polinomiais tentam ajustar uma curva aos dados.\n",
    "\n",
    "### O que é um Grau Polinomial?\n",
    "\n",
    "O grau do polinômio se refere ao maior expoente da variável em uma equação polinomial. Na regressão polinomial, este grau determina a complexidade da curva que o modelo tentará ajustar aos dados.\n",
    "\n",
    "Por exemplo:\n",
    "- **Grau 1:** \\( y = ax + b \\)\n",
    "  - Isto é apenas regressão linear. Não é uma curva, mas uma linha reta.\n",
    "- **Grau 2:** \\( y = ax^2 + bx + c \\)\n",
    "  - Isto representa uma parábola.\n",
    "- **Grau 3:** \\( y = ax^3 + bx^2 + cx + d \\)\n",
    "  - Uma curva mais complexa que pode ter pontos de inflexão.\n",
    "\n",
    "### Como o Grau Afeta o Modelo?\n",
    "\n",
    "- **Modelos de baixo grau (e.g., 1 ou 2)** podem não capturar todos os padrões nos dados, especialmente se a relação entre as variáveis for muito complexa. Isso pode levar a \"underfitting\", onde o modelo não se ajusta bem nem aos dados de treinamento nem a novos dados.\n",
    "\n",
    "- **Modelos de grau muito alto** podem se ajustar demais aos dados de treinamento, capturando o ruído e as variações aleatórias nos dados, o que pode levar ao \"overfitting\". Embora possa parecer excelente no conjunto de treinamento, pode se sair mal em dados novos ou não vistos, porque ele se ajustou muito especificamente aos dados de treinamento.\n",
    "\n",
    "### Então, Qual Grau Escolher?\n",
    "\n",
    "Não existe uma resposta única. A escolha do grau depende dos dados e do problema em questão. Normalmente, começamos com um grau baixo e aumentamos gradualmente, avaliando o desempenho do modelo em um conjunto de validação para evitar o overfitting. Ferramentas como validação cruzada podem ser úteis para determinar o grau ideal para um conjunto específico de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prática: Visualização de Overfitting e Underfitting\n",
    "\n",
    "Para entender de forma mais prática o que discutimos anteriormente sobre overfitting e underfitting, vamos realizar uma demonstração usando o mesmo conjunto de dados. Vamos treinar modelos de regressão polinomial com diferentes graus e observar como a complexidade do modelo (aumentando o grau do polinômio) pode levar a diferentes comportamentos.\n",
    "\n",
    "Neste exercício, vamos:\n",
    "\n",
    "- Treinar modelos polinomiais de diferentes graus.\n",
    "- Visualizar como esses modelos se ajustam aos dados.\n",
    "- Calcular o risco empírico para cada grau do polinômio e identificar onde o modelo pode estar superajustando ou subajustando.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [1, 3, 10, 15]  # Graus dos polinômios para experimentação\n",
    "risks = []  # Lista para armazenar o risco empírico para cada grau\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Looping para treinar e plotar cada modelo\n",
    "for i, degree in enumerate(degrees):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    model.fit(X, y)\n",
    "    predictions = model.predict(X_sorted)\n",
    "    \n",
    "    mse = mean_squared_error(y, model.predict(X))\n",
    "    risks.append(mse)\n",
    "    \n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.scatter(X, y, color='blue', s=20, label='Dados reais')\n",
    "    plt.plot(X_sorted, predictions, color='red', label=f'Grau {degree}')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'Modelo Polinomial - Grau {degree} - MSE {round(mse,4)}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos Resultados\n",
    "Observando os gráficos acima, podemos identificar claramente os casos de underfitting e overfitting:\n",
    "\n",
    "**Grau 1 (Linear)**: O modelo é muito simples e não capta a curvatura dos dados, resultando em **underfitting**.\n",
    "\n",
    "**Grau 3**: Este parece um bom equilíbrio, capturando a tendência dos dados sem se ajustar demais a pequenas variações.\n",
    "\n",
    "**Grau 10 e 15**: São exemplos claros de **overfitting**. Os modelos estão tentando se ajustar a cada ponto de dado, incluindo o ruído, resultando em curvas irregulares que não representarão bem dados novos.\n",
    "\n",
    "Vamos verificar o risco empírico para cada grau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree, risk in zip(degrees, risks):\n",
    "    print(f\"Risco Empírico (MSE) para polinômio de grau {degree}: {risk:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teoria: Risco Estrutural\n",
    "\n",
    "O risco estrutural refere-se ao erro que um modelo fará independentemente da amostra de treinamento, ou seja, é intrínseco à arquitetura do modelo escolhido. Para entender melhor, consideremos dois extremos:\n",
    "\n",
    "1. Um modelo extremamente simples (como uma regressão linear simples para dados que têm uma relação polinomial). Nesse caso, o modelo não terá capacidade suficiente para aprender a verdadeira relação subjacente dos dados. Isso é chamado de **underfitting**.\n",
    "   \n",
    "2. Um modelo extremamente complexo (como um polinômio de alto grau para dados simplesmente lineares). Nesse caso, o modelo terá capacidade excessiva, tentando se ajustar a cada ponto de dado, incluindo o ruído. Isso é chamado de **overfitting**.\n",
    "\n",
    "Ambos os casos refletem o risco estrutural do modelo, que está diretamente relacionado com sua capacidade.\n",
    "\n",
    "## Risco Empírico vs. Risco Estrutural\n",
    "\n",
    "Enquanto o **risco empírico** refere-se ao erro do modelo no conjunto de treinamento (como o modelo se ajusta aos dados que já vimos), o **risco estrutural** refere-se ao erro que podemos esperar que o modelo faça em novos dados, devido à sua complexidade ou simplicidade intrínseca.\n",
    "\n",
    "Em resumo:\n",
    "\n",
    "- **Risco Empírico**: Erro no conjunto de treinamento.\n",
    "- **Risco Estrutural**: Erro inerente ao modelo, independentemente do conjunto de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prática: Demonstração de Risco Estrutural\n",
    "\n",
    "Uma das maneiras mais eficazes de demonstrar o risco estrutural é mostrando que, mesmo que um modelo tenha um risco empírico baixo (isto é, ele se ajuste bem aos dados de treinamento), ele pode não generalizar bem para novos dados. Esta é uma indicação de que o modelo pode estar superajustando (overfitting) ao conjunto de treinamento.\n",
    "\n",
    "Nesta seção, usaremos conjuntos de treinamento e teste para demonstrar esse conceito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de diferentes graus polinomiais que queremos testar\n",
    "degrees = [1, 3, 10, 15]\n",
    "\n",
    "# Listas para armazenar os erros do modelo em dados de treino e teste\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Configurando a figura para a visualização dos resultados\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Loop para cada grau polinomial especificado na lista 'degrees'\n",
    "for i, degree in enumerate(degrees):\n",
    "    \n",
    "    # Criando um modelo polinomial de um certo grau e, em seguida, \n",
    "    # aplicando regressão linear sobre esses recursos polinomiais\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    \n",
    "    # Treinando o modelo nos dados de treino\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazendo previsões nos dados de treino e teste\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculando o erro quadrático médio (MSE) para as previsões de treino e teste\n",
    "    train_mse = mean_squared_error(y_train, train_predictions)\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    \n",
    "    # Adicionando os MSEs calculados às respectivas listas\n",
    "    train_errors.append(train_mse)\n",
    "    test_errors.append(test_mse)\n",
    "    \n",
    "    # Configurando um subplot para visualizar o ajuste do modelo aos dados\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    \n",
    "    # Plotando os dados de treino e teste\n",
    "    plt.scatter(X_train, y_train, color='blue', s=20, label='Dados de Treino')\n",
    "    plt.scatter(X_test, y_test, color='green', s=20, label='Dados de Teste')\n",
    "    \n",
    "    # Plotando as previsões do modelo\n",
    "    plt.plot(X_sorted, model.predict(X_sorted), color='red', label=f'Grau {degree}')\n",
    "    \n",
    "    # Configurando os rótulos dos eixos e o título do subplot\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'Modelo Polinomial - Grau {degree} - MSE Train {round(train_mse,3)} - MSE Test {round(test_mse,3)}')\n",
    "    \n",
    "    # Adicionando a legenda ao subplot\n",
    "    plt.legend()\n",
    "\n",
    "# Ajustando a layout da figura para que os subplots não se sobreponham\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exibindo a figura completa\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos Resultados\n",
    "Conforme aumentamos a complexidade do modelo (aumentando o grau do polinômio), observamos que o modelo começa a se ajustar muito bem ao conjunto de treinamento (risco empírico baixo). No entanto, ao mesmo tempo, o desempenho no conjunto de teste (novos dados) pode começar a piorar. Isso indica um aumento no risco estrutural, onde o modelo não generaliza bem para novos dados.\n",
    "\n",
    "Vamos verificar os erros de treinamento e teste para cada grau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree, train_error, test_error in zip(degrees, train_errors, test_errors):\n",
    "    print(f\"Grau {degree} - Erro de Treinamento (MSE): {train_error:.3f}, Erro de Teste (MSE): {test_error:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "\n",
    "Ao longo desta aula, exploramos conceitos profundos e essenciais em aprendizado de máquina, particularmente os conceitos de **risco empírico** e **risco estrutural**.\n",
    "\n",
    "\n",
    "## Revisão dos conceitos\n",
    "\n",
    "1. **Risco Empírico**: É o erro que observamos no conjunto de treinamento. Mede quão bem nosso modelo ajusta-se aos dados de treino.\n",
    "2. **Risco Estrutural**: Representa a capacidade do modelo de generalizar para novos dados. Ele nos dá uma noção de quão bem um modelo performará em dados não vistos.\n",
    "3. **Overfitting**: Quando um modelo é excessivamente complexo e ajusta-se muito bem aos dados de treinamento, capturando até mesmo o ruído, mas falha em generalizar para novos dados.\n",
    "4. **Underfitting**: Quando um modelo é muito simples e não consegue capturar as tendências subjacentes dos dados, resultando em performance ruim tanto no treinamento quanto em dados não vistos.\n",
    "5. **Dropout**: Técnica de regularização para redes neurais que \"desliga\" aleatoriamente neurônios durante o treinamento. Ajuda a evitar overfitting ao forçar representações mais robustas dos dados.\n",
    "6. **Regularização L1 (Lasso)**: Adiciona penalidade proporcional ao valor absoluto dos coeficientes. Pode zerar alguns coeficientes, ajudando na seleção de características relevantes.\n",
    "7. **Regularização L2 (Ridge)**: Penaliza coeficientes com base no seu quadrado. Mantém coeficientes pequenos, distribuídos suavemente, ideal quando todos os recursos são relevantes.\n",
    "\n",
    "\n",
    "Entender os conceitos de risco empírico e estrutural é crucial para desenvolver modelos robustos e eficientes em aprendizado de máquina. Não se trata apenas de construir um modelo que performa bem nos dados de treinamento, mas que também seja capaz de generalizar bem para novos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício\n",
    "- A base de dados notebooks já está com todos os valores numéricos;\n",
    "- A base possui o valor como sendo a classe alvo;\n",
    "- A base possui 3 colunas com valores aleatórios para atrapalhar a previsão dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('notebooks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos aprender mais conceitos importandes...\n",
    "\n",
    "A normalização dos dados não deve ser feita da forma que estávamos fazendo rsrs (Separa os dados em X e y, normaliza X e Y e separa em treinamento validação e teste).\n",
    "\n",
    "A normalização deve seguir os passos:\n",
    "- 1° Separar os dados em X e y;\n",
    "- 2° Separar os dados em treinamento, validação e teste (ou treinamento e teste);\n",
    "- 3° Normalizar X e y de treinamento (Usar o fit_transform);\n",
    "- 4° Normalizar X e y de validação e teste (usar apenas o transform);\n",
    "\n",
    "**Razão**: Queremos calcular a média e o desvio padrão (ou máximos e mínimos, dependendo do escalonador) usando apenas os dados de treinamento. Isto é crucial porque, na prática, não teremos acesso aos dados futuros (dados de teste), então nosso modelo deve ser construído e ajustado apenas com base nos dados de treinamento.\n",
    "\n",
    "Em contraste, se você normalizasse todo o conjunto de dados antes de dividir em treinamento/teste, estaria vazando informações dos dados de teste para o conjunto de treinamento. Em outras palavras, você estaria usando a média e o desvio padrão (ou outros parâmetros) de todo o conjunto de dados, o que não é representativo de uma situação real e pode levar a um desempenho superestimado.\n",
    "\n",
    "**Motivo para termos aprendido errado**: Na introdução à modelagem e pré-processamento de dados, muitas vezes, simplificamos os procedimentos para facilitar o entendimento dos conceitos fundamentais. Ao normalizar X e y antes de dividir os dados em conjuntos de treinamento, validação e teste, o processo pode parecer mais linear e menos intimidante para os iniciantes, pois concentra-se primeiro na transformação dos dados e, em seguida, em sua divisão. Isso ajuda a introduzir as ideias de normalização e divisão de dados sem sobrecarregar os alunos com muitos detalhes simultaneamente.\n",
    "\n",
    "No entanto, à medida que avançamos e nos aprofundamos nas nuances da modelagem de dados, é crucial entender e adotar práticas mais robustas e realistas. Assim, passamos a enfatizar a importância de dividir os dados primeiro e depois aplicar transformações, para evitar vazamento de informações e para simular com precisão cenários do mundo real em que os modelos são aplicados a novos dados não vistos.\n",
    "\n",
    "OBS: Nunca achei uma literatura sobre isto, mas a prática que uso é:\n",
    "- 1° Separar os dados em X e y;\n",
    "- 2° Separar os dados em treinamento e temporários (são os X_temp e y_temp que serão utilizados para separar os dados de validação e teste);\n",
    "- 3° Normalizar X e y de treinamento (Usar o fit_transform);\n",
    "- 4° Normalizar X_temp e y_temp de validação e teste (usar apenas o transform);\n",
    "- 5° Separar X e y de validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forma que faço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as instâncias dos escalonizadonres\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target  = MinMaxScaler()\n",
    "\n",
    "# Separa os dados em X e y\n",
    "X = df.drop('valor', axis = 1)\n",
    "y = df[['valor']]\n",
    "\n",
    "# Separa os dados em X e y de treinamento e temporários\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normaliza e ajusta o escalonizador com os dados de X de treinamento\n",
    "X_train = scaler_features.fit_transform(X_train)\n",
    "# Normaliza e ajusta o escalonizador com os dados de y de treinamento\n",
    "y_train = scaler_target.fit_transform(y_train)\n",
    "\n",
    "# Ajusta os dados de X_temp\n",
    "X_temp = scaler_features.transform(X_temp)\n",
    "# Ajusta os dados de y_temp\n",
    "y_temp = scaler_target.transform(y_temp)\n",
    "\n",
    "# Separa os dados em X e y de validação e teste\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forma das literaturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as instâncias dos escalonizadonres\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target  = MinMaxScaler()\n",
    "\n",
    "# Separa os dados em X e y\n",
    "X = df.drop('valor', axis = 1)\n",
    "y = df[['valor']]\n",
    "\n",
    "# Separa os dados em X e y de treinamento e temporários\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normaliza e ajusta o escalonizador com os dados de X de treinamento\n",
    "X_train = scaler_features.fit_transform(X_train)\n",
    "# Normaliza e ajusta o escalonizador com os dados de y de treinamento\n",
    "y_train = scaler_target.fit_transform(y_train)\n",
    "\n",
    "# Separa os dados em X e y de validação e teste\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Ajusta os dados de X_val\n",
    "X_val = scaler_features.transform(X_val)\n",
    "# Ajusta os dados de y_val\n",
    "y_val = scaler_target.transform(y_val)\n",
    "\n",
    "# Ajusta os dados de X_test\n",
    "X_test = scaler_features.transform(X_test)\n",
    "# Ajusta os dados de y_test\n",
    "y_test = scaler_target.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "\n",
    "**Objetivo**: Ajustar diferentes modelos ao dataset do notebook e calcular o risco empírico. Sua tarefa é identificar qual modelo tem o menor risco empírico.\n",
    "\n",
    "- 1.1. Ajuste três crie os 5 modelos para regressão abaixo.\n",
    "    - Modelo com apenas 2 camadas ocultas com 5 neurônios em cada camada oculta;\n",
    "    - Modelo com 6 camadas ocultas, com respectivamente 4, 32, 32, 32, 32 e 32 neurônios;\n",
    "    - Modelo com 6 camadas ocultas, com respectivamente 4, 32, 32, 32, 32 e 32 neurônios e utilize dropout após as camadas ocultas 4 e 5 com a taxa de 0.8;\n",
    "    - Modelo com 6 camadas ocultas, com respectivamente 4, 32, 32, 32, 32 e 32 neurônios e utilize dropout após as camadas ocultas 4 e 5 com a taxa de 0.2;\n",
    "    - Modelo com 6 camadas ocultas, com respectivamente 4, 32, 32, 32, 32 e 32 neurônios e regularização de kernel L1 nas camadas ocultas 2 e 5 com a taxa de 0.02;\n",
    "- 1.2. Calcule e exiba o erro quadrático médio (MSE) no conjunto de treinamento para cada modelo (não esqueça de desnormalizar os valores reais e predito antes de realizar os cálculos).\n",
    "\n",
    "## Exercício 2\n",
    "\n",
    "**Objetivo**: Avaliar os modelos ajustados no conjunto de teste e calcular o risco estrutural.\n",
    "\n",
    "- 2.1. Use os modelos que você ajustou no exercício anterior;\n",
    "- 2.2. Calcule e exiba o erro quadrático médio (MSE) no conjunto de teste para cada modelo (não esqueça de desnormalizar os valores reais e predito antes de realizar os cálculos);\n",
    "- 2.3. Exiba um único gráfico de linhas com os valores reais e os preditos de teste pelos 5 modelos (cores para as linhas 'red', 'blue', 'green', 'yellow', 'purple' e 'cyan')(não esqueça de desnormalizar os valores reais e predito antes de exibir os gráficos);\n",
    "- 2.4. Compare os resultados. Qual modelo tem o menor risco estrutural? Ele coincide com o modelo de menor risco empírico do exercício anterior?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
