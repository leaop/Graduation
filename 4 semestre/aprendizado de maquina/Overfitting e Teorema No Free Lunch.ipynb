{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "---\n",
    "\n",
    "## Recapitulação Rápida\n",
    "\n",
    "- **Overfitting e Underfitting**: Temas recorrentes que já estudamos.\n",
    "- **Tipos de Aprendizagem**: Classificação e Regressão.\n",
    "- **Conceitos Avançados**: Risco empírico vs. risco estrutural, dimensão VC e dilema bias-variance.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos da Aula de Hoje\n",
    "\n",
    "1. **Aprofundamento em Overfitting**: Entender o que ele realmente é, como identificá-lo e como podemos prevenir ou mitigar seus efeitos.\n",
    "    - Estaremos utilizando exemplos práticos para demonstrar esses conceitos.\n",
    "  \n",
    "2. **Teorema No Free Lunch**: Explorar o que significa este teorema e quais são suas implicações para a aprendizagem de máquinas.\n",
    "    - Compreender por que não existe um algoritmo que seja o melhor para todos os problemas.\n",
    "\n",
    "---\n",
    "\n",
    "### Por que é Importante?\n",
    "\n",
    "- **Complexidade dos Modelos**: A escolha da complexidade do modelo tem um grande impacto na qualidade das previsões. \n",
    "- **Seleção de Modelos**: O Teorema No Free Lunch nos lembra que não há uma única 'bala de prata' em aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breve Recapitulação de Overfitting e Underfitting\n",
    "---\n",
    "\n",
    "## O Que é Overfitting?\n",
    "\n",
    "- **Definição**: Quando um modelo aprende o 'ruído' nos dados de treinamento a ponto de afetar negativamente o desempenho em dados não vistos.\n",
    "- **Sintomas**:\n",
    "    - Alto desempenho nos dados de treino.\n",
    "    - Baixo desempenho nos dados de teste.\n",
    "  \n",
    "---\n",
    "  \n",
    "## O Que é Underfitting?\n",
    "\n",
    "- **Definição**: Quando um modelo é demasiado simples para captar as complexidades dos dados e, por isso, apresenta desempenho ruim tanto no treino quanto no teste.\n",
    "- **Sintomas**:\n",
    "    - Baixo desempenho nos dados de treino.\n",
    "    - Baixo desempenho nos dados de teste.\n",
    "\n",
    "---\n",
    "\n",
    "## Como Detectamos Estes Fenômenos?\n",
    "\n",
    "- **Curvas de Aprendizagem**: Gráficos que mostram o desempenho do modelo em relação ao tamanho do conjunto de treinamento.\n",
    "- **Métricas de Desempenho**: Utilizando métricas como acurácia, precisão, revocação, F1-score, etc.\n",
    "  \n",
    "---\n",
    "\n",
    "**Nota**: Já abordamos esses tópicos em detalhes nas aulas anteriores. O objetivo hoje é ir além e entender como lidar com o overfitting e explorar o Teorema 'No Free Lunch'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos da Aula de Hoje\n",
    "---\n",
    "\n",
    "## Visão Geral\n",
    "\n",
    "Hoje, nosso foco será em duas áreas-chave:\n",
    "\n",
    "1. **Aprofundamento em Overfitting**: \n",
    "    - **Por que é crucial?**: O overfitting é um dos problemas mais comuns em machine learning e pode levar a resultados enganosos.\n",
    "    - **O que faremos?**: Vamos nos aprofundar na identificação, prevenção e mitigação do overfitting, utilizando exemplos práticos e técnicas específicas.\n",
    "    - **Métodos Abordados**: Regularização, Early Stopping, entre outros.\n",
    "  \n",
    "2. **Teorema No Free Lunch**:\n",
    "    - **Por que é crucial?**: Este teorema nos mostra que não existe um único algoritmo que seja ideal para todos os tipos de problemas.\n",
    "    - **O que faremos?**: Vamos entender a teoria por trás do teorema e suas implicações práticas em machine learning.\n",
    "    - **Implicações**: Escolha de algoritmos, tuning de hiperparâmetros, entre outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprofundamento em Overfitting\n",
    "---\n",
    "\n",
    "## Como Identificar Overfitting com Métricas (3 minutos)\n",
    "\n",
    "- **Validação Cruzada**: Uma forma robusta de avaliar o desempenho do modelo em diferentes subconjuntos de dados.\n",
    "- **Conjunto de Validação**: Separe um conjunto de dados para validação durante o treinamento.\n",
    "- **Métricas de Desempenho**: Acompanhe métricas como Acurácia, F1-score, etc., em ambos os conjuntos (treino e validação).\n",
    "\n",
    "---\n",
    "\n",
    "## Regularização como uma Abordagem para Mitigar Overfitting (4 minutos)\n",
    "\n",
    "- **Definição**: Técnica que adiciona um termo de penalidade à função de custo.\n",
    "- **Tipos Comuns**:\n",
    "    1. **L1 Regularization**: Adiciona o valor absoluto dos pesos como termo de penalidade.\n",
    "    2. **L2 Regularization**: Adiciona o quadrado dos pesos como termo de penalidade.\n",
    "- **Hiperparâmetros**: O fator de regularização é um hiperparâmetro a ser ajustado.\n",
    "\n",
    "---\n",
    "\n",
    "## Exemplo: Overfitting em Redes Neurais e Técnicas para Mitigar (8 minutos)\n",
    "\n",
    "- **Dropout**: Técnica de desativar aleatoriamente alguns neurônios durante o treinamento.\n",
    "- **Early Stopping**: Monitorar o desempenho no conjunto de validação e parar o treinamento quando ele começar a degradar.\n",
    "- **Dados Adicionais**: Às vezes, simplesmente adicionando mais dados pode ajudar a mitigar o overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função np.random.rand do NumPy gera números aleatórios uniformemente distribuídos no intervalo [0.0, 1.0]. \n",
    "- Os números são gerados a partir de uma distribuição uniforme sobre este intervalo, o que significa que cada número tem a mesma probabilidade de ser escolhido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "df = pd.read_csv('notebooks.csv')\n",
    "df_ = df.sample(frac=1).reset_index(drop=True)\n",
    "df_ = df_[1000:3000]\n",
    "X = df_.drop(columns='valor').values\n",
    "y = df_[['valor']]\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento (60%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target  = MinMaxScaler()\n",
    "\n",
    "# Normaliza e ajusta o escalonizador com os dados de X de treinamento\n",
    "X_train = scaler_features.fit_transform(X_train)\n",
    "# Normaliza e ajusta o escalonizador com os dados de y de treinamento\n",
    "y_train = scaler_target.fit_transform(y_train)\n",
    "\n",
    "# Ajusta os dados de X_temp\n",
    "X_temp = scaler_features.transform(X_temp)\n",
    "# Ajusta os dados de y_temp\n",
    "y_temp = scaler_target.transform(y_temp)\n",
    "\n",
    "# Separa os dados em X e y de validação e teste\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendendo a Regularização para Combater o Overfitting\n",
    "\n",
    "## O que é Regularização?\n",
    "- **O Que é Regularização?**: Regularização é uma técnica que adiciona um termo de penalidade à função de custo.\n",
    "- **Por que Usar Regularização?**: É útil para evitar que o modelo capture ruído nos dados de treinamento, reduzindo, assim, o overfitting.\n",
    "\n",
    "\n",
    "É como um professor que te pede para explicar o porquê da sua resposta em um teste, desencorajando você de apenas decorar as respostas. No aprendizado de máquina, adicionamos um 'termo de penalidade' para desencorajar o modelo de ajustar demais aos dados de treinamento.\n",
    "\n",
    "## Tipos de Regularização\n",
    "\n",
    "### L1 (Lasso)\n",
    "\n",
    "- **Como Funciona**: Imagine que você tem um time de futebol e alguns jogadores nunca tocam na bola. A L1 remove esses jogadores do time.\n",
    "- **Quando Usar**: Use L1 quando você suspeita que muitos recursos (ou variáveis) não ajudam a prever a resposta.\n",
    "\n",
    "### L2 (Ridge)\n",
    "\n",
    "- **Como Funciona**: Em vez de demitir jogadores, o técnico (L2) diz a todos para jogarem mais devagar (menor peso).\n",
    "- **Quando Usar**: Use quando todos os recursos parecem úteis e você quer que eles contribuam igualmente.\n",
    "\n",
    "### Elastic Net\n",
    "\n",
    "- **Como Funciona**: É como combinar os técnicos de L1 e L2 para gerenciar o time.\n",
    "- **Quando Usar**: Use quando você não tem certeza de qual técnica de regularização escolher.\n",
    "\n",
    "## Onde Aplicar Regularização?\n",
    "\n",
    "- **Camadas Iniciais**: Regularizar as primeiras camadas pode ser útil se você acha que as entradas (recursos) podem conter ruídos ou informações irrelevantes.\n",
    "- **Camadas do Meio**: Podem ser regularizadas para tornar o modelo mais simples e rápido.\n",
    "- **Camadas Finais**: Evite regularizar demais para não perder as características aprendidas.\n",
    "\n",
    "## Como Escolher a Força da Regularização?\n",
    "\n",
    "- Ajuste o 'termo de penalidade'. Se for muito alto, o modelo pode ficar simples demais e perder importantes padrões nos dados (underfitting).\n",
    "- Use técnicas como validação cruzada para encontrar o melhor ajuste.\n",
    "\n",
    "## Resumo\n",
    "\n",
    "- A regularização é uma técnica poderosa para tornar seu modelo mais generalizável e menos propenso a overfitting.\n",
    "- Escolher o tipo e a intensidade da regularização pode depender do seu conhecimento específico do problema e de técnicas de ajuste de hiperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendendo o Dropout para Combater o Overfitting\n",
    "\n",
    "## O que é Dropout?\n",
    "- **O Que é Dropout?**: Dropout é uma técnica de regularização em redes neurais que \"desliga\" aleatoriamente um subconjunto de neurônios durante o treinamento.\n",
    "- **Por que Usar Dropout?**: O Dropout evita que qualquer neurônio se torne excessivamente especializado em memorizar ruídos dos dados de treinamento, o que contribui para combater o overfitting.\n",
    "\n",
    "É como um time de futebol onde alguns jogadores são aleatoriamente mandados para o banco durante o jogo para garantir que a equipe não dependa demais de um único jogador estrela. Isso torna o time como um todo mais robusto.\n",
    "\n",
    "## Como Funciona o Dropout?\n",
    "\n",
    "- **Implementação**: Durante cada iteração de treinamento, alguns neurônios são escolhidos aleatoriamente para serem \"desativados\". Isso significa que esses neurônios não participam do processo de treinamento para essa iteração específica.\n",
    "  \n",
    "- **Taxa de Dropout**: É o percentual de neurônios que você quer desativar em cada iteração. Por exemplo, uma taxa de 0.5 significa que 50% dos neurônios em uma camada são desativados.\n",
    "\n",
    "## Onde Aplicar Dropout?\n",
    "\n",
    "- **Camadas Iniciais**: Aplicar Dropout nas primeiras camadas pode ajudar se você acredita que os neurônios estão desenvolvendo dependências indesejadas nos dados de entrada. \n",
    "\n",
    "- **Camadas Ocultas Densas**: É mais comum aplicar Dropout nas camadas ocultas onde há uma alta densidade de neurônios. Isso aumenta as chances de overfitting, e o Dropout pode ajudar a mitigar isso.\n",
    "\n",
    "- **Camadas Finais**: Cuidado ao aplicar Dropout próximo à camada de saída, especialmente em tarefas que requerem alta precisão. Desativar neurônios aqui pode levar a predições imprecisas.\n",
    "\n",
    "\n",
    "## Quando Usar Dropout?\n",
    "\n",
    "- **Camadas Densas e Complexas**: Dropout é comumente usado em camadas que possuem muitos neurônios, como camadas densas.\n",
    "  \n",
    "- **Problemas com Overfitting**: Quando o modelo está muito bem ajustado aos dados de treinamento e não generaliza bem para dados novos.\n",
    "\n",
    "## Cuidados ao Usar Dropout\n",
    "\n",
    "- **Não use uma taxa muito alta**: Desativar muitos neurônios pode levar a underfitting.\n",
    "  \n",
    "- **Ajuste durante a Validação**: Sempre verifique o desempenho em um conjunto de validação para encontrar a taxa ideal.\n",
    "\n",
    "## Resumo\n",
    "\n",
    "- Dropout é uma técnica eficaz para evitar overfitting em redes neurais.\n",
    "- É como adicionar uma forma de \"incerteza\" ou \"ruído\" durante o treinamento, tornando o modelo mais robusto.\n",
    "- A escolha da taxa de dropout e onde aplicá-la são decisões cruciais que podem requerer experimentação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para criar os modelos\n",
    "# Função para criar o modelo base\n",
    "def create_base_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Função para criar o modelo com L1 e L2 (Elastic Net)\n",
    "def create_l1_l2_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(8, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Função para criar o modelo com Dropout\n",
    "def create_dropout_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Função para criar o modelo com L1, L2 e Dropout\n",
    "def create_l1_l2_dropout_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(8, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia com uma forma de entrada específica\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "# Criar, compilar e treinar os modelos\n",
    "model_base = create_base_model(input_shape)\n",
    "model_l1_l2 = create_l1_l2_model(input_shape)\n",
    "model_dropout = create_dropout_model(input_shape)\n",
    "model_l1_l2_dropout = create_l1_l2_dropout_model(input_shape)\n",
    "\n",
    "# Compilando e treinando os modelos\n",
    "optimizer1 = Adam(learning_rate=0.001)\n",
    "optimizer2 = Adam(learning_rate=0.001)\n",
    "optimizer3 = Adam(learning_rate=0.001)\n",
    "optimizer4 = Adam(learning_rate=0.001)\n",
    "\n",
    "model_base.compile(optimizer=optimizer1, loss='mse')\n",
    "history_base = model_base.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "model_l1_l2.compile(optimizer=optimizer2, loss='mse')\n",
    "history_l1_l2 = model_l1_l2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "model_dropout.compile(optimizer=optimizer3, loss='mse')\n",
    "history_dropout = model_dropout.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "model_l1_l2_dropout.compile(optimizer=optimizer4, loss='mse')\n",
    "history_l1_l2_dropout = model_l1_l2_dropout.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Calculando os MSE para os modelos\n",
    "y_pred_base = model_base.predict(X_test)\n",
    "y_pred_l1_l2 = model_l1_l2.predict(X_test)\n",
    "y_pred_dropout = model_dropout.predict(X_test)\n",
    "y_pred_l1_l2_dropout = model_l1_l2_dropout.predict(X_test)\n",
    "\n",
    "mse_base = mean_squared_error(y_test, y_pred_base)\n",
    "mse_l1_l2 = mean_squared_error(y_test, y_pred_l1_l2)\n",
    "mse_dropout = mean_squared_error(y_test, y_pred_dropout)\n",
    "mse_l1_l2_dropout = mean_squared_error(y_test, y_pred_l1_l2_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotando os resultados\n",
    "labels = ['Base', 'L1_L2', 'Dropout', 'L1_L2_Dropout']\n",
    "mse_values = [mse_base, mse_l1_l2, mse_dropout, mse_l1_l2_dropout]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(labels, mse_values, color='skyblue')\n",
    "plt.xlabel('MSE')\n",
    "plt.ylabel('Model Type')\n",
    "plt.title('Comparação de MSE nos Modelos')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ticklabel_format(style='plain', axis='x')  # Remove notação científica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como Identificar Overfitting com Métricas\n",
    "---\n",
    "\n",
    "## Definindo o Problema\n",
    "\n",
    "- **Pergunta Principal**: Como saber se o modelo está se ajustando demais aos dados de treinamento?\n",
    "- **Consequência**: Se o modelo está com overfitting, ele terá um desempenho ruim em dados não vistos.\n",
    "\n",
    "---\n",
    "\n",
    "## Utilizando Métricas de Desempenho\n",
    "\n",
    "- **Treinamento vs Validação**: É crucial comparar as métricas de desempenho nos conjuntos de treinamento e validação.\n",
    "    1. **Acurácia**\n",
    "    2. **F1-score**\n",
    "    3. **Curva ROC-AUC**\n",
    "    \n",
    "- **Indicadores de Overfitting**:\n",
    "    - Acurácia alta no conjunto de treinamento, mas baixa no conjunto de validação.\n",
    "    - F1-score desproporcionalmente menor no conjunto de validação.\n",
    "    - Curva ROC-AUC demonstrando divergência entre treino e validação.\n",
    "\n",
    "---\n",
    "\n",
    "## Visualizando com Gráficos\n",
    "\n",
    "- **Plot de Métricas**: Gráficos de linha para acompanhar a evolução das métricas ao longo das épocas ou iterações.\n",
    "    - Eixo X: Épocas ou Iterações\n",
    "    - Eixo Y: Valor da Métrica\n",
    "\n",
    "**Nota**: Na próxima seção, vamos olhar para um exemplo prático que inclui esses gráficos.\n",
    "\n",
    "---\n",
    "\n",
    "Pronto para ver isso na prática? Vamos mergulhar no código a seguir!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sm\n",
    "\n",
    "def metricas_regressao(X_test, y_test, scaler_y, model):\n",
    "    \"\"\"\n",
    "    Avalia métricas de regressão para um modelo e conjunto de teste fornecidos.\n",
    "\n",
    "    Parâmetros:\n",
    "    - X_test: características do conjunto de teste.\n",
    "    - y_test: rótulos verdadeiros do conjunto de teste.\n",
    "    - scaler_y: scaler utilizado para normalizar a variável alvo.\n",
    "    - model: modelo treinado para fazer previsões.\n",
    "\n",
    "    Retorna:\n",
    "    Métricas de avaliação de regressão impressas.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Fazer previsões usando o modelo fornecido\n",
    "    predict = model.predict(X_test)\n",
    "    if scaler_y == 0:\n",
    "        real = y_test\n",
    "    else:\n",
    "    # 2. Inverter a transformação para obter os valores originais (não normalizados)\n",
    "        predict = scaler_y.inverse_transform(predict)\n",
    "        real = scaler_y.inverse_transform(y_test)\n",
    "    # 3. Calcular R2 e R2 ajustado\n",
    "    k = X_test.shape[1]  # número de características independentes\n",
    "    n = len(X_test)  # tamanho da amostra\n",
    "    r2 = sm.r2_score(real, predict)\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)  # fórmula para R2 ajustado\n",
    "\n",
    "    # 4. Imprimir métricas\n",
    "    print('Root Mean Square Error:', round(np.sqrt(np.mean(np.array(predict) - np.array(real))**2), 2))\n",
    "    print('Mean Square Error:', round(sm.mean_squared_error(real, predict), 2))\n",
    "    print('Mean Absolut Error:', round(sm.mean_absolute_error(real, predict), 2))\n",
    "    print('Median Absolut Error:', round(sm.median_absolute_error(real, predict), 2))\n",
    "    print('Explain Variance Score:', round(sm.explained_variance_score(real, predict) * 100, 2))\n",
    "    print('R2 score:', round(sm.r2_score(real, predict) * 100, 2))\n",
    "    print('Adjusted R2 =', round(adj_r2, 3) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n",
      "Root Mean Square Error: 788.66\n",
      "Mean Square Error: 9610520.86\n",
      "Mean Absolut Error: 2310.85\n",
      "Median Absolut Error: 1577.27\n",
      "Explain Variance Score: 75.63\n",
      "R2 score: 73.94\n",
      "Adjusted R2 = 73.0\n"
     ]
    }
   ],
   "source": [
    "metricas_regressao(X_test, y_test, scaler_target, model_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step\n",
      "Root Mean Square Error: 773.51\n",
      "Mean Square Error: 5086858.39\n",
      "Mean Absolut Error: 1680.32\n",
      "Median Absolut Error: 1208.81\n",
      "Explain Variance Score: 87.78\n",
      "R2 score: 86.15\n",
      "Adjusted R2 = 86.0\n"
     ]
    }
   ],
   "source": [
    "metricas_regressao(X_train, y_train, scaler_target, model_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Erros do Modelo com 2000 Registros\n",
    "\n",
    "## Métricas de Desempenho\n",
    "\n",
    "- **Root Mean Square Error (RMSE)**\n",
    "    - Teste: 35.15\n",
    "    - Treinamento: 64.24\n",
    "- **Mean Square Error (MSE)**\n",
    "    - Teste: 8084403.99\n",
    "    - Treinamento: 4111220.34\n",
    "- **Mean Absolute Error (MAE)**\n",
    "    - Teste: 2155.01\n",
    "    - Treinamento: 1572.19\n",
    "- **Median Absolute Error**\n",
    "    - Teste: 1608.74\n",
    "    - Treinamento: 1237.49\n",
    "- **Explained Variance Score**\n",
    "    - Teste: 79.15%\n",
    "    - Treinamento: 88.91%\n",
    "- **R2 Score**\n",
    "    - Teste: 79.15%\n",
    "    - Treinamento: 88.9%\n",
    "- **Adjusted R2**\n",
    "    - Teste: 78.4%\n",
    "    - Treinamento: 88.8%\n",
    "\n",
    "## Interpretação das Métricas\n",
    "\n",
    "- **Root Mean Square Error (RMSE)**\n",
    "    - Representa a raiz quadrada da média dos erros quadráticos. Valores menores indicam melhor ajuste do modelo. \n",
    "- **Mean Square Error (MSE)**\n",
    "    - É a média dos erros quadráticos. Valores mais baixos são melhores, mas é mais sensível a outliers.\n",
    "- **Mean Absolute Error (MAE)**\n",
    "    - É a média dos erros absolutos. Fornece uma ideia de quão erradas são as previsões. \n",
    "- **Median Absolute Error**\n",
    "    - É a mediana dos erros absolutos. Menos sensível a outliers que o MAE.\n",
    "- **Explained Variance Score**\n",
    "    - Mede a proporção da variância do target que é explicada pelo modelo. Valores mais próximos de 100% são ideais.\n",
    "- **R2 Score**\n",
    "    - Mede o quanto do target é explicado pelas features. Quanto mais próximo de 100%, melhor.\n",
    "- **Adjusted R2**\n",
    "    - Semelhante ao R2, mas ajustado pelo número de preditores no modelo. É mais útil quando comparando modelos com diferentes números de preditores.\n",
    "\n",
    "## Análise de Overfitting\n",
    "\n",
    "- O modelo tem um desempenho significativamente melhor nos dados de treinamento em comparação com os dados de teste em quase todas as métricas.\n",
    "- A diferença entre o R2 Score de treinamento e teste é aproximadamente 9.75%, o que pode ser um indicador de que o modelo está sofrendo de algum grau de overfitting.\n",
    "- O RMSE para os dados de treinamento é aproximadamente 64, enquanto para os dados de teste é 35. A diferença notável também aponta para o overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados\n",
    "X = df.drop(columns='valor').values\n",
    "y = df[['valor']]\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento (60%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target  = MinMaxScaler()\n",
    "\n",
    "# Normaliza e ajusta o escalonizador com os dados de X de treinamento\n",
    "X_train = scaler_features.fit_transform(X_train)\n",
    "# Normaliza e ajusta o escalonizador com os dados de y de treinamento\n",
    "y_train = scaler_target.fit_transform(y_train)\n",
    "\n",
    "# Ajusta os dados de X_temp\n",
    "X_temp = scaler_features.transform(X_temp)\n",
    "# Ajusta os dados de y_temp\n",
    "y_temp = scaler_target.transform(y_temp)\n",
    "\n",
    "# Separa os dados em X e y de validação e teste\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia com uma forma de entrada específica\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "# Criar, compilar e treinar o melhor modelo\n",
    "model_dropout = create_dropout_model(input_shape)\n",
    "\n",
    "# Compilando e treinando os modelos\n",
    "optimizer3 = Adam(learning_rate=0.001)\n",
    "model_dropout.compile(optimizer=optimizer3, loss='mse')\n",
    "history_dropout = model_dropout.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "Root Mean Square Error: 18.58\n",
      "Mean Square Error: 7201270.62\n",
      "Mean Absolut Error: 2120.07\n",
      "Median Absolut Error: 1716.75\n",
      "Explain Variance Score: 80.7\n",
      "R2 score: 80.7\n",
      "Adjusted R2 = 80.60000000000001\n"
     ]
    }
   ],
   "source": [
    "metricas_regressao(X_test, y_test, scaler_target, model_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30/188 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 1ms/step\n",
      "Root Mean Square Error: 90.14\n",
      "Mean Square Error: 5462724.87\n",
      "Mean Absolut Error: 1851.78\n",
      "Median Absolut Error: 1500.68\n",
      "Explain Variance Score: 85.25\n",
      "R2 score: 85.23\n",
      "Adjusted R2 = 85.2\n"
     ]
    }
   ],
   "source": [
    "metricas_regressao(X_train, y_train, scaler_target, model_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Erros do Modelo com Acréscimo de Dados\n",
    "\n",
    "## Contexto\n",
    "\n",
    "- Este modelo foi treinado com um conjunto de 10,000 registros, um aumento significativo em relação aos experimentos anteriores que tinham menos registros.\n",
    "\n",
    "## Métricas de Desempenho e Análise\n",
    "\n",
    "### Root Mean Square Error (RMSE)\n",
    "- **Teste**: 127.68\n",
    "- **Treinamento**: 157.96\n",
    "  - Representa o desvio padrão dos erros do modelo. Valores menores indicam um melhor desempenho.\n",
    "\n",
    "### Mean Square Error (MSE)\n",
    "- **Teste**: 6769172.38\n",
    "- **Treinamento**: 5058889.6\n",
    "  - É a média dos erros ao quadrado, sendo sensível a outliers. Valores menores são melhores.\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "- **Teste**: 2017.72\n",
    "- **Treinamento**: 1749.72\n",
    "  - É a média dos erros absolutos, dando uma ideia da magnitude dos erros.\n",
    "\n",
    "### Median Absolute Error\n",
    "- **Teste**: 1544.37\n",
    "- **Treinamento**: 1353.14\n",
    "  - A mediana dos erros absolutos e é menos sensível a outliers.\n",
    "\n",
    "### Explained Variance Score\n",
    "- **Teste**: 81.9%\n",
    "- **Treinamento**: 86.39%\n",
    "  - Representa quanto da variância total é explicada pelo modelo.\n",
    "\n",
    "### R2 Score\n",
    "- **Teste**: 81.86%\n",
    "- **Treinamento**: 86.32%\n",
    "  - Indica o ajuste do modelo aos dados observados.\n",
    "\n",
    "### Adjusted R2\n",
    "- **Teste**: 81.7%\n",
    "- **Treinamento**: 86.3%\n",
    "  - É o R2 ajustado pelo número de preditores no modelo.\n",
    "\n",
    "## Efeito do Acréscimo de Dados\n",
    "\n",
    "- O acréscimo de mais dados no treinamento parece ter ajudado o modelo a generalizar melhor, como evidenciado pelas métricas de teste e treinamento mais próximas.\n",
    "- A diferença no R2 Score entre treinamento e teste diminuiu, sugerindo que o modelo está menos propenso a overfitting.\n",
    "- A inclusão de mais dados pode ter contribuído para uma representação mais abrangente do espaço de características, tornando o modelo mais robusto a variações nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teorema No Free Lunch\n",
    "---\n",
    "\n",
    "## Introdução\n",
    "\n",
    "- **Definição**: O Teorema No Free Lunch (NFL) afirma que não existe um único algoritmo de aprendizado de máquina que funcione melhor para todos os tipos de problemas.\n",
    "- **Importância**: Esse teorema nos ajuda a entender por que a busca pelo \"algoritmo perfeito\" é fútil.\n",
    "\n",
    "---\n",
    "\n",
    "## O Que o Teorema Realmente Significa?\n",
    "\n",
    "1. **Não Existe Algoritmo Universalmente Superior**: Cada algoritmo tem seus próprios pontos fortes e fracos, e o que funciona bem para um problema pode não ser adequado para outro.\n",
    "2. **Dependência do Problema**: O sucesso de um algoritmo é fortemente dependente do tipo de problema que você está tentando resolver.\n",
    "3. **A Importância da Experimentação**: Este teorema reforça a necessidade de experimentar com vários algoritmos e técnicas para encontrar a melhor abordagem para um determinado problema.\n",
    "\n",
    "---\n",
    "\n",
    "## Implicações Práticas\n",
    "\n",
    "- **Seleção de Modelos**: Dada a impossibilidade de um único melhor algoritmo, a seleção de modelos torna-se crucial.\n",
    "- **Otimização de Hiperparâmetros**: O ajuste de hiperparâmetros é mais relevante do que nunca, já que o \"melhor\" algoritmo é problema-específico.\n",
    "\n",
    "---\n",
    "\n",
    "**Exemplos práticos que ilustram o Teorema No Free Lunch em ação.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Gerando um conjunto de dados de exemplo para regressão\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento, validação e teste\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Criando e treinando os modelos de RandomForest e SVM para regressão\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "svm = SVR()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Função para criar o modelo de rede neural com L1 e L2\n",
    "def create_l1_l2_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(8, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Função para criar o modelo de rede neural com Dropout\n",
    "def create_dropout_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Criando e treinando as redes neurais\n",
    "l1_l2_model = create_l1_l2_model(X_train.shape[1])\n",
    "dropout_model = create_dropout_model(X_train.shape[1])\n",
    "\n",
    "l1_l2_model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), verbose=0)\n",
    "dropout_model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "# Avaliando os modelos\n",
    "rf_mse = mean_squared_error(y_test, rf.predict(X_test))\n",
    "svm_mse = mean_squared_error(y_test, svm.predict(X_test))\n",
    "l1_l2_mse = mean_squared_error(y_test, l1_l2_model.predict(X_test).reshape(-1))\n",
    "dropout_mse = mean_squared_error(y_test, dropout_model.predict(X_test).reshape(-1))\n",
    "\n",
    "# Gráfico para comparar as métricas\n",
    "labels = ['Random Forest', 'SVM', 'L1_L2', 'Dropout']\n",
    "values = [rf_mse, svm_mse, l1_l2_mse, dropout_mse]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, values, color=['blue', 'green', 'red', 'purple'])\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Erro Quadrático Médio (MSE)')\n",
    "plt.title('Comparação de MSE entre Modelos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significado e Importância\n",
    "---\n",
    "\n",
    "## O Que o Teorema No Free Lunch Realmente Significa? \n",
    "\n",
    "- **Sem Almoço Grátis**: O nome sugere que não existe uma \"refeição gratuita\" em termos de eficácia algorítmica; tudo tem um custo.\n",
    "- **Universalidade**: Não existe um único algoritmo que seja superior em todos os cenários e tipos de dados.\n",
    "  \n",
    "---\n",
    "\n",
    "## Por Que Isso é Importante? \n",
    "\n",
    "### Fim da Busca pelo \"Algoritmo de Aprendizado Perfeito\"\n",
    "\n",
    "- Elimina a noção de que poderia existir um \"Santo Graal\" dos algoritmos de aprendizado de máquina.\n",
    "  \n",
    "### Acentua a Necessidade de Personalização\n",
    "\n",
    "- Destaca que a escolha do algoritmo deve ser adaptada ao problema específico em mãos.\n",
    "\n",
    "---\n",
    "\n",
    "**Para resumir, o Teorema No Free Lunch nos ensina a ser mais críticos e adaptáveis como cientistas de dados.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como o Teorema No Free Lunch se Relaciona com Overfitting\n",
    "---\n",
    "\n",
    "## Introdução\n",
    "\n",
    "- **Ponto em Comum**: Tanto o Teorema No Free Lunch quanto o conceito de overfitting nos dizem que não há soluções universais no campo do aprendizado de máquina.\n",
    "\n",
    "---\n",
    "\n",
    "## Relação entre NFL e Overfitting\n",
    "\n",
    "1. **Escolha de Algoritmos**: O Teorema No Free Lunch sugere que devemos escolher algoritmos com base no problema específico, algo que também é crucial para evitar o overfitting.\n",
    "\n",
    "2. **Complexidade do Modelo**: \n",
    "    - NFL nos adverte contra a busca por um \"algoritmo perfeito\".\n",
    "    - Overfitting nos adverte contra a busca por um \"modelo perfeitamente ajustado\".\n",
    "    - Ambos são contra a ideia de \"um tamanho serve para todos\".\n",
    "\n",
    "3. **Personalização e Ajuste**:\n",
    "    - NFL destaca a necessidade de ajuste e personalização nos algoritmos.\n",
    "    - Overfitting nos mostra que esse ajuste precisa ser feito com cuidado para evitar memorização em vez de generalização.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "- A consciência do Teorema No Free Lunch pode nos ajudar a ser mais criteriosos na prevenção de overfitting, escolhendo e ajustando algoritmos de forma mais eficaz.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicações Práticas para a Seleção de Modelos\n",
    "---\n",
    "\n",
    "## Introdução\n",
    "\n",
    "- **Contexto**: Agora que entendemos os conceitos de overfitting e o Teorema No Free Lunch, como aplicamos esse conhecimento na prática?\n",
    "\n",
    "---\n",
    "\n",
    "## Passos na Seleção de Modelos\n",
    "\n",
    "1. **Análise do Problema**:\n",
    "    - Entender o tipo de problema (Classificação, Regressão, Agrupamento, etc.) é o primeiro passo na seleção do modelo.\n",
    "\n",
    "2. **Teste de Vários Modelos**:\n",
    "    - Devido ao Teorema No Free Lunch, é recomendável testar diversos algoritmos para encontrar o que se adequa melhor ao problema específico.\n",
    "\n",
    "3. **Validação Cruzada**:\n",
    "    - Usar técnicas como K-Fold para estimar o desempenho do modelo em dados não vistos e ajudar a evitar overfitting.\n",
    "\n",
    "4. **Ajuste de Hiperparâmetros**:\n",
    "    - Com o modelo escolhido, o ajuste de hiperparâmetros torna-se crucial tanto para o desempenho quanto para evitar o overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## Métricas e Diagnósticos\n",
    "\n",
    "- **Selecionar Métricas Relevantes**: Acurácia, Precisão, Recall, F1-Score, entre outros, dependendo do problema.\n",
    "- **Curvas ROC e AUC**: Ferramentas úteis para avaliar a qualidade do modelo em problemas de classificação.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "- A integração desses conceitos (NFL e overfitting) nos dá uma abordagem mais robusta e informada para a seleção e otimização de modelos em aprendizado de máquina.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios\n",
    "\n",
    "Exemplos de aplicação de l1, l2 e l1 e l2 juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importando as bibliotecas necessárias para o modelo de rede neural\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# Função para criar o modelo com regularização L1\n",
    "def create_l1_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l1(0.01)),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Função para criar o modelo com regularização L2\n",
    "def create_l2_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Função para criar o modelo com regularização L1 e L2\n",
    "def create_l1_l2_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(8, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura modelo base 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Função para criar um modelo com 7 camadas ocultas\n",
    "def create_7_layer_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(input_shape,)), # Camada de entrada\n",
    "        Dense(256, activation='relu'),  # Primeira camada oculta\n",
    "        Dense(128, activation='relu'),  # Segunda camada oculta\n",
    "        Dense(64, activation='relu'),   # Terceira camada oculta\n",
    "        Dense(32, activation='relu'),   # Quarta camada oculta\n",
    "        Dense(16, activation='relu'),   # Quinta camada oculta\n",
    "        Dense(8, activation='relu'),    # Sexta camada oculta\n",
    "        Dense(4, activation='relu'),    # Sétima camada oculta\n",
    "        Dense(1, activation='linear')   # Camada de saída\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Função para criar um modelo com 3 camadas ocultas\n",
    "def create_3_layer_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_shape,)),  # Camada de entrada\n",
    "        Dense(32, activation='relu'),  # Primeira camada oculta\n",
    "        Dense(16, activation='relu'),  # Segunda camada oculta\n",
    "        Dense(8, activation='relu'),   # Terceira camada oculta\n",
    "        Dense(1, activation='linear')  # Camada de saída\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura modelo base 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_shape,)),  # Camada de entrada\n",
    "        Dense(32, activation='relu'),  # Primeira camada oculta\n",
    "        Dense(16, activation='relu'),  # Segunda camada oculta\n",
    "        Dense(8, activation='relu'),   # Terceira camada oculta\n",
    "        Dense(1, activation='linear')  # Camada de saída\n",
    "    ])\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilize a base de dados notebooks_ruidosos.csv que contém 3 colunas com valores aleatórios que devem atrapalhar o aprendizado do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1 - Separe os dados em X_train, X_temp, y_train, y_temp, com 50% para o treinamento normalize com fit transform os dados de treinamento (um normalizador para X e outro para y), normalize os dados temporários com o transform e em seguida separe X e y temp em X e y de validação e teste, 50% para cada um. (a coluna valor será o y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('notebooks.csv')\n",
    "X = df_.drop(columns='valor').values\n",
    "y = df_[['valor']]\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento (50%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target  = MinMaxScaler()\n",
    "\n",
    "# Normaliza e ajusta o escalonizador com os dados de X de treinamento\n",
    "X_train = scaler_features.fit_transform(X_train)\n",
    "# Normaliza e ajusta o escalonizador com os dados de y de treinamento\n",
    "y_train = scaler_target.fit_transform(y_train)\n",
    "\n",
    "# Ajusta os dados de X_temp\n",
    "X_temp = scaler_features.transform(X_temp)\n",
    "# Ajusta os dados de y_temp\n",
    "y_temp = scaler_target.transform(y_temp)\n",
    "\n",
    "# Separa os dados em X e y de validação e teste\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2 - De acordo com as peculiaridades de aplicação da regularização de kernel L1, L2 e Elastic Net (L1 e L2 Juntos), em seguida crie uma função que gere um modelo baseado na estrutura do modelo de 7 camadas ocultas que melhor se adeque para a base de dados (de acordo com a teoria), crie e treine por 50 épocas um modelo gerado com esta função;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 2s 17ms/step - loss: 134.6009 - accuracy: 0.0010 - val_loss: 86.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 56.0933 - accuracy: 0.0010 - val_loss: 29.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 16.6829 - accuracy: 0.0010 - val_loss: 8.2915 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.9449 - accuracy: 0.0010 - val_loss: 2.6145 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7966 - accuracy: 0.0010 - val_loss: 1.1195 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8515 - accuracy: 0.0010 - val_loss: 0.6920 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6334 - accuracy: 0.0000e+00 - val_loss: 0.5823 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5564 - accuracy: 0.0010 - val_loss: 0.5320 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5189 - accuracy: 0.0010 - val_loss: 0.5088 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.0010 - val_loss: 0.5004 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.0010 - val_loss: 0.5032 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.0010 - val_loss: 0.5007 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.0010 - val_loss: 0.4966 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.0010 - val_loss: 0.4980 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5002 - accuracy: 0.0020 - val_loss: 0.4972 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.0010 - val_loss: 0.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.0020 - val_loss: 0.4956 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4968 - accuracy: 0.0010 - val_loss: 0.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.0010 - val_loss: 0.4936 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.0010 - val_loss: 0.4941 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.0010 - val_loss: 0.4956 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.0010 - val_loss: 0.4910 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4941 - accuracy: 0.0010 - val_loss: 0.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4937 - accuracy: 0.0010 - val_loss: 0.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.0010 - val_loss: 0.4897 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.0010 - val_loss: 0.4899 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.0010 - val_loss: 0.4895 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.0020 - val_loss: 0.4865 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.0010 - val_loss: 0.4897 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.0010 - val_loss: 0.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.0010 - val_loss: 0.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.0010 - val_loss: 0.4879 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.0010 - val_loss: 0.4874 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.0010 - val_loss: 0.4876 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.0010 - val_loss: 0.4868 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4904 - accuracy: 0.0010 - val_loss: 0.4897 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4908 - accuracy: 0.0010 - val_loss: 0.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.0010 - val_loss: 0.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.0010 - val_loss: 0.4917 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4928 - accuracy: 0.0010 - val_loss: 0.4881 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4929 - accuracy: 0.0010 - val_loss: 0.4932 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4927 - accuracy: 0.0010 - val_loss: 0.4918 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.0010 - val_loss: 0.4898 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4933 - accuracy: 0.0010 - val_loss: 0.4923 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4930 - accuracy: 0.0010 - val_loss: 0.4917 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4929 - accuracy: 0.0010 - val_loss: 0.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.0010 - val_loss: 0.4907 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4923 - accuracy: 0.0010 - val_loss: 0.4903 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4921 - accuracy: 0.0010 - val_loss: 0.4893 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.0010 - val_loss: 0.4908 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_l1_l2():\n",
    "    modelo = keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),  # Substitua input_shape pelo formato dos seus dados de entrada\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        layers.Dense(1, activation='linear') \n",
    "    ])\n",
    "    \n",
    "    modelo.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return modelo\n",
    "\n",
    "# Supondo que você tenha um conjunto de dados de treinamento e um conjunto de dados de validação\n",
    "# X_train e y_train são seus dados de treinamento e rótulos\n",
    "# X_val e y_val são seus dados de validação e rótulos\n",
    "\n",
    "modelo = create_l1_l2()\n",
    "\n",
    "# Treine o modelo por 50 épocas\n",
    "historico_treinamento = modelo.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "\n",
    "# Agora, seu modelo está treinado por 50 épocas e o histórico de treinamento foi registrado em 'historico_treinamento'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3 - De acordo com as peculiaridades de aplicação da aplicação do dropout, crie uma função que gere um modelo baseado na estrutura do modelo de 7 camadas ocultas que melhor se adeque para a base de dados (de acordo com a teoria), em seguida crie e treine por 50 épocas um modelo gerado com esta função;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dropout_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4 - De acordo com as peculiaridades de aplicação da regularização de kernel L1, L2 e Elastic Net (L1 e L2 Juntos) e da aplicação do dropout, crie uma função que gere um modelo  baseado na estrutura do modelo de 7 camadas ocultas que melhor se adeque para a base de dados (basicamente mesclar os dois modelos anteriores), em seguida crie e treine por 50 épocas um modelo gerado com esta função;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5 - De acordo com as peculiaridades de aplicação da regularização de kernel L1, L2 e Elastic Net (L1 e L2 Juntos), em seguida crie uma função que gere um modelo baseado na estrutura do modelo de 3 camadas ocultas que melhor se adeque para a base de dados (de acordo com a teoria), crie e treine por 50 épocas um modelo gerado com esta função;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5 - De acordo com as peculiaridades de aplicação da aplicação do dropout, crie uma função que gere um modelo baseado na estrutura do modelo de 3 camadas ocultas que melhor se adeque para a base de dados (de acordo com a teoria), em seguida crie e treine por 50 épocas um modelo gerado com esta função;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7 - De acordo com as peculiaridades de aplicação da regularização de kernel L1, L2 e Elastic Net (L1 e L2 Juntos) e da aplicação do dropout, crie uma função que gere um modelo  baseado na estrutura do modelo de 3 camadas ocultas que melhor se adeque para a base de dados (basicamente mesclar os dois modelos anteriores), em seguida crie e treine por 50 épocas um modelo gerado com esta função;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 8 - Crie e treine por 50 épocas um modelo gerado com a função create_7_layer_model e outro com a função create_3_layer_model;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 9 - Faça previsão com os 8 modelos nos dados de teste exibindo um gráfico com o MSE de cada um deles;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 10 - Selecione o melhor modelo e exiba as métricas (da função metricas_regressao) com os valores de teste e os valores de treinamento. Comparando as métricas, o modelo apresenta características de overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
