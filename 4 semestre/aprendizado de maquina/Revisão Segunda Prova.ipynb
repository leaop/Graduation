{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risco em Aprendizado de Máquina\n",
    "\n",
    "A aprendizagem de máquina é um campo que busca construir modelos eficientes a partir de dados. A eficácia de um modelo é essencial para garantir previsões precisas e confiáveis. Mas como podemos determinar se um modelo é 'bom'? O que exatamente significa um modelo 'bom'?\n",
    "\n",
    "Essas perguntas nos levam aos conceitos de **risco empírico** e **risco estrutural**, que são fundamentais para avaliar o desempenho dos modelos de aprendizado de máquina.\n",
    "\n",
    "## Risco Empírico vs. Risco Estrutural\n",
    "\n",
    "- **Risco Empírico:** \n",
    "  Este é o erro observado nos dados de treinamento. Ele indica quão bem o modelo está se ajustando aos dados com os quais foi treinado, sendo uma medida do erro de treinamento. Por exemplo, se tivermos um modelo de regressão que apresenta um risco empírico alto, isso significa que ele não está se ajustando bem aos dados de treinamento (Underfitting), podendo ser necessário revisar suas características ou parâmetros.\n",
    "\n",
    "\n",
    "- **Risco Estrutural:** \n",
    "  Este conceito é mais abstrato. Refere-se ao erro que esperamos ver em novos dados, ou seja, o erro em um conjunto de dados que o modelo nunca viu antes. Ele nos dá uma ideia da capacidade de generalização do modelo, sendo uma medida do erro de teste ou validação. Um modelo com baixo risco estrutural é capaz de fazer previsões precisas em dados não vistos anteriormente.\n",
    "\n",
    "## A Importância do Equilíbrio\n",
    "\n",
    "É crucial encontrar um equilíbrio entre o risco empírico e o risco estrutural. Se um modelo se ajusta perfeitamente aos dados de treinamento (risco empírico baixo), mas não generaliza bem para novos dados (risco estrutural alto), ele é considerado sobreajustado (overfitting). Por outro lado, um modelo que não se ajusta bem nem aos dados de treinamento pode estar subajustado (underfitting), indicando que pode ser muito simples para capturar a complexidade dos dados.\n",
    "\n",
    "## Exemplo Prático\n",
    "\n",
    "Imagine um modelo de classificação de e-mails em 'spam' ou 'não spam'. Se o modelo tem um risco empírico baixo, ele classifica corretamente a maioria dos e-mails no conjunto de treinamento. No entanto, se ele tem um risco estrutural alto, pode falhar ao classificar e-mails novos, marcando e-mails legítimos como spam ou permitindo que spam passe como e-mail legítimo.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "Entender o risco empírico e o risco estrutural é essencial para construir e avaliar modelos de aprendizado de máquina eficazes. Eles nos ajudam a entender os limites do que nossos modelos podem aprender e a encontrar um equilíbrio entre o ajuste aos dados de treinamento e a capacidade de generalização para novos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link com o datalhamento do dataset: https://www.kaggle.com/datasets/uciml/electric-power-consumption-data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('consumo_de_energia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separa os dados em X e y\n",
    "scaler_X = MinMaxScaler()\n",
    "X = df.drop('Global_active_power', axis = 1)\n",
    "\n",
    "scaler_y  = MinMaxScaler()\n",
    "y = df[['Global_active_power']]\n",
    "\n",
    "# Separa os dados em X e y de treinamento e temporários\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normaliza e ajusta o escalonizador com os dados de X de treinamento\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "# Normaliza e ajusta o escalonizador com os dados de y de treinamento\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "\n",
    "# Ajusta os dados de X_temp\n",
    "X_temp = scaler_X.transform(X_temp)\n",
    "# Ajusta os dados de y_temp\n",
    "y_temp = scaler_y.transform(y_temp)\n",
    "\n",
    "# Separa os dados em X e y de validação e teste (70% para teste - 70% de 50% = 35% do total)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risco Empírico\n",
    "\n",
    "Quando falamos sobre treinar modelos de aprendizado de máquina, muitas vezes estamos tentando minimizar algum tipo de erro. No contexto de regressão, por exemplo, queremos minimizar a diferença entre as previsões do nosso modelo e os valores reais. Esta diferença é muitas vezes referida como \"erro\". e na maioria dos casos é utilizado o MSE dos dados de treinamento para calcular este erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Função para criar o modelo com L1 e L2 (Elastic Net)\n",
    "def create_l1_l2_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, obtemos a dimensão dos dados de entrada. \n",
    "# 'X.shape[1]' retorna o número de características no conjunto de dados X.\n",
    "input_shape = X.shape[1]\n",
    "\n",
    "# Aqui, chamamos a função 'create_l1_l2_model' para criar o modelo.\n",
    "# Passamos 'input_shape' como argumento para garantir que o modelo saiba quantos neurônios de entrada deve ter.\n",
    "model = create_l1_l2_model(input_shape)\n",
    "\n",
    "# Definimos o Early Stopping para o treinamento do modelo.\n",
    "# 'monitor' é definido como 'val_loss', o que significa que o Early Stopping observará a perda no conjunto de validação.\n",
    "# 'patience' é definido como 10, o que significa que o treinamento será interrompido se não houver melhoria na perda de validação por 10 épocas consecutivas.\n",
    "# 'verbose' é definido como 1, o que significa que mensagens de log serão impressas durante o treinamento.\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Métrica a ser monitorada\n",
    "    patience=3,  # Número de épocas sem melhoria após o qual o treinamento será interrompido\n",
    "    verbose=1,  # Para exibir logs\n",
    "    mode='min'  # O treinamento será interrompido quando 'val_loss' parar de diminuir\n",
    ")\n",
    "\n",
    "# Aqui, iniciamos o treinamento do modelo com o método 'fit'.\n",
    "# 'X_train' e 'y_train' são os dados de treinamento e os rótulos correspondentes.\n",
    "# 'epochs' é definido como 20, o que significa que o modelo passará pelos dados de treinamento 20 vezes no máximo.\n",
    "# 'validation_data' é definido como '(X_val, y_val)', o que significa que o modelo será validado nesse conjunto de dados após cada época.\n",
    "# 'callbacks' é definido como uma lista contendo 'early_stopping', o que significa que o Early Stopping será usado durante o treinamento.\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Usando o modelo para fazer previsões no conjunto de treinamento\n",
    "predict = model.predict(X_train)\n",
    "\n",
    "# Invertendo a normalização das previsões para obter os valores reais\n",
    "predict = scaler_y.inverse_transform(predict)\n",
    "\n",
    "# Invertendo a normalização dos valores reais de treinamento\n",
    "real = scaler_y.inverse_transform(y_train)\n",
    "\n",
    "# Calculando o Erro Quadrático Médio (MSE) entre os valores reais e as previsões\n",
    "mse = mean_squared_error(real, predict)\n",
    "\n",
    "# Imprimindo o MSE\n",
    "print(f\"Risco Empírico (MSE): {mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Importando seaborn para melhorar a estética dos gráficos\n",
    "\n",
    "# Configurando o estilo do gráfico para um estilo mais bonito\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Criando um gráfico de linha para os dados reais\n",
    "# Exibindo apenas os 60 primeiros valores\n",
    "plt.plot(real[:60], 'o', color=\"darkorange\", label=\"Dados Reais\")\n",
    "\n",
    "# Criando um gráfico de linha para as previsões\n",
    "# Exibindo apenas os 60 primeiros valores\n",
    "plt.plot(predict[:60], 'o', color=\"blue\", label=\"Previsão\")\n",
    "\n",
    "# Definindo o rótulo do eixo X como 'Índice'\n",
    "plt.xlabel(\"Índice\")\n",
    "\n",
    "# Definindo o rótulo do eixo Y como 'Valores'\n",
    "plt.ylabel(\"Valores\")\n",
    "\n",
    "# Definindo o título do gráfico\n",
    "plt.title(\"Comparação entre Dados Reais e Previsões com Normalização\")\n",
    "\n",
    "# Adicionando a legenda ao gráfico\n",
    "plt.legend()\n",
    "\n",
    "# Exibindo o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesmo exemplo mas sem normalizar os dados\n",
    "X = df.drop('Global_active_power', axis = 1)\n",
    "y = df[['Global_active_power']]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.7, random_state=42)\n",
    "\n",
    "input_shape = X.shape[1]\n",
    "\n",
    "model = create_l1_l2_model(input_shape)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "predict = model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, predict)\n",
    "print(f\"Risco Empírico (MSE): {mse:.3f}\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(y_train[:60].values, 'o', color=\"darkorange\", label=\"Dados Reais\")\n",
    "plt.plot(predict[:60], 'o', color=\"blue\", label=\"Previsão\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Valores\")\n",
    "plt.title(\"Comparação entre Dados Reais e Previsões sem Normalização\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting e Underfitting: Entendendo os Conceitos e a Relação com Risco Empírico\n",
    "\n",
    "## Overfitting e Underfitting: Uma Visão Geral\n",
    "\n",
    "- **Overfitting (Sobreajuste)**: \n",
    "  - **O que é?** Ocorre quando um modelo aprende demais dos dados de treinamento, capturando ruído como se fosse um padrão.\n",
    "  - **Problemas**: Bom desempenho nos dados de treinamento, mas desempenho ruim em dados novos ou não vistos.\n",
    "  - **Exemplo**: Imagine um estudante que memoriza as questões da prova em vez de entender os conceitos. Ele pode se sair bem em uma prova semelhante, mas falhará em questões que exigem compreensão real.\n",
    "\n",
    "- **Underfitting (Subajuste)**:\n",
    "  - **O que é?** Acontece quando um modelo é muito simples, falhando em capturar padrões nos dados.\n",
    "  - **Problemas**: Desempenho ruim tanto nos dados de treinamento quanto nos dados novos.\n",
    "  - **Exemplo**: Pense em um estudante que estuda muito pouco e, portanto, não tem conhecimento suficiente para passar na prova.\n",
    "\n",
    "### Soluções:\n",
    "\n",
    "- Para **overfitting**, podemos simplificar o modelo, usar técnicas de regularização ou obter mais dados de treinamento.\n",
    "- Para **underfitting**, podemos tornar o modelo mais complexo ou adicionar mais características relevantes aos dados de entrada.\n",
    "\n",
    "## Relação com Risco Empírico\n",
    "\n",
    "- **Risco Empírico e Overfitting**:\n",
    "  - **Cenário**: Baixo risco empírico, mas alto erro em dados de validação/teste.\n",
    "  - **Interpretação**: O modelo está memorizando os dados de treinamento, não generalizando bem para dados novos.\n",
    "  \n",
    "- **Risco Empírico e Underfitting**:\n",
    "  - **Cenário**: Alto risco empírico e alto erro em dados de validação/teste.\n",
    "  - **Interpretação**: O modelo não está aprendendo adequadamente, falhando em capturar padrões essenciais.\n",
    "\n",
    "## Como Encontrar o Equilíbrio?\n",
    "\n",
    "- **Validação Cruzada**: Use a validação cruzada para avaliar o desempenho do modelo em diferentes subconjuntos de dados de treinamento.\n",
    "- **Regularização**: Aplique técnicas de regularização para penalizar modelos complexos.\n",
    "- **Ajuste de Hiperparâmetros**: Experimente diferentes hiperparâmetros para encontrar a melhor combinação que evite overfitting e underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendendo a Regularização para Combater o Overfitting\n",
    "\n",
    "## Introdução à Regularização\n",
    "\n",
    "A **Regularização** é uma técnica fundamental no aprendizado de máquina para prevenir o overfitting, garantindo que o modelo generalize bem para dados não vistos. É semelhante a um professor que pede para explicar o raciocínio por trás de uma resposta, evitando a mera memorização.\n",
    "\n",
    "## Por Que a Regularização é Necessária?\n",
    "\n",
    "- **Prevenção de Overfitting**: Evita que o modelo memorize o ruído dos dados de treinamento.\n",
    "- **Melhoria da Generalização**: Ajuda o modelo a performar bem em dados não vistos.\n",
    "- **Redução da Complexidade do Modelo**: Penaliza pesos grandes, levando a modelos mais simples.\n",
    "\n",
    "## Explorando os Tipos de Regularização\n",
    "\n",
    "### 1. **L1 (Lasso)**\n",
    "\n",
    "- **Funcionamento**: Elimina pesos de características irrelevantes, efetivamente selecionando características.\n",
    "- **Aplicação Prática**: Útil quando há suspeita de muitas características irrelevantes.\n",
    "\n",
    "### 2. **L2 (Ridge)**\n",
    "\n",
    "- **Funcionamento**: Penaliza pesos grandes, mas não os elimina completamente.\n",
    "- **Aplicação Prática**: Útil quando todas as características são relevantes.\n",
    "\n",
    "### 3. **Elastic Net**\n",
    "\n",
    "- **Funcionamento**: Combina L1 e L2, proporcionando um equilíbrio entre a seleção de características e a penalização de pesos grandes.\n",
    "- **Aplicação Prática**: Útil quando há incerteza sobre a relevância das características.\n",
    "\n",
    "## Aplicando Regularização nas Camadas da Rede Neural\n",
    "\n",
    "- **Camadas Iniciais**: Útil para filtrar ruídos nas entradas.\n",
    "- **Camadas Intermediárias**: Ajuda a simplificar a arquitetura da rede.\n",
    "- **Camadas Finais**: Aplicação cautelosa para evitar a perda de informações cruciais.\n",
    "\n",
    "## Ajustando a Força da Regularização\n",
    "\n",
    "- **Ajuste Fino**: Use validação cruzada para encontrar o termo de penalidade ideal.\n",
    "- **Evite Underfitting**: Cuidado para não aplicar penalidade excessiva, levando a um modelo muito simples.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "Compreender e aplicar adequadamente a regularização é crucial para construir modelos robustos e generalizáveis, evitando o overfitting e garantindo um bom desempenho em dados não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compreendendo o Dropout para Mitigar o Overfitting\n",
    "\n",
    "## Introdução ao Dropout\n",
    "\n",
    "O **Dropout** é uma técnica de regularização para redes neurais que ajuda a prevenir o overfitting, desativando aleatoriamente um conjunto de neurônios durante o treinamento. Imagine um time de futebol onde alguns jogadores são aleatoriamente substituídos para garantir a independência e a robustez da equipe como um todo.\n",
    "\n",
    "## Como o Dropout Funciona?\n",
    "\n",
    "- **Processo**: Em cada época de treinamento, um percentual de neurônios é aleatoriamente \"desligado\", ou seja, não contribui para o treinamento.\n",
    "- **Taxa de Dropout**: Define a proporção de neurônios a serem desativados, por exemplo, uma taxa de 0.5 desativa 50% dos neurônios.\n",
    "\n",
    "## Benefícios do Dropout\n",
    "\n",
    "- **Prevenção de Overfitting**: Evita a dependência excessiva dos neurônios em características específicas.\n",
    "- **Promove a Robustez**: Força a rede a ser mais flexível e adaptável.\n",
    "\n",
    "## Aplicando o Dropout\n",
    "\n",
    "- **Camadas Iniciais**: Pode ser útil para evitar dependências nos dados de entrada.\n",
    "- **Camadas Ocultas Densas**: Comumente usado aqui para prevenir overfitting devido à alta densidade de neurônios.\n",
    "- **Camadas Finais**: Use com cautela para evitar a perda de informações críticas.\n",
    "\n",
    "## Quando e Como Usar Dropout?\n",
    "\n",
    "- **Em Redes Profundas**: Útil em redes neurais profundas com muitos neurônios.\n",
    "- **Ajuste a Taxa de Dropout**: Use a validação cruzada para encontrar a taxa de dropout ideal.\n",
    "- **Observe o Desempenho**: Monitore o desempenho do modelo para garantir que o dropout está beneficiando o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risco Estrutural em Aprendizado de Máquina\n",
    "\n",
    "O **risco estrutural** é um conceito fundamental em aprendizado de máquina que se refere ao erro inerente à arquitetura de um modelo, independentemente dos dados de treinamento específicos utilizados. Ele destaca a importância de escolher um modelo com a complexidade adequada para a tarefa em questão.\n",
    "\n",
    "## Exemplos\n",
    "\n",
    "1. **Modelo Simples**:\n",
    "   - **Exemplo**: Usar uma regressão linear para dados com relação polinomial.\n",
    "   - **Problema**: O modelo não consegue capturar a relação subjacente (underfitting).\n",
    "   - **Risco Estrutural**: Alto, pois a simplicidade do modelo leva a erros significativos em novos dados.\n",
    "\n",
    "2. **Modelo Complexo**:\n",
    "   - **Exemplo**: Usar um polinômio de alto grau para dados linearmente relacionados.\n",
    "   - **Problema**: O modelo tenta se ajustar a cada ponto, incluindo ruído (overfitting).\n",
    "   - **Risco Estrutural**: Alto, devido à excessiva complexidade do modelo.\n",
    "\n",
    "## Risco Estrutural vs. Risco Empírico\n",
    "\n",
    "- **Risco Empírico**:\n",
    "  - **Definição**: Erro do modelo nos dados de treinamento.\n",
    "  - **Foco**: Minimizar o erro nos dados vistos.\n",
    "  \n",
    "- **Risco Estrutural**:\n",
    "  - **Definição**: Erro esperado do modelo em novos dados.\n",
    "  - **Foco**: Escolher a complexidade do modelo para minimizar o erro em dados não vistos.\n",
    "\n",
    "## Balanceando Risco Empírico e Estrutural\n",
    "\n",
    "- **Objetivo**: Encontrar um equilíbrio entre um modelo nem muito simples (alto risco estrutural) nem muito complexo (risco empírico baixo, mas alto risco estrutural em novos dados).\n",
    "- **Técnica**: Utilizar validação cruzada para avaliar o desempenho do modelo em dados não vistos e ajustar a complexidade do modelo conforme necessário.\n",
    "\n",
    "# Prática: Demonstração de Risco Estrutural\n",
    "\n",
    "Uma das maneiras mais eficazes de demonstrar o risco estrutural é mostrando que, mesmo que um modelo tenha um risco empírico baixo (isto é, ele se ajuste bem aos dados de treinamento), ele pode não generalizar bem para novos dados. Esta é uma indicação de que o modelo pode estar superajustando (overfitting) ao conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = model.predict(X_train)\n",
    "predict_test = model.predict(X_test)\n",
    "mse_train = mean_squared_error(y_train, predict_train)\n",
    "mse_test = mean_squared_error(y_test, predict_test)\n",
    "print(f\"Risco Empírico (MSE) Treinamento: {mse_train:.3f}\")\n",
    "print(f\"Risco Empírico (MSE) Teste: {mse_test:.3f}\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(y_test[:60].values, 'o', color=\"darkorange\", label=\"Dados Reais\")\n",
    "plt.plot(predict_test[:60], 'o', color=\"blue\", label=\"Previsão\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Valores\")\n",
    "plt.title(\"Comparação entre Dados Reais e Previsões sem Normalização\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensão VC\n",
    "\n",
    "A **Dimensão VC** é uma métrica teórica que quantifica a capacidade de um modelo de aprendizado estatístico de se ajustar a diferentes conjuntos de dados. Ela é um indicador da complexidade do modelo, refletindo sua flexibilidade em aprender padrões a partir dos dados.\n",
    "\n",
    "### O que é uma Dimensão VC Alta ou Baixa?\n",
    "\n",
    "- **Dimensão VC Alta**: \n",
    "    - **O que é**: Um modelo com uma Dimensão VC alta tem uma capacidade significativa de se ajustar aos dados.\n",
    "    - **Vantagens**: Pode capturar padrões complexos e sutis nos dados.\n",
    "    - **Desvantagens**: Risco de overfitting, onde o modelo aprende o ruído dos dados como se fosse um padrão legítimo.\n",
    "    - **Exemplo**: Redes neurais profundas geralmente têm uma Dimensão VC alta.\n",
    "  \n",
    "- **Dimensão VC Baixa**: \n",
    "    - **O que é**: Um modelo com uma Dimensão VC baixa tem capacidade limitada de se ajustar aos dados.\n",
    "    - **Vantagens**: Menor risco de overfitting.\n",
    "    - **Desvantagens**: Pode não ser capaz de capturar padrões mais complexos, levando ao underfitting.\n",
    "    - **Exemplo**: Uma regressão linear tem uma Dimensão VC baixa.\n",
    "\n",
    "### Como Balancear?\n",
    "O objetivo é encontrar um equilíbrio, escolhendo um modelo com a Dimensão VC adequada para o problema específico, evitando tanto o overfitting quanto o underfitting.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o X_temp em três conjuntos de treinamento de tamanhos iguais\n",
    "X_train1, X_temp, y_train1, y_temp = train_test_split(X_train, y_train, test_size=(2/3), random_state=42)\n",
    "X_train2, X_train3, y_train2, y_train3 = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "X_trains = [X_train1, X_train2, X_train3]\n",
    "y_trains = [y_train1, y_train2, y_train3]\n",
    "\n",
    "def train_model(X_train,y_train, X_val, y_val):\n",
    "    model = create_l1_l2_model(input_shape)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10,\n",
    "        verbose=0,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    return model\n",
    "# Treinando e avaliando modelos\n",
    "for cont in range(3):\n",
    "    model = train_model(X_trains[cont],y_trains[cont], X_val, y_val)\n",
    "\n",
    "    train_error = mean_squared_error(y_trains[cont], model.predict(X_trains[cont]))\n",
    "    test_error = mean_squared_error(y_test, model.predict(X_test))\n",
    "    \n",
    "    print(f\"Subconjunto de treinamento {cont} (Tamanho {len(y_trains[cont])}):\")\n",
    "    print(f\"Erro de treinamento: {train_error:.5f}\")\n",
    "    print(f\"Erro de teste: {test_error:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistência do Erro\n",
    "\n",
    "- **Importância**: A consistência nos erros de treinamento e teste indica um alinhamento adequado entre a capacidade do modelo e a complexidade dos dados.\n",
    "- **Exemplo**: Um modelo com alta Dimensão VC pode apresentar baixo erro de treinamento, mas alto erro de teste, sinalizando overfitting.\n",
    "\n",
    "## Variação entre Subconjuntos\n",
    "\n",
    "- **Relevância**: A variação nos erros entre diferentes subconjuntos reflete a influência dos dados específicos no treinamento.\n",
    "- **Análise**: Uma variação não drasticamente diferente indica que o modelo é suficientemente flexível para se adaptar a diferentes subconjuntos de dados.\n",
    "- **Exemplo**: Um modelo com baixa Dimensão VC pode apresentar grande variação nos erros, indicando sua incapacidade de se ajustar bem a variações nos dados.\n",
    "\n",
    "## Relação com a Dimensão VC\n",
    "\n",
    "- **Estimativa da Dimensão VC**: Usamos métricas como erro de treinamento e teste para ter uma ideia da Dimensão VC do modelo.\n",
    "- **Análise dos Erros**: \n",
    "  - **Overfitting**: Erros de treinamento baixos e erros de teste altos indicam uma Dimensão VC muito alta.\n",
    "  - **Underfitting**: Erros de treinamento e teste altos indicam uma Dimensão VC muito baixa.\n",
    "- **Conclusão**: O modelo deve ter uma capacidade adequada para os dados, com erros de treinamento e teste consistentes em diferentes subconjuntos.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "- **Avaliação Final**: A análise do risco estrutural e da Dimensão VC é crucial para entender e melhorar a performance do modelo.\n",
    "- **Próximos Passos**: Experimentar com modelos de diferentes complexidades e observar a variação nos erros de treinamento e teste pode fornecer insights mais profundos sobre a Dimensão VC do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilema Bias-Variance\n",
    "\n",
    "O **Dilema Bias-Variance** é um problema fundamental no aprendizado de máquina, referindo-se ao trade-off entre o erro devido a suposições simplistas (bias) e o erro devido a excessiva sensibilidade aos dados de treinamento (variance).\n",
    "\n",
    "# Bias e Variance:\n",
    "\n",
    "- **Bias Alto**:\n",
    "    - **O que é**: Erro devido a suposições simplistas sobre a forma do relacionamento entre as variáveis.\n",
    "    - **Consequências**: Erro sistemático e consistente nos dados, levando a underfitting.\n",
    "    - **Quando é Bom**: Quando sabemos que a relação entre as variáveis é de fato simples.\n",
    "  \n",
    "- **Variance Alta**:\n",
    "    - **O que é**: Erro devido a excessiva sensibilidade aos dados de treinamento.\n",
    "    - **Consequências**: O modelo se ajusta demais aos dados de treinamento, capturando o ruído como padrão, levando a overfitting.\n",
    "    - **Quando é Bom**: Quando temos grandes volumes de dados e a complexidade real do problema é alta.\n",
    "\n",
    "### Como Balancear?\n",
    "O objetivo é minimizar tanto o bias quanto a variance para construir um modelo robusto e confiável que performe bem em dados não vistos, encontrando um ponto de equilíbrio que minimize o erro total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar os resultados\n",
    "def plot_results_nn(model, title, subplot, X_train, y_train, X_test, y_test):\n",
    "    history = model.fit(X_train, y_train, epochs=5, verbose=0)\n",
    "    train_loss = history.history['loss'][-1]  # Pega o último loss de treinamento\n",
    "    predict = model.predict(X_test)\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)  # Calcula o loss de teste\n",
    "    ax = plt.subplot(subplot)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(y_train[:60].values, 'o', color=\"darkorange\", label=\"Dados Reais\")\n",
    "    plt.plot(predict[:60], 'o', color=\"blue\", label=\"Previsão\")\n",
    "    plt.xlabel(\"Índice\")\n",
    "    plt.ylabel(\"Valores\")\n",
    "    # Adiciona o loss de treino e teste ao título\n",
    "    plt.title(f\"{title}\\nTrain Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(1, activation='linear',  input_shape=(input_shape,)))  # Camada de entrada e única camada oculta\n",
    "model_1.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(50, activation='relu',  input_shape=(input_shape,)))  # Camada de entrada\n",
    "model_2.add(Dense(30, activation='relu'))  \n",
    "model_2.add(Dense(30, activation='relu'))  \n",
    "model_2.add(Dense(1, activation='linear'))\n",
    "model_2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(128, activation='relu',  input_shape=(input_shape,)))  # Camada de entrada\n",
    "model_3.add(Dense(64, activation='relu'))  \n",
    "model_3.add(Dense(16, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))  \n",
    "model_3.add(Dense(8, activation='relu'))  \n",
    "model_3.add(Dense(1, activation='linear'))\n",
    "model_3.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Plotando os resultados\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Passe X_train, y_train, X_test e y_test como argumentos adicionais para plot_results_nn\n",
    "plot_results_nn(model_1, \"Rede Neural 1\", 131, X_train, y_train, X_test, y_test)\n",
    "plot_results_nn(model_2, \"Rede Neural 2\", 132, X_train, y_train, X_test, y_test)\n",
    "plot_results_nn(model_3, \"Rede Neural 3\", 133, X_train, y_train, X_test, y_test)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "# Função para calcular bias, variance e erro total\n",
    "def calculate_bias_variance(models, X_train, X_test, y_train, y_test):\n",
    "    biases, variances, errors = [], [], []\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train, epochs=20, verbose=0)  # Treinando cada modelo\n",
    "        predictions = model.predict(X_test).flatten()  # Previsões do modelo\n",
    "        \n",
    "        # Calculando bias, variance e erro total\n",
    "        bias = np.mean((predictions - y_test.values.flatten()) ** 2)\n",
    "        variance = np.var(predictions)\n",
    "        error = mean_squared_error(y_test.values.flatten(), predictions)\n",
    "        \n",
    "        biases.append(bias)\n",
    "        variances.append(variance)\n",
    "        errors.append(error)\n",
    "    return biases, variances, errors\n",
    "\n",
    "# Criando modelos de redes neurais correspondentes a diferentes \"complexidades\"\n",
    "models = []\n",
    "for cont in range(1, 15):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10*cont , activation='relu',input_shape=(X_train.shape[1],)))   # Camada de entrada e oculta, aumentando neurônios conforme o loop\n",
    "    model.add(Dense(1, activation='linear'))  # Camada de saída\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    models.append(model)\n",
    "\n",
    "biases, variances, errors = calculate_bias_variance(models, X_train[:2500], X_test, y_train[:2500], y_test)\n",
    "clear_output(wait=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Criando um eixo para bias\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(range(1, 15), biases, label='Bias ($Bias^2$)', marker='o', color='blue')\n",
    "ax1.set_xlabel('Complexidade do Modelo (10x neurônios)')\n",
    "ax1.set_ylabel('Bias ($Bias^2$)', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Criando um segundo eixo para variância e erro total\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(1, 15), variances, label='Variance', marker='o', color='green')\n",
    "ax2.plot(range(1, 15), errors, label='Erro Total', marker='o', color='red')\n",
    "ax2.set_ylabel('Variance / Erro Total', color='green')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "plt.title('Dilema Bias-Variance com Redes Neurais de Diferentes Complexidades')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# À medida que a complexidade do modelo (número de neurônios) aumenta, o bias tende a diminuir, mas a variância tede a aumentar.\n",
    "# O erro total tem um ponto de mínimo, onde a combinação de bias e variância é ótima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "# Função para calcular bias, variance e erro total\n",
    "def calculate_bias_variance(models, X_test, y_test):\n",
    "    biases, variances, errors = [], [], []\n",
    "    for model in models:\n",
    "        predictions = model.predict(X_test).flatten()  # Previsões do modelo\n",
    "        \n",
    "        # Calculando bias, variance e erro total\n",
    "        bias = np.mean((predictions - y_test.values.flatten()) ** 2)\n",
    "        variance = np.var(predictions)\n",
    "        error = mean_squared_error(y_test.values.flatten(), predictions)\n",
    "        \n",
    "        biases.append(bias)\n",
    "        variances.append(variance)\n",
    "        errors.append(error)\n",
    "    return biases, variances, errors\n",
    "\n",
    "\n",
    "# Criando modelos de redes neurais correspondentes a diferentes \"complexidades\"\n",
    "models = [model_1, model_2, model_3]\n",
    "\n",
    "biases, variances, errors = calculate_bias_variance(models, X_test, y_test)\n",
    "clear_output(wait=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Criando um eixo para bias\n",
    "ax1 = plt.gca()\n",
    "ax1.plot(range(1, 4), biases, label='Bias ($Bias^2$)', marker='o', color='blue')\n",
    "ax1.set_xlabel('Complexidade do Modelo (10x neurônios)')\n",
    "ax1.set_ylabel('Bias ($Bias^2$)', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Criando um segundo eixo para variância e erro total\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(1, 4), variances, label='Variance', marker='o', color='green')\n",
    "ax2.plot(range(1, 4), errors, label='Erro Total', marker='o', color='red')\n",
    "ax2.set_ylabel('Variance / Erro Total', color='green')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "plt.title('Dilema Bias-Variance com Redes Neurais de Diferentes Complexidades')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Dataset audi.csv representa informações de carros da marca audi no Reino Unido, tendo com 9 atriburos e uma classe alvo que é \"price\", que representa a o valor do carro (ou coleção)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1 - Leia  abase de dados e converta valores textuais para numéricos;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2 - Separe a base em X e y de treinamento (80%) e teste (20%), normalize os dados de treinamento com fit_transform e em seguida normalize os dados de teste com o transform;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3 - Defina um modelo com 12 camadas ocultas (sem dropout e regularização de kernel) e verifique o risco empírico dele, comparando valores previstos de treinamento e teste (não esqueça de dessnormalizar os valores para os cálculos das métricas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4 - Plote um gráfico com os valores reais e preditos de treinamento;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5 - Plote um gráfico com os valores reais e preditos de teste;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 6 - Analizando as 3 questões anteriores, o modelo possui um alto, baixo ou médio risco empírico? Justifique sua resposta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 7 -  Diria que o modelo possui underfitting, overfitting ou nenhum dos dois? Justifique sua resposta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 8 - Se fosse aplicar regularização de kernel e/ou dropout, como ficaria o seu modelo mantendo as mesmas camadas ocultas? Justifique sua resposta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 9 - Verifique a flexibilidade do novo modelo com dropout e/ou regularização de kernel (Risco estrutural). Separe a base de treinamento em 4 subconjuntos do mesmo tamanho, treine o modelo 4 vezes com as 4 bases de treinamento diferentes, em seguida exiba o mse dos dados de treinamento e teste dos 4 modelos (não esqueça de desnormalizar os valores antes de gerar as métricas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 10 - Como você classificaria o a dimensão VC deste modelo? Justifique sua resposta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
