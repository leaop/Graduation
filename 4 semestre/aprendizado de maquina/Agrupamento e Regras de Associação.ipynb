{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução aos Métodos Descritivos\n",
    "\n",
    "## Definição de Métodos Descritivos\n",
    "Métodos Descritivos em Machine Learning são técnicas usadas para explorar, analisar e descrever a estrutura dos dados. \n",
    "Diferentemente dos métodos preditivos, que focam em prever variáveis alvo (classe alvo - aprendizado supervisionado), os métodos descritivos buscam identificar padrões, relações ou características intrínsecas nos dados, sem a necessidade de uma variável de resposta pré-definida (sem classe alvo, algoritmo não-supervisionado).\n",
    "\n",
    "## Importância e Aplicações do Agrupamento\n",
    "- **Agrupamento (Clustering):**\n",
    "  - *Conceito:* O agrupamento visa agrupar dados com características similares.\n",
    "  - *Importância:* Ajuda a descobrir a estrutura subjacente nos dados, útil em análise exploratória.\n",
    "  - *Aplicações:* Segmentação de mercado, organização de grandes bibliotecas de documentos, análise de redes sociais, e em sistemas de recomendação para encontrar grupos de itens semelhantes.\n",
    "\n",
    "## Importância e Aplicações das Regras de Associação\n",
    "- **Regras de Associação:**\n",
    "  - *Conceito:* Estas regras são usadas para identificar relações frequentes e fortes entre variáveis em grandes conjuntos de dados.\n",
    "  - *Importância:* Cruciais para a análise de transações, ajudando a entender padrões de compra do consumidor.\n",
    "  - *Aplicações:* Análise de cesto de compras, detecção de fraudes, análise de redes sociais e bioinformática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas essenciais para análise de dados e machine learning\n",
    "import pandas as pd         # Para manipulação e análise de dados\n",
    "import numpy as np          # Para operações numéricas e matriciais\n",
    "import matplotlib.pyplot as plt  # Para visualização de dados\n",
    "import seaborn as sns       # Para visualização de dados avançada\n",
    "\n",
    "# Bibliotecas específicas para métodos de Machine Learning\n",
    "from sklearn.cluster import KMeans  # Para o algoritmo de agrupamento K-Means\n",
    "from sklearn.decomposition import PCA  # Para análise de componentes principais (PCA)\n",
    "from sklearn.preprocessing import StandardScaler  # Para normalização de dados\n",
    "\n",
    "# Configurações adicionais para visualizações\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Agrupamento (Clustering)\n",
    "\n",
    "## Introdução ao Conceito de Agrupamento\n",
    "O Agrupamento, ou Clustering, é um método de aprendizado não supervisionado que envolve a divisão de um conjunto de dados em subconjuntos, de modo que os dados em cada subconjunto (idealmente) compartilham algumas características comuns ou propriedades. O objetivo é descobrir uma estrutura ou padrão inerente nos dados, agrupando-os com base na semelhança de suas características.\n",
    "\n",
    "## Tipos de Técnicas de Agrupamento e Suas Aplicações\n",
    "- **K-Means:** \n",
    "  - *Descrição:* Divide os dados em K grupos distintos baseados na distância aos centróides.\n",
    "  - *Aplicações:* Segmentação de mercado, agrupamento de documentos, análise de imagens e dados geoespaciais.\n",
    "\n",
    "- **Agrupamento Hierárquico:** \n",
    "  - *Descrição:* Constrói uma hierarquia de clusters, seja de forma aglomerativa (bottom-up) ou divisiva (top-down).\n",
    "  - *Aplicações:* Análise taxonômica, organização de bibliotecas de mídia, categorização de produtos.\n",
    "\n",
    "- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise):** \n",
    "  - *Descrição:* Agrupa pontos que estão próximos uns dos outros com base na densidade.\n",
    "  - *Aplicações:* Detecção de anomalias, análise de dados espaciais, identificação de aglomerados em dados de alta dimensionalidade.\n",
    "\n",
    "- **Agrupamento Baseado em Modelo:** \n",
    "  - *Descrição:* Utiliza modelos probabilísticos para determinar a pertinência dos dados a um cluster.\n",
    "  - *Aplicações:* Bioinformática (por exemplo, agrupamento de genes), marketing (segmentação de clientes), análise de redes sociais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "class KMeansVisualizer:\n",
    "    def __init__(self, X, n_clusters, n_iterations, output_widget):\n",
    "        self.X = X\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_iterations = n_iterations\n",
    "        self.kmeans = KMeans(n_clusters=n_clusters, init='random', n_init=1, random_state=0)\n",
    "        self.current_iteration = 0\n",
    "        self.output_widget = output_widget\n",
    "        self.states = []\n",
    "\n",
    "        for i in range(n_iterations):\n",
    "            self.kmeans.max_iter = i + 1\n",
    "            y_kmeans = self.kmeans.fit_predict(X)\n",
    "            centers = self.kmeans.cluster_centers_\n",
    "            self.states.append((y_kmeans.copy(), centers.copy()))\n",
    "\n",
    "    def plot_current_state(self):\n",
    "        with self.output_widget:\n",
    "            self.output_widget.clear_output(wait=True)\n",
    "            y_kmeans, centers = self.states[self.current_iteration]\n",
    "            plt.scatter(self.X[:, 0], self.X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "            plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5, marker='x')\n",
    "            plt.title(f'K-Means Iteration {self.current_iteration + 1}')\n",
    "            plt.show()\n",
    "\n",
    "    def on_previous_clicked(self, b):\n",
    "        if self.current_iteration > 0:\n",
    "            self.current_iteration -= 1\n",
    "            self.plot_current_state()\n",
    "\n",
    "    def on_next_clicked(self, b):\n",
    "        if self.current_iteration < self.n_iterations - 1:\n",
    "            self.current_iteration += 1\n",
    "            self.plot_current_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atualização dos Centróides no K-Means\n",
    "\n",
    "O K-Means é um algoritmo de agrupamento que busca particionar um conjunto de dados em K grupos distintos. Uma das etapas cruciais desse algoritmo é a atualização dos centróides dos clusters. Vamos entender como isso é feito:\n",
    "\n",
    "## 1. Inicialização dos Centróides\n",
    "- No início, K centróides são inicializados. Isso pode ser feito de várias maneiras, como escolher aleatoriamente K pontos dos dados ou pontos aleatórios no espaço de características.\n",
    "- Esses centróides iniciais servem como ponto de partida para a formação dos clusters.\n",
    "\n",
    "## 2. Atribuição de Pontos aos Clusters\n",
    "- Cada ponto de dado é atribuído ao cluster do centróide mais próximo.\n",
    "- A proximidade é geralmente medida usando a distância euclidiana entre o ponto de dado e o centróide.\n",
    "\n",
    "## 3. Recálculo dos Centróides\n",
    "- Após a atribuição de todos os pontos a clusters, os centróides são recalculados.\n",
    "- O novo centróide de um cluster é calculado tomando a média de todas as coordenadas dos pontos de dados no cluster.\n",
    "- Matematicamente, se um cluster tem pontos \\(x_1, x_2, ..., x_n\\), o novo centróide \\(c\\) é calculado como:\n",
    "  \\[ c = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\]\n",
    "- Isso significa que cada coordenada do centróide é a média das coordenadas correspondentes de todos os pontos no cluster.\n",
    "\n",
    "## 4. Repetição do Processo\n",
    "- O processo de atribuição de pontos e recalculação dos centróides é repetido.\n",
    "- A cada iteração, os centróides se movem, idealmente, para a posição que minimiza a variação dentro de cada cluster.\n",
    "\n",
    "## 5. Convergência\n",
    "- O algoritmo continua iterando até que os centróides não mudem significativamente entre as iterações consecutivas, indicando a convergência.\n",
    "- Outro critério de parada comum é o número máximo de iterações, que previne o algoritmo de correr indefinidamente.\n",
    "\n",
    "## Resultado Final\n",
    "- Ao final, os centróides representam o 'centro' de seus clusters, e os pontos de dados são agrupados de forma que a distância total entre eles e os centróides de seus respectivos clusters seja minimizada.\n",
    "\n",
    "Este processo iterativo permite que o K-Means encontre uma boa partição dos dados, agrupando-os efetivamente em clusters com características semelhantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados sintéticos\n",
    "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.6, random_state=16)\n",
    "\n",
    "output_widget = widgets.Output()\n",
    "visualizer = KMeansVisualizer(X, n_clusters=4, n_iterations=5, output_widget=output_widget)\n",
    "\n",
    "# Criando botões de navegação\n",
    "previous_button = widgets.Button(description='Previous')\n",
    "next_button = widgets.Button(description='Next')\n",
    "previous_button.on_click(visualizer.on_previous_clicked)\n",
    "next_button.on_click(visualizer.on_next_clicked)\n",
    "\n",
    "# Exibir os widgets e o gráfico inicial\n",
    "buttons = widgets.HBox([previous_button, next_button])\n",
    "display(buttons, output_widget)\n",
    "visualizer.plot_current_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Algoritmos de Agrupamento\n",
    "\n",
    "## Algoritmo Hierárquico\n",
    "### Descrição\n",
    "- O Agrupamento Hierárquico é um método de análise de cluster que busca construir uma hierarquia de clusters.\n",
    "- Existem dois tipos: Aglomerativo (bottom-up) e Divisivo (top-down).\n",
    "\n",
    "### Vantagens\n",
    "- Não requer a especificação do número de clusters.\n",
    "- O dendrograma produzido é útil para entender os dados.\n",
    "\n",
    "### Desvantagens\n",
    "- Computacionalmente caro, especialmente para grandes conjuntos de dados.\n",
    "- Uma vez que uma decisão é feita para combinar dois clusters, não pode ser desfeita.\n",
    "\n",
    "## DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "### Descrição\n",
    "- DBSCAN agrupa pontos que estão próximos um do outro com base em densidade.\n",
    "- Pontos em regiões de alta densidade são agrupados juntos, e pontos em regiões de baixa densidade são considerados ruído.\n",
    "\n",
    "### Vantagens\n",
    "- Não requer que se especifique o número de clusters.\n",
    "- Pode encontrar clusters de formas arbitrárias.\n",
    "\n",
    "### Desvantagens\n",
    "- Não se sai bem quando os clusters variam significativamente em densidade.\n",
    "- A escolha dos parâmetros (eps e min_samples) pode ser difícil.\n",
    "\n",
    "## Outros Algoritmos de Agrupamento\n",
    "- **Mean Shift:** Baseia-se em deslizar janelas para a densidade mais alta de pontos.\n",
    "- **Expectation-Maximization (EM) usando Misturas Gaussianas:** Modelo baseado em misturas de distribuições Gaussianas.\n",
    "- **Agrupamento Espectral:** Usa autovalores de uma matriz de similaridade para reduzir a dimensionalidade antes de agrupar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos Práticos de Algoritmos de Agrupamento com Visualizações\n",
    "\n",
    "# Importando as bibliotecas necessárias\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Configurações para visualizações\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "# Gerando um dataset para Agrupamento Hierárquico e DBSCAN\n",
    "X_moons, _ = make_moons(n_samples=300, noise=0.05, random_state=42)\n",
    "\n",
    "# Aplicando Agrupamento Hierárquico\n",
    "linked = linkage(X_moons, 'single')\n",
    "plt.subplot(1, 2, 1)\n",
    "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
    "plt.title('Dendrograma - Agrupamento Hierárquico')\n",
    "plt.xlabel('Amostra')\n",
    "plt.ylabel('Distância')\n",
    "\n",
    "# Aplicando DBSCAN\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X_moons)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=clusters, cmap='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comentários:\n",
    "# Este bloco de código demonstra a aplicação prática de dois algoritmos de agrupamento: Hierárquico e DBSCAN.\n",
    "# O dendrograma ajuda a entender como os clusters hierárquicos são formados.\n",
    "# DBSCAN é aplicado ao mesmo conjunto de dados, mostrando como ele agrupa dados com base na densidade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicação dos Modelos de Clusterização e seus Parâmetros\n",
    "\n",
    "## K-Means\n",
    "- **Descrição:** O K-Means é um algoritmo de clusterização que particiona o conjunto de dados em K grupos distintos, minimizando a soma das distâncias quadradas de cada ponto ao centróide do seu cluster.\n",
    "- **Parâmetros Principais:**\n",
    "  - `n_clusters`: Número de clusters desejados.\n",
    "  - `random_state`: Semente para a geração de números aleatórios, garantindo a reproducibilidade.\n",
    "\n",
    "## Agrupamento Hierárquico (AgglomerativeClustering)\n",
    "- **Descrição:** Este método constrói uma hierarquia de clusters, fundindo iterativamente os pares de clusters que minimizam algum critério de ligação.\n",
    "- **Parâmetros Principais:**\n",
    "  - `n_clusters`: Número de clusters a serem formados e a quantidade de centróides a serem gerados.\n",
    "  - Não possui um `random_state`, pois o algoritmo é determinístico.\n",
    "\n",
    "## DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "- **Descrição:** O DBSCAN agrupa pontos que estão densamente agrupados e marca pontos em regiões pouco densas como ruído ou outliers.\n",
    "- **Parâmetros Principais:**\n",
    "  - `eps`: A distância máxima entre dois pontos para serem considerados no mesmo bairro.\n",
    "  - `min_samples`: O número mínimo de pontos para formar um cluster denso.\n",
    "\n",
    "## Agrupamento Baseado em Modelo (GaussianMixture)\n",
    "- **Descrição:** Este modelo assume que os dados são gerados a partir de uma mistura de várias distribuições Gaussianas com parâmetros desconhecidos.\n",
    "- **Parâmetros Principais:**\n",
    "  - `n_components`: Número de componentes de mistura (Gaussianas) no modelo.\n",
    "  - `random_state`: Semente para a geração de números aleatórios, assegurando a reproducibilidade.\n",
    "\n",
    "Cada um desses algoritmos tem suas peculiaridades e são adequados para diferentes tipos de dados e requisitos de clusterização. A escolha do algoritmo e a configuração dos parâmetros dependem fortemente da natureza dos dados e do problema específico em questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Gerando os dados\n",
    "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.6, random_state=16)\n",
    "\n",
    "# Aplicando K-Means\n",
    "kmeans = KMeans(n_clusters=4, random_state=16)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Aplicando Agrupamento Hierárquico\n",
    "hierarchical = AgglomerativeClustering(n_clusters=4)\n",
    "hierarchical_labels = hierarchical.fit_predict(X)\n",
    "\n",
    "# Aplicando DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X)\n",
    "\n",
    "# Aplicando Agrupamento Baseado em Modelo (Gaussian Mixture)\n",
    "gmm = GaussianMixture(n_components=4, random_state=16)\n",
    "gmm_labels = gmm.fit_predict(X)\n",
    "\n",
    "# Criando gráficos\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# K-Means\n",
    "axs[0, 0].scatter(X[:, 0], X[:, 1], c=kmeans_labels, cmap='viridis', marker='o', edgecolor='k', s=50)\n",
    "axs[0, 0].set_title('K-Means Clustering')\n",
    "\n",
    "# Agrupamento Hierárquico\n",
    "axs[0, 1].scatter(X[:, 0], X[:, 1], c=hierarchical_labels, cmap='viridis', marker='o', edgecolor='k', s=50)\n",
    "axs[0, 1].set_title('Hierarchical Clustering')\n",
    "\n",
    "# DBSCAN\n",
    "axs[1, 0].scatter(X[:, 0], X[:, 1], c=dbscan_labels, cmap='viridis', marker='o', edgecolor='k', s=50)\n",
    "axs[1, 0].set_title('DBSCAN Clustering')\n",
    "\n",
    "# Agrupamento Baseado em Modelo (Gaussian Mixture)\n",
    "axs[1, 1].scatter(X[:, 0], X[:, 1], c=gmm_labels, cmap='viridis', marker='o', edgecolor='k', s=50)\n",
    "axs[1, 1].set_title('Gaussian Mixture Clustering')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regras de Associação\n",
    "\n",
    "## Fundamentos das Regras de Associação\n",
    "Regras de Associação são uma técnica importante em Data Mining para descobrir relações interessantes entre variáveis em grandes bancos de dados. Elas são usadas para identificar padrões, correlações ou estruturas frequentes entre conjuntos de itens ou atributos em transações ou outros conjuntos de dados.\n",
    "\n",
    "As regras são frequentemente aplicadas em Análise de Cesto de Compras, onde descobrimos quais produtos tendem a ser comprados juntos. Elas também são úteis em uma variedade de outros campos, como bioinformática, análise de redes sociais e recomendações de produtos.\n",
    "\n",
    "## Medidas de Associação: Suporte, Confiança e Lift\n",
    "- **Suporte:** \n",
    "  - Indica quão frequentemente uma regra de associação é verdadeira em um conjunto de dados.\n",
    "  - Calculado como a proporção de transações que contêm todos os itens da regra.\n",
    "\n",
    "- **Confiança:** \n",
    "  - Mede a confiabilidade da inferência feita pela regra.\n",
    "  - Calculado como a proporção de transações com o item X que também contêm o item Y.\n",
    "\n",
    "- **Lift:** \n",
    "  - Indica a força da associação entre os itens da regra.\n",
    "  - Calculado como a razão entre a confiança da regra e o suporte do item consequente. \n",
    "  - Um lift maior que 1 indica uma associação forte.\n",
    "\n",
    "\n",
    "## Casos de Uso Reais das Regras de Associação\n",
    "\n",
    "### Análise de Cesto de Compras (Market Basket Analysis)\n",
    "- **Descrição:** Identifica quais produtos são frequentemente comprados juntos em supermercados ou lojas online.\n",
    "- **Aplicação:** Usado para otimizar a disposição de produtos nas prateleiras, em promoções cruzadas e para desenvolver estratégias de marketing direcionado.\n",
    "\n",
    "### Recomendação de Produtos\n",
    "- **Descrição:** Sugere produtos complementares ou alternativos a clientes com base em suas compras anteriores.\n",
    "- **Aplicação:** Amplamente utilizado em e-commerce para impulsionar vendas através de recomendações personalizadas.\n",
    "\n",
    "### Análise de Sequência em Bioinformática\n",
    "- **Descrição:** Encontra padrões e associações em sequências biológicas, como DNA, RNA ou proteínas.\n",
    "- **Aplicação:** Auxilia na identificação de relações funcionais entre genes ou na descoberta de novos alvos para drogas.\n",
    "\n",
    "### Detecção de Fraudes\n",
    "- **Descrição:** Identifica combinações incomuns de atividades que podem indicar comportamento fraudulento.\n",
    "- **Aplicação:** Utilizado por instituições financeiras para prevenir fraudes em cartões de crédito ou transações bancárias.\n",
    "\n",
    "### Análise de Redes Sociais\n",
    "- **Descrição:** Descobre padrões de relacionamento e interação entre usuários ou grupos.\n",
    "- **Aplicação:** Usado para entender a dinâmica de redes sociais, identificar influenciadores e otimizar campanhas de marketing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Groceries_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.itemDescription.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Member_number'] == 1000].sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando os itens por Member_number e Date para criar carrinhos de compras\n",
    "grouped = df.groupby(['Member_number', 'Date'])['itemDescription'].apply(list).reset_index(name='Items')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todos os carrinhos de compras\n",
    "transactions = grouped['Items'].tolist()\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Preparando os dados para o modelo Apriori\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_transformed = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicação dos Parâmetros do Código Apriori e Association Rules\n",
    "\n",
    "## Parâmetros do Apriori\n",
    "O método `apriori` é utilizado para encontrar conjuntos de itens frequentes.\n",
    "\n",
    "- **df_transformed:** \n",
    "  - O DataFrame transformado que representa as transações. Cada coluna representa um item, e cada linha representa uma transação. Os valores são `True` se o item estiver presente na transação.\n",
    "\n",
    "- **min_support:** \n",
    "  - O suporte mínimo é um valor entre 0 e 1 que define a frequência mínima (relativa) que um conjunto de itens deve ter para ser considerado frequente. \n",
    "  - No código, `min_support=0.01` significa que estamos considerando conjuntos de itens que aparecem em pelo menos 1% das transações.\n",
    "\n",
    "- **use_colnames:** \n",
    "  - Quando definido como `True`, permite que o DataFrame resultante use os nomes das colunas (nomes dos itens) em vez de índices de coluna.\n",
    "\n",
    "## Parâmetros do Association Rules\n",
    "O método `association_rules` é utilizado para extrair regras de associação dos conjuntos de itens frequentes.\n",
    "\n",
    "- **frequent_itemsets:** \n",
    "  - O DataFrame gerado pelo método Apriori contendo os conjuntos de itens frequentes.\n",
    "\n",
    "- **metric:** \n",
    "  - A métrica a ser usada para identificar regras importantes. \n",
    "  - No código, `metric=\"confidence\"` significa que estamos interessados na confiança das regras.\n",
    "\n",
    "- **min_threshold:** \n",
    "  - O valor mínimo para a métrica especificada. \n",
    "  - Com `min_threshold=0.1`, estamos filtrando regras que têm uma confiança de pelo menos 10%.\n",
    "\n",
    "## Colunas do DataFrame de Regras\n",
    "- **antecedents:** \n",
    "  - O antecedente da regra. Este é o conjunto de itens que implica o consequente.\n",
    "\n",
    "- **consequents:** \n",
    "  - O consequente da regra. Este é o item ou conjunto de itens que são implicados pelo antecedente.\n",
    "\n",
    "- **support:** \n",
    "  - A proporção de transações que contêm tanto o antecedente quanto o consequente. É uma medida de quão frequentemente a regra ocorre no conjunto de dados.\n",
    "\n",
    "- **confidence:** \n",
    "  - Uma medida de quão frequentemente o consequente é verdadeiro quando o antecedente é verdadeiro. É uma medida da força da implicação.\n",
    "\n",
    "- **lift:** \n",
    "  - A razão da confiança da regra sobre a frequência esperada do consequente se antecedente e consequente fossem independentes. Um valor maior que 1 indica uma associação forte.\n",
    "\n",
    "Esta estrutura de código é comumente usada em análise de cesto de compras para descobrir padrões de compra e associações entre itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Aplicando o algoritmo Apriori para encontrar conjuntos de itens frequentes\n",
    "frequent_itemsets = apriori(df_transformed, min_support=0.01, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
