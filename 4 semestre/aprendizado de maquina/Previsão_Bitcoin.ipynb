{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação em Aprendizado de Máquina\n",
    "\n",
    "A classificação é um tipo de aprendizado supervisionado onde o objetivo é prever a categoria de entrada de um conjunto de classes. Ao contrário da regressão, que prevê um valor contínuo, a classificação prediz uma categoria discreta.\n",
    "\n",
    "#### Tipos de Classificação\n",
    "\n",
    "1. **Classificação Binária**: Classificação com duas classes. Por exemplo, determinar se um email é spam ou não spam.\n",
    "2. **Classificação Multiclasse**: Classificação com mais de duas classes. Por exemplo, classificar uma fruta como maçã, banana ou cereja.\n",
    "3. **Classificação Multilabel**: Cada exemplo pode pertencer a mais de uma classe. Por exemplo, um filme pode ser classificado em múltiplos gêneros.\n",
    "\n",
    "#### Métricas para Avaliar Modelos de Classificação\n",
    "\n",
    "Avaliar a performance de um modelo de classificação é crucial para entender como o modelo irá se comportar em dados não vistos. Algumas métricas comuns incluem:\n",
    "\n",
    "1. **Acurácia**: A proporção de predições corretas feitas pelo modelo.\n",
    "`Acurácia = (Verdadeiros Positivos + Verdadeiros Negativos) / (Total de Amostras)`\n",
    "   - **Valores bons**: Mais próximo de 1.\n",
    "   - **Valores ruins**: Mais próximo de 0.\n",
    "\n",
    "2. **Precisão**: A proporção de predições positivas corretas.\n",
    "`Precisão = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos)`\n",
    "   - **Valores bons**: Maior precisão significa menos falsos positivos.\n",
    "   - **Valores ruins**: Mais próximo de 0.\n",
    "\n",
    "3. **Recall**: A proporção de observações positivas reais que foram previstas corretamente.\n",
    "`Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos)`\n",
    "   - **Valores bons**: Maior recall significa menos falsos negativos.\n",
    "   - **Valores ruins**: Mais próximo de 0.\n",
    "\n",
    "4. **F1-Score**: A média harmônica de Precisão e Recall, útil quando você deseja balancear Precisão e Recall.\n",
    "`F1-Score = 2 * (Precisão * Recall) / (Precisão + Recall)`\n",
    "   - **Valores bons**: Mais próximo de 1, indicando bom balanceamento entre Precisão e Recall.\n",
    "   - **Valores ruins**: Mais próximo de 0.\n",
    "\n",
    "5. **Curva ROC e Área Abaixo da Curva (AUC-ROC)**: A curva ROC mostra a capacidade do modelo de distinguir entre as classes. A AUC fornece uma agregação da performance em todos os limiares de classificação possíveis.\n",
    "   - **Valores bons**: Mais próximo de 1, indicando excelente discriminação entre as classes.\n",
    "   - **Valores ruins**: Mais próximo de 0.5, indicando nenhuma discriminação.\n",
    "\n",
    "6. **Matriz de Confusão**: Uma tabela que mostra as frequências de classificação para cada classe. Não tem valores \"bons\" ou \"ruins\" em si, mas é útil para entender o tipo de erros que o modelo está cometendo.\n",
    "\n",
    "A seleção de métricas depende do problema específico, das necessidades do negócio e das características do conjunto de dados. Compreender essas métricas e seus valores ideais pode ajudar na otimização e seleção do modelo mais apropriado.\n",
    "\n",
    "#### Algoritmos Comuns de Classificação\n",
    "\n",
    "Existem diversos algoritmos usados para classificação, como:\n",
    "\n",
    "- Regressão Logística\n",
    "- Máquinas de Suporte Vetorial (SVM)\n",
    "- Árvores de Decisão e Florestas Aleatórias\n",
    "- Redes Neurais\n",
    "\n",
    "A escolha do algoritmo depende das características dos dados, dos requisitos do problema e da interpretabilidade desejada."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def metricas_classificacao(y_real, y_pred):\n",
    "    # Calcular métricas\n",
    "    metrics = {\n",
    "        \"Acurácia\": accuracy_score(y_real, y_pred),\n",
    "        \"Precisão (macro)\": precision_score(y_real, y_pred, average='macro'),\n",
    "        \"Recall (macro)\": recall_score(y_real, y_pred, average='macro'),\n",
    "        \"F1-Score (macro)\": f1_score(y_real, y_pred, average='macro')\n",
    "    }\n",
    "    \n",
    "    # Printar métricas\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Calcular a Matriz de Confusão\n",
    "    confusion_mat = confusion_matrix(y_real, y_pred)\n",
    "\n",
    "    # Printar Matriz de Confusão\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    sns.heatmap(confusion_mat, annot=True, cmap='YlGnBu', fmt='g')\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Média Macro``: Calcula a métrica independente para cada classe e, em seguida, toma a média (portanto, trata todas as classes igualmente). É útil quando você quer que cada classe tenha o mesmo peso na métrica global, independentemente de quantas amostras há em cada classe. É uma boa opção quando as classes estão desbalanceadas e você quer uma métrica que não seja influenciada por isso.\n",
    "\n",
    "`Média Micro`: Calcula a métrica globalmente, considerando cada elemento da matriz de confusão. É útil quando você quer que a métrica reflita a distribuição de classes no conjunto de dados.\n",
    "\n",
    "`Média Weighted`: Calcula a métrica para cada classe e toma a média, ponderando as métricas pelo número de verdadeiros exemplos em cada classe. É útil quando você quer que a métrica reflita a distribuição de classes, mas ainda leve em conta o desempenho em cada classe individual.\n",
    "\n",
    "`Sem Média`: Você também pode optar por não usar nenhuma média e, em vez disso, calcular a métrica para cada classe individualmente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação Binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carregar os dados\n",
    "df = pd.read_csv('titanic.csv') # Caminho do arquivo\n",
    "\n",
    "# Selecionar colunas relevantes e preencher valores ausentes (pode-se fazer um pré-processamento mais completo)\n",
    "df = df[['classe_da_passagem', 'sexo', 'idade', 'irmaos_a_bordo', 'pais_ou_filhos_a_bordo', 'valor_bilhete', 'sobreviveu']]\n",
    "df['sexo'] = df['sexo'].map({'male': 0, 'female': 1})\n",
    "df['idade'].fillna(df['idade'].mean(), inplace=True)\n",
    "\n",
    "# Dividir os dados em recursos (X) e alvo (y)\n",
    "X = df.drop('sobreviveu', axis=1)\n",
    "y = df['sobreviveu']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Padronizar os recursos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Criar e ajustar o modelo de Regressão Logística\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prever o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo usando a função \"joker\"\n",
    "metrics = metricas_classificacao(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação Multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar os dados\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Inicializar e ajustar o modelo\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prever as classes para os dados de teste\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = metricas_classificacao(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão em Machine Learning\n",
    "\n",
    "A regressão é uma técnica de aprendizado de máquina supervisionada utilizada para prever uma quantidade contínua. Ela encontra a relação entre as variáveis dependentes (saída) e independentes (características) em um conjunto de dados.\n",
    "\n",
    "## Tópicos\n",
    "\n",
    "### 1. Tipos de Regressão\n",
    "\n",
    "#### a. Regressão Linear Simples\n",
    "A regressão linear simples encontra a relação linear entre uma variável independente (X) e a variável dependente (Y). A relação é representada como uma linha reta.\n",
    "\n",
    "#### b. Regressão Linear Múltipla\n",
    "A regressão linear múltipla encontra a relação entre várias variáveis independentes (X1, X2, ..., Xn) e a variável dependente (Y).\n",
    "\n",
    "#### c. Regressão Polinomial\n",
    "A regressão polinomial modela a relação como uma equação polinomial. É útil quando os dados têm uma relação curvilínea.\n",
    "\n",
    "`A regressão polinomial é uma forma de análise de regressão que modela a relação entre uma variável dependente \n",
    "y e uma ou mais variáveis independentes X usando uma equação polinomial. Ao contrário da regressão linear simples, que modela a relação como uma linha reta, a regressão polinomial pode capturar relações mais complexas que são curvilíneas ou não lineares.`\n",
    "#### d. Regressão de Ridge e Lasso\n",
    "Ridge e Lasso são técnicas de regularização que ajudam a evitar o overfitting no modelo.\n",
    "\n",
    "### 2. Avaliação de Modelos de Regressão\n",
    "\n",
    "Root Mean Square Error (RMSE):\n",
    "\n",
    "O que é: A raiz quadrada da média dos erros quadráticos, medindo a diferença entre os valores que o modelo prevê e os valores reais.\n",
    "O que nos diz: Oferece uma noção da magnitude dos erros do modelo, penalizando mais fortemente grandes erros.\n",
    "Valor Ideal: Quanto mais próximo de 0, melhor.\n",
    "\n",
    "#### Mean Square Error (MSE):\n",
    "- O que é: A média dos erros quadráticos.\n",
    "- O que nos diz: Semelhante ao RMSE, mostra o quão bem o modelo está ajustado, com maior penalização para grandes erros.\n",
    "- Valor Ideal: O valor ideal é 0.\n",
    "\n",
    "#### Mean Absolute Error (MAE):\n",
    "- O que é: A média dos valores absolutos dos erros.\n",
    "- O que nos diz: Fornece uma medida das previsões erradas sem penalizar grandes erros tanto quanto o MSE e o RMSE.\n",
    "- Valor Ideal: 0, significando que as previsões estão perfeitamente corretas.\n",
    "\n",
    "#### Median Absolute Error:\n",
    "- O que é: A mediana dos valores absolutos dos erros.\n",
    "- O que nos diz: Dá uma ideia de como o modelo está performando em um caso \"típico\" e é menos sensível a outliers.\n",
    "- Valor Ideal: 0 é o valor ideal.\n",
    "\n",
    "#### Explained Variance Score:\n",
    "- O que é: Mostra a proporção da variação total na variável dependente que é capturada pelo modelo.\n",
    "- O que nos diz: Um valor mais alto indica que o modelo explica uma grande parte da variabilidade nos dados.\n",
    "- Valor Ideal: 100% é o valor ideal.\n",
    "\n",
    "#### R2 Score:\n",
    "- O que é: A porcentagem da variação da variável dependente que é previsível a partir das variáveis independentes.\n",
    "- O que nos diz: Um valor mais alto significa que mais variações são explicadas pelo modelo, o que é desejável.\n",
    "- Valor Ideal: 100% é o valor ideal.\n",
    "\n",
    "#### Adjusted R2:\n",
    "- O que é: Semelhante ao R2, mas ajustado com base no número de preditores no modelo.\n",
    "- O que nos diz: Dá uma medida mais realista de quão bem o modelo se ajusta aos dados, especialmente quando se adiciona mais variáveis.\n",
    "- Valor Ideal: 100% seria ideal, mas em geral, um valor que seja próximo ou igual ao R2 é considerado bom.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar os dados\n",
    "data = pd.read_csv('publicidade.csv') # Supondo que o arquivo está neste caminho\n",
    "X = data[['TV']]\n",
    "y = data['Sales']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar e ajustar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prever vendas para os dados de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plotar os dados originais e a linha de regressão\n",
    "plt.scatter(X_train, y_train, color='blue', label='Dados Originais')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2, label='Linha de Regressão')\n",
    "plt.xlabel('Investimento em TV (em $1000s)')\n",
    "plt.ylabel('Receita de Vendas (em M$)')\n",
    "plt.legend()\n",
    "plt.title('Regressão Linear Simples entre Investimento em TV e Receita de Vendas')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear Múltipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar os dados\n",
    "data = pd.read_csv('publicidade.csv') # Supondo que o arquivo está neste caminho\n",
    "X = data[['TV', 'Radio', 'Newspaper']]\n",
    "y = data['Sales']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar e ajustar o modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prever vendas para os dados de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo (opcional)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "# Plotar os valores reais\n",
    "plt.scatter(X_test['TV'], y_test, color='blue', label='Valores Reais')\n",
    "\n",
    "# Plotar os valores preditos\n",
    "plt.scatter(X_test['TV'], y_pred, color='red', label='Valores Preditos')\n",
    "\n",
    "plt.xlabel('Investimento em TV (em $1000s)')\n",
    "plt.ylabel('Receita de Vendas (em M$)')\n",
    "plt.legend()\n",
    "plt.title('Comparação entre Valores Reais e Preditos')\n",
    "plt.show()\n",
    "\n",
    "# Plotar os coeficientes do modelo\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(['TV', 'Radio', 'Newspaper'], model.coef_)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.title('Coeficientes de Regressão Linear Múltipla')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico de barras que foi gerado pelo código mostra os coeficientes da regressão linear múltipla para as três variáveis independentes: TV, rádio e jornal. Cada barra no gráfico representa um coeficiente associado a uma dessas variáveis.\n",
    "\n",
    "### 1. **TV**\n",
    "A barra associada à TV mostra o coeficiente para a variável TV. Este coeficiente indica quanto a receita de vendas (em milhões de dólares) é esperada mudar para cada aumento adicional de $1000 investido em publicidade na TV, mantendo todos os outros fatores constantes.\n",
    "\n",
    "### 2. **Rádio**\n",
    "Similarmente, a barra associada à rádio indica quanto a receita de vendas é esperada mudar para cada aumento adicional de $1000 investido em publicidade no rádio, com todos os outros fatores mantidos constantes.\n",
    "\n",
    "### 3. **Jornal**\n",
    "A barra para a variável jornal mostra o efeito previsto na receita de vendas para cada aumento adicional de $1000 investido em publicidade em jornais, mantendo todos os outros fatores constantes.\n",
    "\n",
    "Os coeficientes podem ser positivos ou negativos. Um coeficiente positivo significa que há uma relação positiva entre a variável e as vendas, ou seja, um aumento no investimento em publicidade para essa mídia está associado a um aumento nas vendas. Um coeficiente negativo indicaria uma relação negativa.\n",
    "\n",
    "O tamanho absoluto das barras dá uma indicação da força da relação entre cada variável e as vendas. Por exemplo, se a barra para a TV for significativamente maior do que as outras, isso sugere que o investimento em publicidade na TV tem um efeito maior na receita de vendas do que o investimento em rádio ou jornal.\n",
    "\n",
    "Em suma, este gráfico fornece uma representação visual da magnitude e direção dos efeitos das diferentes variáveis independentes no modelo de regressão. Isso pode ajudar a entender quais variáveis têm os maiores efeitos sobre a variável dependente e em que direção.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar os dados\n",
    "data = pd.read_csv('publicidade.csv') # Supondo que o arquivo está neste caminho\n",
    "X = data[['TV']]\n",
    "y = data['Sales']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transformar as características usando PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2) # Grau 2 para uma parábola\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Inicializar e ajustar o modelo de regressão linear com as características polinomiais\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Prever vendas para os dados de teste\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# Plotar os dados originais e a curva de regressão polinomial\n",
    "plt.scatter(X_train, y_train, color='blue', label='Dados Originais')\n",
    "plt.scatter(X_test, y_pred, color='red', label='Previsões')\n",
    "plt.xlabel('Investimento em TV (em $1000s)')\n",
    "plt.ylabel('Receita de Vendas (em M$)')\n",
    "plt.legend()\n",
    "plt.title('Regressão Polinomial entre Investimento em TV e Receita de Vendas')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um exemplo mais prático:\n",
    "A base de dados abaixo nos retorna dados com vários atributos e no final qual foi o valor do bitcoin no dia.\n",
    "Cada linha (registro) possui os valores de um dia específico, de 2009 até um dia antes do dia atual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/coinmetrics/data/master/csv/btc.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como podemos fazer para prever o valor do dia seguinte?\n",
    "Se nossa classe alvo não existe (valor do dia seguinte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_original = [1,2,3,4]\n",
    "lista = [1,2,3,4]\n",
    "print('Lista original', lista)\n",
    "\n",
    "# Exclui o primeiro registro da lista\n",
    "lista.pop(0)\n",
    "print('Lista sem o primeiro registro', lista)\n",
    "\n",
    "# Acrescenta zero ao último valor da lista\n",
    "lista.append(0)\n",
    "print('Lista com 0 na última posição', lista)\n",
    "\n",
    "df_exemplo = pd.DataFrame()\n",
    "df_exemplo['Valor Original'] = lista_original\n",
    "df_exemplo['Valor Alterado'] = lista\n",
    "df_exemplo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se considerarmos que cada dia é uma linha, agora temos a coluna valor Alterado com o valor do dia seguinte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista com os valores do preço do bitcoin nos dias\n",
    "lista_preco = list(df['PriceUSD'].values)\n",
    "\n",
    "# Remove o primeiro elemento desta lista\n",
    "lista_preco.pop(0)\n",
    "\n",
    "#Acrescenta 0 no final\n",
    "lista_preco.append(0)\n",
    "\n",
    "# Cria a coluna preco_dia_seguinte e acrescenta a lista que alteramos\n",
    "df['preco_dia_seguinte'] = lista_preco\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar nulos na coluna PriceUSD\n",
    "df.dropna(subset=['PriceUSD'], inplace = True)\n",
    "\n",
    "# Apagar nulos na coluna preco_dia_seguinte\n",
    "df.dropna(subset=['preco_dia_seguinte'], inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar todas colunas com mais de 1 valor nulo\n",
    "null_counts = df.isnull().sum()\n",
    "colunas_apagar = null_counts[null_counts > 1].index.tolist()\n",
    "colunas_apagar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(colunas_apagar, axis = 1, inplace  = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar as colunas de data\n",
    "df['ano'] = df['time'].dt.year\n",
    "df['mes'] = df['time'].dt.month\n",
    "df['dia'] = df['time'].dt.day\n",
    "df['dia_semana'] =df['time'].dt.day_of_week\n",
    "df['dia_ano'] =df['time'].dt.day_of_year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No geral, tem como colocar uma data no modelo de machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um dataframe com as datas apenas para plotar os gráficos com as datas\n",
    "datas = df[['time']].copy(deep=True)\n",
    "\n",
    "# Exclui a coluna de data da base\n",
    "df.drop(['time'], axis = 1, inplace  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna a correlação dos atributos com o valor que queremos prever\n",
    "correlation_matrix = df.corr()['preco_dia_seguinte']\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar as colunas com pouca correlação ao preco_dia_seguinte\n",
    "colunas_interesse = ['mes', 'dia', 'dia_semana', 'dia_ano', 'PriceUSD']\n",
    "colunas_remover = correlation_matrix[(correlation_matrix >= -0.3) & (correlation_matrix <= 0.3)].index.tolist()\n",
    "colunas_remover = [coluna for coluna in colunas_remover if coluna not in colunas_interesse]\n",
    "colunas_remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagar as colunas com pouca correlação ao preco_dia_seguinte\n",
    "df.drop(colunas_remover, axis=1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclui todas as linhas que possuem ao menos 1 registro nulo\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['preco_dia_seguinte'], axis = 1)\n",
    "y = df[['preco_dia_seguinte']]\n",
    "\n",
    "scale_X = MinMaxScaler()\n",
    "X = scale_X.fit_transform(X)\n",
    "\n",
    "scale_y = MinMaxScaler()\n",
    "y = scale_y.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X,y, shuffle=True, test_size=0.30, random_state=50)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, shuffle=True, test_size=0.5, random_state=50)\n",
    "\n",
    "# Isto é apenas para plotar gráficos de datas com as previsões\n",
    "X_train_data, X_temp_data, y_train_data, y_temp_data = train_test_split(datas['time'],datas['time'], shuffle=True, test_size=0.30, random_state=50)\n",
    "X_test_data, X_val_data, y_test_data, y_val_data = train_test_split(X_temp_data, y_temp_data, shuffle=True, test_size=0.5, random_state=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]\n",
    "\n",
    "# Criar um modelo sequencial\n",
    "model = Sequential()\n",
    "# Adicionar a primeira camada densa com 64 unidades, função de ativação relu\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "# Adicionar uma segunda camada densa com 32 unidades, função de ativação relu\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# Adicionar a camada de saída com 1 unidade, função de ativação linear\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# Compilar o modelo com o otimizador adam e a função de perda mean_squared_error\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treina o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar o modelo aos dados de treinamento\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = history.history['loss']\n",
    "val_loss_history = history.history['val_loss'] \n",
    "\n",
    "# Definimos os valores do eixo x (as épocas)\n",
    "x = [y+1 for y in range(0,len(loss_history))]\n",
    "\n",
    "plt.plot(x, loss_history, label = \"Loss\")\n",
    "plt.plot(x, val_loss_history, label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "grafico_x = [x for x in range(1,len(y_test_desnormalizado[:50])+1)]\n",
    "plt.plot(grafico_x, y_test_desnormalizado[:50], label='Real')\n",
    "plt.plot(grafico_x, predict_desnormalizado[:50], label='Predito')\n",
    "plt.title('Comparando valores reais e preditos de teste')\n",
    "plt.legend()\n",
    "plt.ylabel('Valor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)\n",
    "# Desnormaliza o y_test na variável y_desnormalizado\n",
    "y_test_desnormalizado = scale_y.inverse_transform(y_test)\n",
    "\n",
    "# Desnormaliza o predict na variável predict_desnormalizado\n",
    "predict_desnormalizado = scale_y.inverse_transform(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sm\n",
    "import numpy as np\n",
    "# Função Joker para avaliar modelos de regressão\n",
    "def metrics(X_test,predict, real):\n",
    "    k = X_test.shape[1]\n",
    "    n = len(X_test)\n",
    "    r2 = sm.r2_score(real, predict)\n",
    "    adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "    print('Root Mean Square Error: ',round(np.sqrt(np.mean(np.array(predict) - np.array(real))**2),2))\n",
    "    print('Mean Square Error:', round(sm.mean_squared_error(real, predict ),2))\n",
    "    print('Mean Absolut Error:', round(sm.mean_absolute_error(real, predict ),2))\n",
    "    print('Median Absolut Error:', round(sm.median_absolute_error(real, predict ),2))\n",
    "    print('Explain Variance Score:', round(sm.explained_variance_score(real, predict)*100,2))\n",
    "    print('R2 score:', round(sm.r2_score(real, predict)*100,2))\n",
    "    print('Adjusted R2 =', round(adj_r2,3)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(X_test,predict_desnormalizado, y_test_desnormalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predito = pd.DataFrame()\n",
    "df_predito['Data'] = X_test_data\n",
    "df_predito['Real'] = list(y_test_desnormalizado.flatten())\n",
    "df_predito['Predito'] = list(predict_desnormalizado.flatten())\n",
    "df_predito.sort_values(by='Real', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_x = [x for x in range(1,len(df_predito)+1)]\n",
    "plt.plot(grafico_x, df_predito.Real, label='Real')\n",
    "plt.plot(grafico_x, df_predito.Predito, label='Predito')\n",
    "plt.title('Comparando valores reais e preditos de teste')\n",
    "plt.legend()\n",
    "plt.ylabel('Valor')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício\n",
    "\n",
    "1 - BITCOIN - Utilize a mesma estrutura de modelo para os exercícios de A até F\n",
    "* A ) Treine um modelo para realizar a previsão do valor do bitcoin sem remover as colunas menos relevantes e exiba as métricas\n",
    "* B ) Treine um modelo para realizar a previsão do valor do bitcoin removendo as colunas com o filtro (correlation_matrix >= -0.3) & (correlation_matrix <= 0.3) e exiba as métricas\n",
    "* C ) Treine um modelo para realizar a previsão do valor do bitcoin removendo as colunas com o filtro (correlation_matrix >= -0.4) & (correlation_matrix <= 0.4) e exiba as métricas\n",
    "* D ) Treine um modelo para realizar a previsão do valor do bitcoin removendo as colunas com o filtro (correlation_matrix >= -0.5) & (correlation_matrix <= 0.5) e exiba as métricas\n",
    "* E ) Treine um modelo para realizar a previsão do valor do bitcoin removendo as colunas com o filtro (correlation_matrix >= -0.6) & (correlation_matrix <= 0.6) e exiba as métricas\n",
    "* F ) Treine um modelo para realizar a previsão do valor do bitcoin removendo as colunas com o filtro (correlation_matrix >= -0.7) & (correlation_matrix <= 0.7) e exiba as métricas\n",
    "* G ) Qual foi o modelo que obteve os melhores resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Agora que já decidiu qual o melhor filtro, treine 4 estruturas de modelos distintas, exiba as métricas para cada modelo e informe qual o melhor. As estruturas do modelo são:\n",
    "* A ) Com uma camada oculta\n",
    "* B ) Com duas camadas ocultas\n",
    "* C ) Com 5 camadas ocultas\n",
    "* D ) Com 10 camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
