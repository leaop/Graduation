{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução às Árvores de Decisão\n",
    "\n",
    "---\n",
    "\n",
    "## Árvores de Decisão no Machine Learning\n",
    "- **O que são Árvores de Decisão?**\n",
    "  - Estruturas de decisão hierárquicas utilizadas para classificação e regressão.\n",
    "  - Compostas por nós, ramos e folhas representando decisões baseadas em características dos dados.\n",
    "\n",
    "- **Importância no Machine Learning:**\n",
    "  - Flexibilidade para lidar com diferentes tipos de dados.\n",
    "  - Facilidade de interpretação e visualização.\n",
    "  - Aplicabilidade em diversas áreas, como finanças, medicina e e-commerce.\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivos da Aula:**\n",
    "- Compreender a teoria por trás das árvores de decisão e como aplicá-las na prática.\n",
    "- Explorar dois algoritmos principais: ID3 e Random Forest.\n",
    "- Implementar árvores de decisão em Python e analisar seu desempenho em conjuntos de dados reais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores de Decisão e o Algoritmo ID3\n",
    "\n",
    "---\n",
    "\n",
    "## Conceitos Básicos de Árvores de Decisão\n",
    "- **Definição:** Modelo de aprendizado supervisionado utilizado para classificação e regressão.\n",
    "- **Aplicabilidade:** Amplo uso em diferentes campos, como finanças, medicina e marketing.\n",
    "\n",
    "## Estrutura de uma Árvore de Decisão\n",
    "1. **Nós:**\n",
    "   - **Nó Raiz:** Ponto de partida da árvore.\n",
    "   - **Nós Internos:** Representam os testes em atributos.\n",
    "   - **Nós Folha:** Representam as decisões ou os resultados finais.\n",
    "\n",
    "2. **Ramos:**\n",
    "   - Conexões que representam as respostas aos testes e levam ao próximo nó ou folha.\n",
    "\n",
    "3. **Folhas:**\n",
    "   - Resultado final da decisão tomada após percorrer a árvore.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão do Conjunto de Dados em Árvores de Decisão\n",
    "\n",
    "### Processo de Divisão em Nós\n",
    "- **Objetivo:** Subdividir o conjunto de dados em subconjuntos mais homogêneos.\n",
    "- **Método:** \n",
    "  - Cada nó da árvore faz uma pergunta sobre um atributo.\n",
    "  - Os dados são divididos com base nas respostas a essa pergunta.\n",
    "\n",
    "### Seleção do Atributo para Divisão\n",
    "- **Baseada em Ganho de Informação:**\n",
    "  - Escolhe-se o atributo que proporciona a maior redução na entropia.\n",
    "  - O objetivo é tornar os subconjuntos resultantes mais homogêneos em relação às classes de saída.\n",
    "\n",
    "### Exemplo Prático\n",
    "- **Cenário:** Classificação de e-mails em 'spam' e 'não spam'.\n",
    "- **Aplicação:**\n",
    "  - Um nó pode dividir os dados com base no atributo \"contém a palavra 'oferta'\".\n",
    "  - Isso resulta em dois subconjuntos: e-mails com e sem a palavra 'oferta'.\n",
    "  - O processo continua até as folhas da árvore serem \"puras\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critérios de Divisão: Entropia e Ganho de Informação\n",
    "\n",
    "### Entropia\n",
    "- **Definição:** Medida da incerteza ou desordem em um conjunto de dados. Originária da termodinâmica e adaptada para a teoria da informação e aprendizado de máquina.\n",
    "- **Cálculo:**\n",
    "  - Fórmula: `-sum(p(x) * log(p(x)))`\n",
    "  - Onde `p(x)` é a probabilidade de um elemento pertencer a uma classe específica.\n",
    "- **Interpretação:**\n",
    "  - Valores altos indicam maior desordem.\n",
    "  - Nos nós das árvores de decisão, alta entropia indica menos \"pureza\".\n",
    "\n",
    "### Ganho de Informação\n",
    "- **Definição:** Medida da redução na entropia resultante da divisão de um conjunto de dados baseado em um atributo.\n",
    "- **Cálculo:**\n",
    "  - Fórmula: `Ganho(S, A) = Entropia(S) - sum((|Sv| / |S|) * Entropia(Sv))`\n",
    "  - Onde `S` é o conjunto antes da divisão, `A` é o atributo para divisão, e `Sv` são os subconjuntos após a divisão.\n",
    "- **Interpretação:**\n",
    "  - Atributos com maior ganho de informação são mais eficazes na redução da incerteza.\n",
    "  - Preferidos para criar decisões (nós) na árvore.\n",
    "\n",
    "### Divisão do Conjunto de Dados\n",
    "- **Processo:**\n",
    "  - O conjunto de dados é dividido em subconjuntos com base nos valores de um atributo escolhido.\n",
    "  - A escolha do atributo é baseada no ganho de informação, procurando maximizar a redução da entropia.\n",
    "- **Importância no Modelo:**\n",
    "  - Essencial para a construção eficaz das árvores de decisão.\n",
    "  - Ajuda na tomada de decisões e na \"limpeza\" dos dados para melhor interpretação e classificação.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Algoritmo ID3: Passo a Passo\n",
    "\n",
    "### Introdução ao ID3\n",
    "- **Definição:** O algoritmo ID3 (Iterative Dichotomiser 3) é um método clássico utilizado para construir árvores de decisão. É usado principalmente para problemas de classificação.\n",
    "- **Funcionamento:** Baseia-se em critérios de informação para dividir o conjunto de dados e formar uma árvore que representa as decisões.\n",
    "\n",
    "### Passos do Algoritmo ID3\n",
    "1. **Início na Raiz da Árvore:**\n",
    "   - Começa com todo o conjunto de dados.\n",
    "   - Considera todos os atributos disponíveis.\n",
    "\n",
    "2. **Seleção do Melhor Atributo:**\n",
    "   - Usa o critério de Ganho de Informação para escolher o melhor atributo.\n",
    "   - O atributo selecionado é aquele que melhor divide o conjunto de dados em categorias homogêneas.\n",
    "\n",
    "3. **Divisão do Conjunto de Dados:**\n",
    "   - Divide o conjunto de dados com base no valor do atributo escolhido.\n",
    "   - Cada valor distinto do atributo gera um ramo na árvore.\n",
    "\n",
    "4. **Repetição do Processo:**\n",
    "   - O processo é repetido para cada subconjunto de dados resultante.\n",
    "   - Novos nós são criados em cada passo, utilizando os atributos restantes.\n",
    "\n",
    "5. **Critérios de Parada:**\n",
    "   - O processo continua até que os nós folha sejam puros (contenham apenas dados de uma categoria) ou outros critérios de parada sejam atingidos, como profundidade máxima da árvore ou número mínimo de amostras em um nó.\n",
    "\n",
    "### Resultado\n",
    "- A árvore de decisão final representa uma série de decisões, que ajudam a classificar novos dados com base nos atributos e valores aprendidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exemplo Prático em Python\n",
    "- Construção de uma árvore de decisão simples utilizando o algoritmo ID3.\n",
    "- Uso de um conjunto de dados simples para ilustrar o processo.\n",
    "- Código comentado passo a passo para facilitar a compreensão.\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo da Seção:**\n",
    "- Compreender a teoria e a prática por trás das árvores de decisão e do algoritmo ID3.\n",
    "- Aplicar o conhecimento adquirido em um exemplo prático em Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jogar_tenis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicação da Base de Dados para Uso com Árvore de Decisão\n",
    "\n",
    "A base de dados consiste em cinco colunas que representam características meteorológicas e uma resposta. Estas são:\n",
    "\n",
    "1. **Clima:** \n",
    "   - Categorias: 'ensolarado', 'nublado', 'chuva'.\n",
    "   - Descreve o estado do tempo.\n",
    "\n",
    "2. **Temperatura:** \n",
    "   - Categorias: 'quente', 'ameno', 'frio'.\n",
    "   - Indica a temperatura do ambiente.\n",
    "\n",
    "3. **Umidade:** \n",
    "   - Categorias: 'alta', 'normal'.\n",
    "   - Reflete o nível de umidade do ar.\n",
    "\n",
    "4. **Vento:** \n",
    "   - Categorias: 'fraco', 'forte'.\n",
    "   - Mostra a intensidade do vento.\n",
    "\n",
    "5. **Jogar Tenis:** \n",
    "   - Categorias: 'não', 'sim'.\n",
    "   - Resposta binária, indicando a adequação para Jogar Tenis.\n",
    "\n",
    "### Utilização em Árvore de Decisão\n",
    "- **Objetivo:** Usar esta base de dados para construir uma árvore de decisão que possa prever a 'Resposta' com base nas condições meteorológicas.\n",
    "- **Processo:** \n",
    "  - A árvore de decisão divide o conjunto de dados em nós baseados nas características, procurando a melhor divisão para maximizar a pureza dos nós em relação à resposta (sim/não).\n",
    "  - Ideal para entender padrões e tomar decisões baseadas em condições climáticas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo dados categóricos em numéricos (+ uma forma de aplicar)\n",
    "df_encoded = df.apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as características e o alvo\n",
    "X = df_encoded.drop('Jogar Tenis', axis=1)\n",
    "y = df_encoded['Jogar Tenis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando e treinando o modelo de árvore de decisão\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a árvore de decisão com parâmetros ajustados\n",
    "plt.figure(figsize=(15, 10))  # Aumentando o tamanho da figura\n",
    "\n",
    "# Ajustando o tamanho da fonte\n",
    "plot_tree(clf, filled=True, feature_names=X.columns, class_names=['Não', 'Sim'], rounded=True, \n",
    "          fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo Random Forest\n",
    "\n",
    "---\n",
    "\n",
    "## Introdução ao Conceito de Ensemble Learning\n",
    "- **Definição:** Técnica que combina as previsões de vários modelos de machine learning para produzir uma previsão mais precisa.\n",
    "- **Princípio Básico:** \"A sabedoria das multidões\" - um conjunto de modelos pode ser mais eficaz do que um único modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## Random Forest: Ideia Básica e Diferenças\n",
    "- **O que é Random Forest?**\n",
    "  - Um método de ensemble que combina várias árvores de decisão para melhorar a estabilidade e a precisão.\n",
    "- **Diferenças em Relação às Árvores de Decisão Individuais:**\n",
    "  - Cada árvore na floresta é construída a partir de uma amostra aleatória dos dados.\n",
    "  - As decisões de cada árvore são agregadas para formar a decisão final.\n",
    "\n",
    "---\n",
    "\n",
    "## Vantagens e Desvantagens do Random Forest\n",
    "- **Vantagens:**\n",
    "  - Alta precisão e robustez.\n",
    "  - Menor risco de overfitting em comparação com árvores de decisão individuais.\n",
    "  - Importância das variáveis automaticamente calculada.\n",
    "- **Desvantagens:**\n",
    "  - Maior complexidade computacional.\n",
    "  - Menor interpretabilidade em comparação com uma única árvore de decisão.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exemplo Prático em Python\n",
    "- Implementação de um modelo Random Forest utilizando a biblioteca `sklearn`.\n",
    "- Uso de um conjunto de dados real para ilustrar o processo.\n",
    "- Explicação detalhada do código para garantir a compreensão.\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo da Seção:**\n",
    "- Entender o funcionamento e a aplicação prática do Random Forest.\n",
    "- Comparar a eficácia do Random Forest com as árvores de decisão individuais.\n",
    "- Aplicar o conhecimento em um exemplo prático usando Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de Dados de Identificação de Vidros\n",
    "\n",
    "\n",
    "## Fontes\n",
    "- Criador: B. German\n",
    "  - Estabelecimento Central de Pesquisa\n",
    "  - Serviço de Ciência Forense do Ministério do Interior\n",
    "  - Aldermaston, Reading, Berkshire RG7 4PN\n",
    "- Nota técnica desconhecida (número não listado aqui)\n",
    "- Resultados Gerais: o algoritmo do vizinho mais próximo se comparou bem com o sistema baseado em regras\n",
    "\n",
    "## Informações Relevantes\n",
    "A motivação para o estudo da classificação dos tipos de vidro foi a investigação criminológica. Na cena do crime, o vidro encontrado pode ser usado como evidência... se for corretamente identificado!\n",
    "\n",
    "## Número de Registros\n",
    "214\n",
    "\n",
    "## Número de Atributos\n",
    "9 mais a classe\n",
    "- Todos os atributos são de valor contínuo\n",
    "\n",
    "## Informações dos Atributos e da Classe\n",
    "- RI: Índice de refração\n",
    "- Na: Sódio (unidade de medida: percentual de peso no óxido correspondente, assim como os atributos 4-10)\n",
    "- Mg: Magnésio\n",
    "- Al: Alumínio\n",
    "- Si: Silício\n",
    "- K: Potássio\n",
    "- Ca: Cálcio\n",
    "- Ba: Bário\n",
    "- Fe: Ferro\n",
    "- Tipo de vidro (atributo de classe):\n",
    "  - 1 - Janelas de edifícios processadas por flutuação\n",
    "  - 2 - Janelas de edifícios não processadas por flutuação\n",
    "  - 3 - Janelas de veículos processadas por flutuação\n",
    "  - 4 - Janelas de veículos não processadas por flutuação (nenhuma nesta base de dados)\n",
    "  - 5 - Recipientes\n",
    "  - 6 - Utensílios de mesa\n",
    "  - 7 - Faróis\n",
    "- Valores de Atributos Ausentes: Nenhum\n",
    "\n",
    "## Estatísticas Resumidas\n",
    "| Atributo | Mínimo | Máximo | Média   | Desvio Padrão | Correlação com a Classe |\n",
    "|----------|--------|--------|---------|---------------|-------------------------|\n",
    "| RI       | 1.5112 | 1.5339 | 1.5184  | 0.0030        | -0.1642                 |\n",
    "| Na       | 10.73  | 17.38  | 13.4079 | 0.8166        | 0.5030                  |\n",
    "| Mg       | 0      | 4.49   | 2.6845  | 1.4424        | -0.7447                 |\n",
    "| Al       | 0.29   | 3.5    | 1.4449  | 0.4993        | 0.5988                  |\n",
    "| Si       | 69.81  | 75.41  | 72.6509 | 0.7745        | 0.1515                  |\n",
    "| K        | 0      | 6.21   | 0.4971  | 0.6522        | -0.0100                 |\n",
    "| Ca       | 5.43   | 16.19  | 8.9570  | 1.4232        | 0.0007                  |\n",
    "| Ba       | 0      | 3.15   | 0.1750  | 0.4972        | 0.5751                  |\n",
    "| Fe       | 0      | 0.51   | 0.0570  | 0.0974        | -0.1879                 |\n",
    "\n",
    "\n",
    "## Distribuição de Classes (de um total de 214 instâncias)\n",
    "- 163 Vidros de Janela (janelas de edifícios e veículos)\n",
    "- 87 processados por flutuação\n",
    "- 70 janelas de edifícios\n",
    "- 17 janelas de veículos\n",
    "- 76 não processados por flutuação\n",
    "- 76 janelas de edifícios\n",
    "- 0 janelas de veículos\n",
    "- 51 Vidros Não-Janela\n",
    "- 13 recipientes\n",
    "- 9 utensílios de mesa\n",
    "- 29 faróis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vidro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def metricas_classificacao(y_real, y_pred):\n",
    "    # Calcular métricas\n",
    "    metrics = {\n",
    "        \"Acurácia\": accuracy_score(y_real, y_pred),\n",
    "        \"Precisão (macro)\": precision_score(y_real, y_pred, average='macro', zero_division=0),\n",
    "        \"Recall (macro)\": recall_score(y_real, y_pred, average='macro', zero_division=0),\n",
    "        \"F1-Score (macro)\": f1_score(y_real, y_pred, average='macro', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    # Printar métricas\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Calcular a Matriz de Confusão\n",
    "    confusion_mat = confusion_matrix(y_real, y_pred)\n",
    "\n",
    "    # Printar Matriz de Confusão\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    sns.heatmap(confusion_mat, annot=True, cmap='YlGnBu', fmt='g')\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os recursos (X) e o rótulo alvo (y)\n",
    "X = df.drop('Type', axis=1)  # Substitua 'Class' pelo nome da sua coluna de classe\n",
    "y = df['Type']  # Substitua 'Class' pelo nome da sua coluna de classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicação do Parâmetro `n_estimators` no Random Forest\n",
    "\n",
    "O algoritmo Random Forest é um método de ensemble popular em aprendizado de máquina. Ele opera construindo múltiplas árvores de decisão durante o treinamento. A saída do algoritmo é determinada pela moda das classes (em tarefas de classificação) ou pela média das previsões (em tarefas de regressão) das árvores individuais.\n",
    "\n",
    "## Parâmetro `n_estimators`\n",
    "\n",
    "O parâmetro `n_estimators` é crucial no Random Forest. Ele especifica o número de árvores de decisão que devem ser construídas pelo algoritmo.\n",
    "\n",
    "### Como Funciona\n",
    "\n",
    "- **Número de Árvores**: Define quantas árvores de decisão serão criadas e utilizadas para fazer previsões.\n",
    "- **Valores Comuns**: Geralmente varia de 10 a centenas ou milhares. O valor ideal depende das características específicas do conjunto de dados e do problema.\n",
    "- **Impacto no Desempenho**: \n",
    "  - **Precisão**: Aumentar `n_estimators` geralmente melhora a precisão, pois mais árvores reduzem a variância das previsões.\n",
    "  - **Recursos Computacionais**: Maior número de árvores pode aumentar significativamente o tempo de treinamento e o uso de recursos.\n",
    "- **Equilíbrio**: É importante encontrar um equilíbrio entre a quantidade de árvores e os recursos disponíveis, além de considerar o princípio dos rendimentos decrescentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo de Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Treinando o modelo\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_classificacao(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando o resultado com menos árvores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo de Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "# Treinando o modelo\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "metricas_classificacao(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparação entre ID3 e Random Forest\n",
    "\n",
    "---\n",
    "\n",
    "## Diferenças de Performance\n",
    "- **ID3:**\n",
    "  - Ideal para conjuntos de dados menores e mais simples.\n",
    "  - Tende a sofrer de overfitting em dados mais complexos.\n",
    "  - Facilmente interpretável devido à sua estrutura simples.\n",
    "\n",
    "- **Random Forest:**\n",
    "  - Mais eficaz em conjuntos de dados grandes e complexos.\n",
    "  - Reduz significativamente o risco de overfitting.\n",
    "  - Melhor desempenho geral, mas com maior custo computacional.\n",
    "\n",
    "---\n",
    "\n",
    "## Quando Usar Cada Um\n",
    "- **ID3:**\n",
    "  - Quando a interpretabilidade do modelo é crucial.\n",
    "  - Em problemas com menos variáveis e dados menos complexos.\n",
    "\n",
    "- **Random Forest:**\n",
    "  - Em problemas que exigem modelos robustos e de alta precisão.\n",
    "  - Quando a complexidade dos dados é alta e a interpretabilidade não é a principal preocupação.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização de Dados para ID3 e Random Forest\n",
    "\n",
    "Ao utilizar algoritmos baseados em árvores de decisão, como ID3 e Random Forest, surge frequentemente a pergunta sobre a necessidade de normalização dos dados. Vamos explorar esta questão e entender como lidar com colunas textuais que foram convertidas para numéricas.\n",
    "\n",
    "## Normalização: Não é Necessária para ID3 e Random Forest\n",
    "\n",
    "### Características dos Algoritmos de Árvore\n",
    "\n",
    "1. **Decisões Baseadas em Thresholds**:\n",
    "   - Estes algoritmos tomam decisões com base em limiares das características.\n",
    "   - Exemplo: \"se a temperatura > 20 graus\".\n",
    "\n",
    "2. **Insensibilidade à Escala**:\n",
    "   - Árvores de decisão não são afetadas pela escala dos dados.\n",
    "   - Isso difere de algoritmos como SVM ou redes neurais, onde a normalização pode influenciar as funções de custo ou gradientes.\n",
    "\n",
    "3. **Interpretabilidade**:\n",
    "   - Manter os dados na escala original ajuda a preservar a interpretabilidade do modelo.\n",
    "\n",
    "### Tratamento de Colunas Textuais Convertidas para Numéricas\n",
    "\n",
    "- **Codificação de Categorias**:\n",
    "  - Conversão de colunas textuais para numéricas é feita para permitir o processamento pelo algoritmo.\n",
    "  - Métodos comuns incluem codificação label ou one-hot encoding.\n",
    "\n",
    "- **Manutenção da Forma Convertida**:\n",
    "  - Para algoritmos de árvore, mantenha essas colunas na forma convertida sem normalização.\n",
    "  - A magnitude dos códigos numéricos não afeta o desempenho do modelo.\n",
    "\n",
    "### Exceções\n",
    "\n",
    "- **Algoritmos Sensíveis à Escala**:\n",
    "  - Se utilizar um algoritmo sensível à escala junto com um algoritmo de árvore, pode ser necessário normalizar os dados.\n",
    "  - Exemplo: combinação de modelos (ensemble) que inclui algoritmos sensíveis à escala.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "Para algoritmos como ID3 e Random Forest, a normalização dos recursos numéricos não é necessária, e as colunas textuais convertidas devem ser mantidas em seu formato numérico codificado. Isso mantém a simplicidade do processo de pré-processamento e a interpretabilidade dos modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios\n",
    "`Quem terminar os exercícios até o final da aula irá ganhar ponto extra` \n",
    "OBS: Só irei publicar a base de dados após o término de toda explicação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicação da Base de Dados de Saúde\n",
    "\n",
    "A base de dados `ataque_cardiaco.csv` tem informações relacionadas à saúde e estilos de vida dos indivíduos. Abaixo está um breve resumo de cada coluna e o que ela representa:\n",
    "\n",
    "- `AltaPressãoSanguínea`: Mostra se o indivíduo tem histórico de hipertensão.\n",
    "- `AltoColesterol`: Registra se o indivíduo tem níveis elevados de colesterol.\n",
    "- `VerificaçãoColesterol`: Indica se o indivíduo fez um exame de colesterol recentemente.\n",
    "- `IMC`: Índice de Massa Corporal, que é um indicador da saúde corporal em relação à altura e peso.\n",
    "- `Fumante`: Mostra se o indivíduo é fumante.\n",
    "- `AVC`: Indica se o indivíduo já sofreu um Acidente Vascular Cerebral.\n",
    "- `Diabetes`: Registra se o indivíduo tem diabetes.\n",
    "- `AtividadeFísica`: Indica o nível de atividade física do indivíduo.\n",
    "- `Frutas`: Registra a frequência de consumo de frutas.\n",
    "- `Legumes`: Registra a frequência de consumo de legumes.\n",
    "- `ConsumoAltoDeÁlcool`: Indica se o indivíduo consome álcool em quantidade considerada alta.\n",
    "- `QualquerPlanoDeSaúde`: Mostra se o indivíduo possui algum tipo de plano de saúde.\n",
    "- `SemMédicoPorCusto`: Indica se o indivíduo deixou de consultar um médico devido a custos.\n",
    "- `SaúdeGeral`: Avaliação geral da saúde do indivíduo.\n",
    "- `SaúdeMental`: Indica a condição de saúde mental do indivíduo.\n",
    "- `SaúdeFísica`: Indica a condição de saúde física do indivíduo.\n",
    "- `DificuldadeParaCaminhar`: Mostra se o indivíduo tem dificuldade para caminhar.\n",
    "- `Sexo`: Gênero do indivíduo.\n",
    "- `Idade`: Idade do indivíduo.\n",
    "- `Educação`: Nível de educação do indivíduo.\n",
    "- `Renda`: Faixa de renda do indivíduo.\n",
    "- `DoençaCardíacaouAtaque`: Indica se o indivíduo teve alguma doença cardíaca ou ataque cardíaco. `Classe Alvo`\n",
    "\n",
    "Essas colunas fornecem uma visão abrangente dos fatores de saúde e estilo de vida que podem impactar o bem-estar geral dos indivíduos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados só possui valores inteiros e não possui valores núlos. Todavia, Faça a análise completa abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Leitura da Base de Dados\n",
    "\n",
    "- **Tarefa**: Leia a base de dados 'ataque_cardiaco.csv'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Análise Inicial dos Dados\n",
    "\n",
    "Realize uma análise exploratória inicial para compreender melhor os dados:\n",
    "\n",
    "- **Ver as linhas iniciais**: Observe as primeiras entradas para ter uma ideia da estrutura dos dados.\n",
    "- **Tipo de Dados das Colunas**: Identifique os tipos de dados de cada coluna.\n",
    "- **Valores Nulos**: Verifique a quantidade de valores nulos em cada coluna.\n",
    "- **Informações Descritivas**: Analise as estatísticas descritivas das colunas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Separação dos Dados em X e y\n",
    "\n",
    "- **Tarefa**: Separe os dados em variáveis independentes (X) e a variável dependente (y), sendo y 'DoençaCardíacaouAtaque'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Divisão em Conjuntos de Treinamento e Teste\n",
    "\n",
    "- **Proporção**: Separe os dados em 70% para treinamento e 30% para teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Criação de Modelos Random Forest\n",
    "\n",
    "- **Objetivo**: Crie 5 instâncias do modelo Random Forest com os seguintes valores para `n_estimators`: 5, 20, 50, 100, 200.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Treinamento dos Modelos Random Forest\n",
    "\n",
    "- **Tarefa**: Treine cada um dos 5 modelos Random Forest criados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Criação e Treinamento de Modelo de Árvore de Decisão\n",
    "\n",
    "- **Objetivo**: Crie e treine um modelo de árvore de decisão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Avaliação dos Modelos\n",
    "\n",
    "- **Métricas**: Utilize a função de métricas para avaliar o desempenho dos 6 modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Comparação e Seleção do Melhor Modelo\n",
    "\n",
    "- **Análise**: Com base nas métricas de avaliação, determine qual foi o melhor modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
